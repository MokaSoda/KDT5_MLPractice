{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-28T12:42:16.171378200Z",
     "start_time": "2024-02-28T12:42:15.574342100Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "# autoMPG\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearnex import patch_sklearn, unpatch_sklearn\n",
    "patch_sklearn()\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "# font to 맑은 고딕\n",
    "mpl.rc('font', family='Malgun Gothic')\n",
    "import seaborn as sns\n",
    "\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터셋 로딩 및 전처리\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-28T12:42:16.935303400Z",
     "start_time": "2024-02-28T12:42:16.172375100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "    mpg  cylinders  displacement horsepower  weight  acceleration  model_year  \\\n0  18.0          8         307.0      130.0  3504.0          12.0          70   \n1  15.0          8         350.0      165.0  3693.0          11.5          70   \n2  18.0          8         318.0      150.0  3436.0          11.0          70   \n3  16.0          8         304.0      150.0  3433.0          12.0          70   \n4  17.0          8         302.0      140.0  3449.0          10.5          70   \n\n   origin                   car_name  \n0       1  chevrolet chevelle malibu  \n1       1          buick skylark 320  \n2       1         plymouth satellite  \n3       1              amc rebel sst  \n4       1                ford torino  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mpg</th>\n      <th>cylinders</th>\n      <th>displacement</th>\n      <th>horsepower</th>\n      <th>weight</th>\n      <th>acceleration</th>\n      <th>model_year</th>\n      <th>origin</th>\n      <th>car_name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>18.0</td>\n      <td>8</td>\n      <td>307.0</td>\n      <td>130.0</td>\n      <td>3504.0</td>\n      <td>12.0</td>\n      <td>70</td>\n      <td>1</td>\n      <td>chevrolet chevelle malibu</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>15.0</td>\n      <td>8</td>\n      <td>350.0</td>\n      <td>165.0</td>\n      <td>3693.0</td>\n      <td>11.5</td>\n      <td>70</td>\n      <td>1</td>\n      <td>buick skylark 320</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>18.0</td>\n      <td>8</td>\n      <td>318.0</td>\n      <td>150.0</td>\n      <td>3436.0</td>\n      <td>11.0</td>\n      <td>70</td>\n      <td>1</td>\n      <td>plymouth satellite</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>16.0</td>\n      <td>8</td>\n      <td>304.0</td>\n      <td>150.0</td>\n      <td>3433.0</td>\n      <td>12.0</td>\n      <td>70</td>\n      <td>1</td>\n      <td>amc rebel sst</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>17.0</td>\n      <td>8</td>\n      <td>302.0</td>\n      <td>140.0</td>\n      <td>3449.0</td>\n      <td>10.5</td>\n      <td>70</td>\n      <td>1</td>\n      <td>ford torino</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv(url, header=None, sep='\\s+')\n",
    "df.columns = ['mpg', 'cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'model_year', 'origin', 'car_name']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-28T12:42:16.997792500Z",
     "start_time": "2024-02-28T12:42:16.968598300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 398 entries, 0 to 397\n",
      "Data columns (total 9 columns):\n",
      " #   Column        Non-Null Count  Dtype   \n",
      "---  ------        --------------  -----   \n",
      " 0   mpg           398 non-null    float64 \n",
      " 1   cylinders     398 non-null    int64   \n",
      " 2   displacement  398 non-null    float64 \n",
      " 3   horsepower    398 non-null    object  \n",
      " 4   weight        398 non-null    float64 \n",
      " 5   acceleration  398 non-null    float64 \n",
      " 6   model_year    398 non-null    int64   \n",
      " 7   origin        398 non-null    category\n",
      " 8   car_name      398 non-null    object  \n",
      "dtypes: category(1), float64(4), int64(2), object(2)\n",
      "memory usage: 25.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df['origin'] = df['origin'].astype('category')\n",
    "df['model_year'] = df['model_year'].apply(lambda x: pd.to_datetime(x, format='%y').year)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-28T12:42:17.054951100Z",
     "start_time": "2024-02-28T12:42:16.970598500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      mpg  cylinders  displacement  horsepower  weight  acceleration  \\\n0    18.0          8         307.0       130.0  3504.0          12.0   \n1    15.0          8         350.0       165.0  3693.0          11.5   \n2    18.0          8         318.0       150.0  3436.0          11.0   \n3    16.0          8         304.0       150.0  3433.0          12.0   \n4    17.0          8         302.0       140.0  3449.0          10.5   \n..    ...        ...           ...         ...     ...           ...   \n387  27.0          4         140.0        86.0  2790.0          15.6   \n388  44.0          4          97.0        52.0  2130.0          24.6   \n389  32.0          4         135.0        84.0  2295.0          11.6   \n390  28.0          4         120.0        79.0  2625.0          18.6   \n391  31.0          4         119.0        82.0  2720.0          19.4   \n\n     model_year origin                   car_name  \n0          1970      1  chevrolet chevelle malibu  \n1          1970      1          buick skylark 320  \n2          1970      1         plymouth satellite  \n3          1970      1              amc rebel sst  \n4          1970      1                ford torino  \n..          ...    ...                        ...  \n387        1982      1            ford mustang gl  \n388        1982      2                  vw pickup  \n389        1982      1              dodge rampage  \n390        1982      1                ford ranger  \n391        1982      1                 chevy s-10  \n\n[392 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mpg</th>\n      <th>cylinders</th>\n      <th>displacement</th>\n      <th>horsepower</th>\n      <th>weight</th>\n      <th>acceleration</th>\n      <th>model_year</th>\n      <th>origin</th>\n      <th>car_name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>18.0</td>\n      <td>8</td>\n      <td>307.0</td>\n      <td>130.0</td>\n      <td>3504.0</td>\n      <td>12.0</td>\n      <td>1970</td>\n      <td>1</td>\n      <td>chevrolet chevelle malibu</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>15.0</td>\n      <td>8</td>\n      <td>350.0</td>\n      <td>165.0</td>\n      <td>3693.0</td>\n      <td>11.5</td>\n      <td>1970</td>\n      <td>1</td>\n      <td>buick skylark 320</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>18.0</td>\n      <td>8</td>\n      <td>318.0</td>\n      <td>150.0</td>\n      <td>3436.0</td>\n      <td>11.0</td>\n      <td>1970</td>\n      <td>1</td>\n      <td>plymouth satellite</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>16.0</td>\n      <td>8</td>\n      <td>304.0</td>\n      <td>150.0</td>\n      <td>3433.0</td>\n      <td>12.0</td>\n      <td>1970</td>\n      <td>1</td>\n      <td>amc rebel sst</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>17.0</td>\n      <td>8</td>\n      <td>302.0</td>\n      <td>140.0</td>\n      <td>3449.0</td>\n      <td>10.5</td>\n      <td>1970</td>\n      <td>1</td>\n      <td>ford torino</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>387</th>\n      <td>27.0</td>\n      <td>4</td>\n      <td>140.0</td>\n      <td>86.0</td>\n      <td>2790.0</td>\n      <td>15.6</td>\n      <td>1982</td>\n      <td>1</td>\n      <td>ford mustang gl</td>\n    </tr>\n    <tr>\n      <th>388</th>\n      <td>44.0</td>\n      <td>4</td>\n      <td>97.0</td>\n      <td>52.0</td>\n      <td>2130.0</td>\n      <td>24.6</td>\n      <td>1982</td>\n      <td>2</td>\n      <td>vw pickup</td>\n    </tr>\n    <tr>\n      <th>389</th>\n      <td>32.0</td>\n      <td>4</td>\n      <td>135.0</td>\n      <td>84.0</td>\n      <td>2295.0</td>\n      <td>11.6</td>\n      <td>1982</td>\n      <td>1</td>\n      <td>dodge rampage</td>\n    </tr>\n    <tr>\n      <th>390</th>\n      <td>28.0</td>\n      <td>4</td>\n      <td>120.0</td>\n      <td>79.0</td>\n      <td>2625.0</td>\n      <td>18.6</td>\n      <td>1982</td>\n      <td>1</td>\n      <td>ford ranger</td>\n    </tr>\n    <tr>\n      <th>391</th>\n      <td>31.0</td>\n      <td>4</td>\n      <td>119.0</td>\n      <td>82.0</td>\n      <td>2720.0</td>\n      <td>19.4</td>\n      <td>1982</td>\n      <td>1</td>\n      <td>chevy s-10</td>\n    </tr>\n  </tbody>\n</table>\n<p>392 rows × 9 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['horsepower'] = df['horsepower'].apply(lambda x: pd.to_numeric(x, errors='coerce'))\n",
    "df.dropna(inplace=True, axis=0)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-28T12:42:17.114755800Z",
     "start_time": "2024-02-28T12:42:16.988306400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "mpg             1.000000\ncylinders      -0.777618\ndisplacement   -0.805127\nhorsepower     -0.778427\nweight         -0.832244\nacceleration    0.423329\nName: mpg, dtype: float64"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrdf = df.drop([\n",
    "    'car_name', \n",
    "    'origin' , \n",
    "    'model_year'\n",
    "    ], axis=1)\n",
    "corrdf.corr()['mpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-28T12:42:17.116749Z",
     "start_time": "2024-02-28T12:42:16.994801400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "     cylinders  displacement  horsepower  weight  acceleration\n387          4         140.0        86.0  2790.0          15.6\n388          4          97.0        52.0  2130.0          24.6\n389          4         135.0        84.0  2295.0          11.6\n390          4         120.0        79.0  2625.0          18.6\n391          4         119.0        82.0  2720.0          19.4",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cylinders</th>\n      <th>displacement</th>\n      <th>horsepower</th>\n      <th>weight</th>\n      <th>acceleration</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>387</th>\n      <td>4</td>\n      <td>140.0</td>\n      <td>86.0</td>\n      <td>2790.0</td>\n      <td>15.6</td>\n    </tr>\n    <tr>\n      <th>388</th>\n      <td>4</td>\n      <td>97.0</td>\n      <td>52.0</td>\n      <td>2130.0</td>\n      <td>24.6</td>\n    </tr>\n    <tr>\n      <th>389</th>\n      <td>4</td>\n      <td>135.0</td>\n      <td>84.0</td>\n      <td>2295.0</td>\n      <td>11.6</td>\n    </tr>\n    <tr>\n      <th>390</th>\n      <td>4</td>\n      <td>120.0</td>\n      <td>79.0</td>\n      <td>2625.0</td>\n      <td>18.6</td>\n    </tr>\n    <tr>\n      <th>391</th>\n      <td>4</td>\n      <td>119.0</td>\n      <td>82.0</td>\n      <td>2720.0</td>\n      <td>19.4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = df['mpg']\n",
    "features = df.drop([\n",
    "    'mpg', \n",
    "    'car_name', \n",
    "    'origin' , \n",
    "    'model_year', \n",
    "    # 'acceleration',\n",
    "    ], axis=1\n",
    "                   )\n",
    "features.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-28T12:42:19.735844600Z",
     "start_time": "2024-02-28T12:42:17.004110700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RBscaler KNN R2 Score: 0.8617\n",
      "stdScaler KNN R2 Score: 0.8562\n",
      "scalerZ KNN R2 Score: 0.8879\n",
      "RBscaler linear R2 Score: 0.8914\n",
      "stdScaler linear R2 Score: 0.8914\n",
      "scalerZ linear R2 Score: 0.8745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:2667: UserWarning: n_quantiles (1000) is greater than the total number of samples (313). n_quantiles is set to n_samples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:2667: UserWarning: n_quantiles (1000) is greater than the total number of samples (313). n_quantiles is set to n_samples.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "node array from the pickle has an incompatible dtype:\n- expected: {'names': ['left_child', 'right_child', 'feature', 'threshold', 'impurity', 'n_node_samples', 'weighted_n_node_samples', 'missing_go_to_left'], 'formats': ['<i8', '<i8', '<i8', '<f8', '<f8', '<i8', '<f8', 'u1'], 'offsets': [0, 8, 16, 24, 32, 40, 48, 56], 'itemsize': 64}\n- got     : [('left_child', '<i8'), ('right_child', '<i8'), ('feature', '<i8'), ('threshold', '<f8'), ('impurity', '<f8'), ('n_node_samples', '<i8'), ('weighted_n_node_samples', '<f8')]",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[7], line 66\u001B[0m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m regression \u001B[38;5;129;01min\u001B[39;00m regressionList:\n\u001B[0;32m     65\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m scaler \u001B[38;5;129;01min\u001B[39;00m scalerList:\n\u001B[1;32m---> 66\u001B[0m                 trainData(scaler, regression)\n",
      "Cell \u001B[1;32mIn[7], line 55\u001B[0m, in \u001B[0;36mtrainData\u001B[1;34m(scaler, regression)\u001B[0m\n\u001B[0;32m     42\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtrainData\u001B[39m(scaler, regression):\n\u001B[0;32m     43\u001B[0m         model \u001B[38;5;241m=\u001B[39m Pipeline(\n\u001B[0;32m     44\u001B[0m         [\n\u001B[0;32m     45\u001B[0m         scaler,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     53\u001B[0m         ]\n\u001B[0;32m     54\u001B[0m         )\n\u001B[1;32m---> 55\u001B[0m         model\u001B[38;5;241m.\u001B[39mfit(X_train, y_train)\n\u001B[0;32m     56\u001B[0m         \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmetrics\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m mean_squared_error, mean_absolute_error, r2_score\n\u001B[0;32m     57\u001B[0m         y_pred \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mpredict(X_test)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[1;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1144\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[0;32m   1146\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m   1147\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m   1148\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m   1149\u001B[0m     )\n\u001B[0;32m   1150\u001B[0m ):\n\u001B[1;32m-> 1151\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fit_method(estimator, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py:420\u001B[0m, in \u001B[0;36mPipeline.fit\u001B[1;34m(self, X, y, **fit_params)\u001B[0m\n\u001B[0;32m    418\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_final_estimator \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpassthrough\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m    419\u001B[0m         fit_params_last_step \u001B[38;5;241m=\u001B[39m fit_params_steps[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msteps[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m][\u001B[38;5;241m0\u001B[39m]]\n\u001B[1;32m--> 420\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_final_estimator\u001B[38;5;241m.\u001B[39mfit(Xt, y, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_params_last_step)\n\u001B[0;32m    422\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\daal4py\\sklearn\\_device_offload.py:88\u001B[0m, in \u001B[0;36msupport_usm_ndarray.<locals>.decorator.<locals>.wrapper_with_self\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m     86\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(func)\n\u001B[0;32m     87\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapper_with_self\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m---> 88\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m wrapper_impl(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\daal4py\\sklearn\\_device_offload.py:74\u001B[0m, in \u001B[0;36msupport_usm_ndarray.<locals>.decorator.<locals>.wrapper_impl\u001B[1;34m(obj, *args, **kwargs)\u001B[0m\n\u001B[0;32m     72\u001B[0m usm_iface \u001B[38;5;241m=\u001B[39m _extract_usm_iface(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     73\u001B[0m q, hostargs, hostkwargs \u001B[38;5;241m=\u001B[39m _get_host_inputs(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m---> 74\u001B[0m result \u001B[38;5;241m=\u001B[39m _run_on_device(func, q, obj, \u001B[38;5;241m*\u001B[39mhostargs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mhostkwargs)\n\u001B[0;32m     75\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m usm_iface \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(result, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m__array_interface__\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[0;32m     76\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _copy_to_usm(q, result)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\daal4py\\sklearn\\_device_offload.py:65\u001B[0m, in \u001B[0;36m_run_on_device\u001B[1;34m(func, queue, obj, *args, **kwargs)\u001B[0m\n\u001B[0;32m     62\u001B[0m         \u001B[38;5;28;01mwith\u001B[39;00m sycl_context(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgpu\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m queue\u001B[38;5;241m.\u001B[39msycl_device\u001B[38;5;241m.\u001B[39mis_gpu \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m     63\u001B[0m                           host_offload_on_fail\u001B[38;5;241m=\u001B[39mhost_offload):\n\u001B[0;32m     64\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m dispatch_by_obj(obj, func, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m---> 65\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m dispatch_by_obj(obj, func, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\daal4py\\sklearn\\_device_offload.py:53\u001B[0m, in \u001B[0;36m_run_on_device.<locals>.dispatch_by_obj\u001B[1;34m(obj, func, *args, **kwargs)\u001B[0m\n\u001B[0;32m     51\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdispatch_by_obj\u001B[39m(obj, func, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m     52\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m obj \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m---> 53\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m func(obj, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     54\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\daal4py\\sklearn\\ensemble\\_forest.py:1029\u001B[0m, in \u001B[0;36mRandomForestRegressor.fit\u001B[1;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[0;32m   1002\u001B[0m \u001B[38;5;129m@support_usm_ndarray\u001B[39m()\n\u001B[0;32m   1003\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfit\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, y, sample_weight\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m   1004\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1005\u001B[0m \u001B[38;5;124;03m    Build a forest of trees from the training set (X, y).\u001B[39;00m\n\u001B[0;32m   1006\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1027\u001B[0m \u001B[38;5;124;03m    self : object\u001B[39;00m\n\u001B[0;32m   1028\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 1029\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _fit_regressor(\u001B[38;5;28mself\u001B[39m, X, y, sample_weight\u001B[38;5;241m=\u001B[39msample_weight)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\daal4py\\sklearn\\ensemble\\_forest.py:538\u001B[0m, in \u001B[0;36m_fit_regressor\u001B[1;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[0;32m    536\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m sklearn_check_version(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m1.2\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m    537\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_estimator \u001B[38;5;241m=\u001B[39m DecisionTreeRegressor()\n\u001B[1;32m--> 538\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mestimators_ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_estimators_\n\u001B[0;32m    539\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n\u001B[0;32m    540\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m(RandomForestRegressor, \u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39mfit(\n\u001B[0;32m    541\u001B[0m     X, y, sample_weight\u001B[38;5;241m=\u001B[39msample_weight)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\daal4py\\sklearn\\ensemble\\_forest.py:1135\u001B[0m, in \u001B[0;36mRandomForestRegressor._estimators_\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1126\u001B[0m     tree_i_state_dict \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m   1127\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmax_depth\u001B[39m\u001B[38;5;124m'\u001B[39m: tree_i_state_class\u001B[38;5;241m.\u001B[39mmax_depth,\n\u001B[0;32m   1128\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnode_count\u001B[39m\u001B[38;5;124m'\u001B[39m: tree_i_state_class\u001B[38;5;241m.\u001B[39mnode_count,\n\u001B[0;32m   1129\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnodes\u001B[39m\u001B[38;5;124m'\u001B[39m: tree_i_state_class\u001B[38;5;241m.\u001B[39mnode_ar,\n\u001B[0;32m   1130\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mvalues\u001B[39m\u001B[38;5;124m'\u001B[39m: tree_i_state_class\u001B[38;5;241m.\u001B[39mvalue_ar}\n\u001B[0;32m   1132\u001B[0m     est_i\u001B[38;5;241m.\u001B[39mtree_ \u001B[38;5;241m=\u001B[39m Tree(\n\u001B[0;32m   1133\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_features_in_, np\u001B[38;5;241m.\u001B[39marray(\n\u001B[0;32m   1134\u001B[0m             [\u001B[38;5;241m1\u001B[39m], dtype\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39mintp), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_outputs_)\n\u001B[1;32m-> 1135\u001B[0m     est_i\u001B[38;5;241m.\u001B[39mtree_\u001B[38;5;241m.\u001B[39m__setstate__(tree_i_state_dict)\n\u001B[0;32m   1136\u001B[0m     estimators_\u001B[38;5;241m.\u001B[39mappend(est_i)\n\u001B[0;32m   1138\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m estimators_\n",
      "File \u001B[1;32msklearn\\tree\\_tree.pyx:714\u001B[0m, in \u001B[0;36msklearn.tree._tree.Tree.__setstate__\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32msklearn\\tree\\_tree.pyx:1418\u001B[0m, in \u001B[0;36msklearn.tree._tree._check_node_ndarray\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: node array from the pickle has an incompatible dtype:\n- expected: {'names': ['left_child', 'right_child', 'feature', 'threshold', 'impurity', 'n_node_samples', 'weighted_n_node_samples', 'missing_go_to_left'], 'formats': ['<i8', '<i8', '<i8', '<f8', '<f8', '<i8', '<f8', 'u1'], 'offsets': [0, 8, 16, 24, 32, 40, 48, 56], 'itemsize': 64}\n- got     : [('left_child', '<i8'), ('right_child', '<i8'), ('feature', '<i8'), ('threshold', '<f8'), ('impurity', '<f8'), ('n_node_samples', '<i8'), ('weighted_n_node_samples', '<f8')]"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# num = 750\n",
    "saved = 0\n",
    "scores_test = []\n",
    "scores_train = []\n",
    "# randomforest 59  n_esti 750 \n",
    "# knn 59 n_neighbors = 5\n",
    "\n",
    "# for num in range(1,300):\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features, \n",
    "    target, \n",
    "    test_size=0.2, \n",
    "    random_state=59\n",
    ")\n",
    "\n",
    "scalerList = [\n",
    "        ('RBscaler', RobustScaler()),\n",
    "        ('stdScaler', StandardScaler()),\n",
    "        ('scalerZ', QuantileTransformer(output_distribution='normal')),\n",
    "]\n",
    "\n",
    "regressionList = [\n",
    "        ('KNN', KNeighborsRegressor(n_neighbors=3)),\n",
    "        ('linear', LinearRegression()),\n",
    "        ('randomForest', RandomForestRegressor(n_estimators=750)),\n",
    "        ('SVM', SVR(C=399)),\n",
    "]\n",
    "\n",
    "\n",
    "def trainData(scaler, regression):\n",
    "        model = Pipeline(\n",
    "        [\n",
    "        scaler,\n",
    "        ('poly', PolynomialFeatures(\n",
    "            degree=3,\n",
    "            interaction_only=True,\n",
    "            include_bias=False,\n",
    "            )\n",
    "        ),\n",
    "        regression\n",
    "        ]\n",
    "        )\n",
    "        model.fit(X_train, y_train)\n",
    "        from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "        y_pred = model.predict(X_test)\n",
    "        score = r2_score(y_test, y_pred)\n",
    "        print(scaler[0], regression[0], end=' ')\n",
    "        # print(f'Mean Squared Error: {mean_squared_error(y_test, y_pred, squared=False):.2f}')\n",
    "        # print(f'Mean Absolute Error: {mean_absolute_error(y_test, y_pred):.2f}')\n",
    "        print(f'R2 Score: {score:.4f}')\n",
    "        \n",
    "for regression in regressionList:\n",
    "        for scaler in scalerList:\n",
    "                trainData(scaler, regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-28T12:42:19.737809500Z",
     "start_time": "2024-02-28T12:42:19.736811400Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# for num in range(1,2):\n",
    "model = Pipeline(\n",
    "    [\n",
    "        # ('RBscaler', RobustScaler()),\n",
    "        ('stdScaler', StandardScaler()),\n",
    "        # ('scalerZ', QuantileTransformer(output_distribution='normal')),\n",
    "        ('poly', PolynomialFeatures(\n",
    "            degree=3,\n",
    "            interaction_only=True,\n",
    "            include_bias=False,\n",
    "            )\n",
    "        ),\n",
    "        # ('KNN', KNeighborsRegressor(n_neighbors=3)),\n",
    "        ('linear', LinearRegression()),\n",
    "        # ('randomForest', RandomForestRegressor(n_estimators=750)),\n",
    "        # ('SVM', SVR(C=399)),\n",
    "        \n",
    "    ]\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "score = r2_score(y_test, y_pred)\n",
    "print(f'Mean Squared Error: {mean_squared_error(y_test, y_pred, squared=False):.2f}')\n",
    "print(f'Mean Absolute Error: {mean_absolute_error(y_test, y_pred):.2f}')\n",
    "print(f'R2 Score: {score:.4f}')\n",
    "# if saved < score:\n",
    "#     saved = score\n",
    "#     saved_num = num\n",
    "\n",
    "scores_train.append(model.score(X_train, y_train))\n",
    "scores_test.append(model.score(X_test, y_test))\n",
    "# print(f'Best num: {saved_num}, Best score: {saved}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-28T12:42:19.737809500Z",
     "start_time": "2024-02-28T12:42:19.737809500Z"
    }
   },
   "outputs": [],
   "source": [
    "# plt.plot(range(len(scores_train)), scores_train, label='Training Score')\n",
    "# plt.plot(range(len(scores_test)), scores_test, label='Test Score')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-28T12:42:19.738805900Z"
    }
   },
   "outputs": [],
   "source": [
    "# for idx, data in enumerate(scores_train):\n",
    "#     tmp = scores_test[idx] - data\n",
    "#     print(tmp, idx)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EXAM_ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
