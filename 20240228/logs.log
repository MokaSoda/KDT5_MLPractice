2024-02-28 22:05:56,506:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:05:56,506:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:05:56,506:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:05:56,506:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:05:56,583:INFO:PyCaret RegressionExperiment
2024-02-28 22:05:56,583:INFO:Logging name: reg-default-name
2024-02-28 22:05:56,583:INFO:ML Usecase: MLUsecase.REGRESSION
2024-02-28 22:05:56,583:INFO:version 3.3.0
2024-02-28 22:05:56,583:INFO:Initializing setup()
2024-02-28 22:05:56,583:INFO:self.USI: 2ca0
2024-02-28 22:05:56,583:INFO:self._variable_keys: {'memory', 'seed', 'fold_generator', 'exp_name_log', 'html_param', '_ml_usecase', 'gpu_n_jobs_param', 'fold_shuffle_param', 'X_train', 'logging_param', 'y_test', 'transform_target_param', 'X_test', 'idx', 'pipeline', 'y_train', 'data', 'gpu_param', '_available_plots', 'n_jobs_param', 'exp_id', 'y', 'X', 'fold_groups_param', 'USI', 'log_plots_param', 'target_param'}
2024-02-28 22:05:56,583:INFO:Checking environment
2024-02-28 22:05:56,583:INFO:python_version: 3.9.18
2024-02-28 22:05:56,583:INFO:python_build: ('main', 'Dec 23 2023 16:29:04')
2024-02-28 22:05:56,583:INFO:machine: AMD64
2024-02-28 22:05:56,583:INFO:platform: Windows-10-10.0.22621-SP0
2024-02-28 22:05:56,583:INFO:Memory: svmem(total=34228445184, available=22235508736, percent=35.0, used=11992936448, free=22235508736)
2024-02-28 22:05:56,583:INFO:Physical Core: 8
2024-02-28 22:05:56,583:INFO:Logical Core: 16
2024-02-28 22:05:56,583:INFO:Checking libraries
2024-02-28 22:05:56,583:INFO:System:
2024-02-28 22:05:56,583:INFO:    python: 3.9.18 | packaged by conda-forge | (main, Dec 23 2023, 16:29:04) [MSC v.1929 64 bit (AMD64)]
2024-02-28 22:05:56,583:INFO:executable: c:\Users\Administrator\anaconda3\envs\EXAM_ML\python.exe
2024-02-28 22:05:56,583:INFO:   machine: Windows-10-10.0.22621-SP0
2024-02-28 22:05:56,583:INFO:PyCaret required dependencies:
2024-02-28 22:05:56,951:INFO:                 pip: 24.0
2024-02-28 22:05:56,951:INFO:          setuptools: 69.1.1
2024-02-28 22:05:56,951:INFO:             pycaret: 3.3.0
2024-02-28 22:05:56,951:INFO:             IPython: 8.12.0
2024-02-28 22:05:56,951:INFO:          ipywidgets: 8.1.2
2024-02-28 22:05:56,951:INFO:                tqdm: 4.66.2
2024-02-28 22:05:56,951:INFO:               numpy: 1.25.2
2024-02-28 22:05:56,951:INFO:              pandas: 1.5.3
2024-02-28 22:05:56,951:INFO:              jinja2: 3.1.3
2024-02-28 22:05:56,951:INFO:               scipy: 1.11.4
2024-02-28 22:05:56,951:INFO:              joblib: 1.3.2
2024-02-28 22:05:56,951:INFO:             sklearn: 1.4.1.post1
2024-02-28 22:05:56,951:INFO:                pyod: 1.1.3
2024-02-28 22:05:56,951:INFO:            imblearn: 0.12.0
2024-02-28 22:05:56,951:INFO:   category_encoders: 2.6.3
2024-02-28 22:05:56,951:INFO:            lightgbm: 4.3.0
2024-02-28 22:05:56,951:INFO:               numba: 0.58.1
2024-02-28 22:05:56,951:INFO:            requests: 2.31.0
2024-02-28 22:05:56,951:INFO:          matplotlib: 3.7.5
2024-02-28 22:05:56,951:INFO:          scikitplot: 0.3.7
2024-02-28 22:05:56,951:INFO:         yellowbrick: 1.5
2024-02-28 22:05:56,951:INFO:              plotly: 5.19.0
2024-02-28 22:05:56,951:INFO:    plotly-resampler: Not installed
2024-02-28 22:05:56,952:INFO:             kaleido: 0.2.1
2024-02-28 22:05:56,952:INFO:           schemdraw: 0.15
2024-02-28 22:05:56,952:INFO:         statsmodels: 0.14.1
2024-02-28 22:05:56,952:INFO:              sktime: 0.27.0
2024-02-28 22:05:56,952:INFO:               tbats: 1.1.3
2024-02-28 22:05:56,952:INFO:            pmdarima: 2.0.4
2024-02-28 22:05:56,952:INFO:              psutil: 5.9.8
2024-02-28 22:05:56,952:INFO:          markupsafe: 2.1.5
2024-02-28 22:05:56,952:INFO:             pickle5: Not installed
2024-02-28 22:05:56,952:INFO:         cloudpickle: 3.0.0
2024-02-28 22:05:56,952:INFO:         deprecation: 2.1.0
2024-02-28 22:05:56,952:INFO:              xxhash: 3.4.1
2024-02-28 22:05:56,952:INFO:           wurlitzer: Not installed
2024-02-28 22:05:56,952:INFO:PyCaret optional dependencies:
2024-02-28 22:05:58,860:INFO:                shap: 0.44.1
2024-02-28 22:05:58,860:INFO:           interpret: 0.5.1
2024-02-28 22:05:58,860:INFO:                umap: 0.5.5
2024-02-28 22:05:58,860:INFO:     ydata_profiling: 4.6.5
2024-02-28 22:05:58,860:INFO:  explainerdashboard: 0.4.5
2024-02-28 22:05:58,860:INFO:             autoviz: Not installed
2024-02-28 22:05:58,860:INFO:           fairlearn: 0.7.0
2024-02-28 22:05:58,860:INFO:          deepchecks: Not installed
2024-02-28 22:05:58,860:INFO:             xgboost: 2.0.3
2024-02-28 22:05:58,860:INFO:            catboost: 1.2.3
2024-02-28 22:05:58,860:INFO:              kmodes: 0.12.2
2024-02-28 22:05:58,860:INFO:             mlxtend: 0.23.1
2024-02-28 22:05:58,860:INFO:       statsforecast: 1.5.0
2024-02-28 22:05:58,860:INFO:        tune_sklearn: 0.5.0
2024-02-28 22:05:58,860:INFO:                 ray: 2.9.3
2024-02-28 22:05:58,860:INFO:            hyperopt: 0.2.7
2024-02-28 22:05:58,860:INFO:              optuna: 3.5.0
2024-02-28 22:05:58,860:INFO:               skopt: 0.9.0
2024-02-28 22:05:58,860:INFO:              mlflow: 2.10.2
2024-02-28 22:05:58,860:INFO:              gradio: 4.19.2
2024-02-28 22:05:58,860:INFO:             fastapi: 0.110.0
2024-02-28 22:05:58,860:INFO:             uvicorn: 0.27.1
2024-02-28 22:05:58,860:INFO:              m2cgen: 0.10.0
2024-02-28 22:05:58,860:INFO:           evidently: 0.4.16
2024-02-28 22:05:58,860:INFO:               fugue: 0.8.6
2024-02-28 22:05:58,860:INFO:           streamlit: Not installed
2024-02-28 22:05:58,860:INFO:             prophet: Not installed
2024-02-28 22:05:58,860:INFO:None
2024-02-28 22:05:58,860:INFO:Set up data.
2024-02-28 22:05:58,868:INFO:Set up folding strategy.
2024-02-28 22:05:58,868:INFO:Set up train/test split.
2024-02-28 22:05:58,906:INFO:Set up index.
2024-02-28 22:05:58,906:INFO:Assigning column types.
2024-02-28 22:05:58,906:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-02-28 22:05:58,906:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-02-28 22:05:58,906:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-02-28 22:05:58,914:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-02-28 22:05:58,952:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-02-28 22:05:58,983:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-28 22:05:58,983:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:05:58,983:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:05:58,998:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-02-28 22:05:59,006:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-02-28 22:05:59,006:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-02-28 22:05:59,044:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-02-28 22:05:59,075:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-28 22:05:59,075:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:05:59,075:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:05:59,075:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-02-28 22:05:59,083:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-02-28 22:05:59,083:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-02-28 22:05:59,121:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-02-28 22:05:59,152:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-28 22:05:59,152:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:05:59,152:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:05:59,160:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-02-28 22:05:59,160:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-02-28 22:05:59,204:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-02-28 22:05:59,229:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-28 22:05:59,229:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:05:59,237:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:05:59,237:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-02-28 22:05:59,244:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-02-28 22:05:59,282:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-02-28 22:05:59,309:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-28 22:05:59,313:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:05:59,314:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:05:59,321:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-02-28 22:05:59,360:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-02-28 22:05:59,390:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-28 22:05:59,390:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:05:59,390:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:05:59,390:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-02-28 22:05:59,437:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-02-28 22:05:59,467:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-28 22:05:59,467:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:05:59,467:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:05:59,515:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-02-28 22:05:59,544:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-28 22:05:59,544:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:05:59,544:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:05:59,544:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-02-28 22:05:59,591:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-02-28 22:05:59,623:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:05:59,624:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:05:59,667:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-02-28 22:05:59,698:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:05:59,706:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:05:59,706:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-02-28 22:05:59,775:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:05:59,783:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:05:59,852:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:05:59,860:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:05:59,860:INFO:Preparing preprocessing pipeline...
2024-02-28 22:05:59,860:INFO:Set up simple imputation.
2024-02-28 22:05:59,867:INFO:Finished creating preprocessing pipeline.
2024-02-28 22:05:59,875:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['cylinders', 'displacement',
                                             'horsepower', 'weight',
                                             'acceleration'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2024-02-28 22:05:59,875:INFO:Creating final display dataframe.
2024-02-28 22:05:59,906:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target               mpg
2                   Target type        Regression
3           Original data shape          (392, 6)
4        Transformed data shape          (392, 6)
5   Transformed train set shape          (274, 6)
6    Transformed test set shape          (118, 6)
7              Numeric features                 5
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              2ca0
2024-02-28 22:05:59,991:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:05:59,991:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:06:00,067:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:06:00,067:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:06:00,067:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\internal\metrics.py:51: FutureWarning: The `needs_threshold` and `needs_proba` parameter are deprecated in version 1.4 and will be removed in 1.6. You can either let `response_method` be `None` or set it to `predict` to preserve the same behaviour.
  warnings.warn(

2024-02-28 22:06:00,067:INFO:setup() successfully completed in 3.48s...............
2024-02-28 22:06:13,397:INFO:PyCaret RegressionExperiment
2024-02-28 22:06:13,398:INFO:Logging name: reg-default-name
2024-02-28 22:06:13,398:INFO:ML Usecase: MLUsecase.REGRESSION
2024-02-28 22:06:13,398:INFO:version 3.3.0
2024-02-28 22:06:13,398:INFO:Initializing setup()
2024-02-28 22:06:13,398:INFO:self.USI: d436
2024-02-28 22:06:13,398:INFO:self._variable_keys: {'memory', 'seed', 'fold_generator', 'exp_name_log', 'html_param', '_ml_usecase', 'gpu_n_jobs_param', 'fold_shuffle_param', 'X_train', 'logging_param', 'y_test', 'transform_target_param', 'X_test', 'idx', 'pipeline', 'y_train', 'data', 'gpu_param', '_available_plots', 'n_jobs_param', 'exp_id', 'y', 'X', 'fold_groups_param', 'USI', 'log_plots_param', 'target_param'}
2024-02-28 22:06:13,398:INFO:Checking environment
2024-02-28 22:06:13,398:INFO:python_version: 3.9.18
2024-02-28 22:06:13,398:INFO:python_build: ('main', 'Dec 23 2023 16:29:04')
2024-02-28 22:06:13,398:INFO:machine: AMD64
2024-02-28 22:06:13,398:INFO:platform: Windows-10-10.0.22621-SP0
2024-02-28 22:06:13,398:INFO:Memory: svmem(total=34228445184, available=22149578752, percent=35.3, used=12078866432, free=22149578752)
2024-02-28 22:06:13,398:INFO:Physical Core: 8
2024-02-28 22:06:13,398:INFO:Logical Core: 16
2024-02-28 22:06:13,398:INFO:Checking libraries
2024-02-28 22:06:13,398:INFO:System:
2024-02-28 22:06:13,398:INFO:    python: 3.9.18 | packaged by conda-forge | (main, Dec 23 2023, 16:29:04) [MSC v.1929 64 bit (AMD64)]
2024-02-28 22:06:13,398:INFO:executable: c:\Users\Administrator\anaconda3\envs\EXAM_ML\python.exe
2024-02-28 22:06:13,398:INFO:   machine: Windows-10-10.0.22621-SP0
2024-02-28 22:06:13,398:INFO:PyCaret required dependencies:
2024-02-28 22:06:13,398:INFO:                 pip: 24.0
2024-02-28 22:06:13,398:INFO:          setuptools: 69.1.1
2024-02-28 22:06:13,398:INFO:             pycaret: 3.3.0
2024-02-28 22:06:13,398:INFO:             IPython: 8.12.0
2024-02-28 22:06:13,398:INFO:          ipywidgets: 8.1.2
2024-02-28 22:06:13,398:INFO:                tqdm: 4.66.2
2024-02-28 22:06:13,398:INFO:               numpy: 1.25.2
2024-02-28 22:06:13,398:INFO:              pandas: 1.5.3
2024-02-28 22:06:13,398:INFO:              jinja2: 3.1.3
2024-02-28 22:06:13,398:INFO:               scipy: 1.11.4
2024-02-28 22:06:13,398:INFO:              joblib: 1.3.2
2024-02-28 22:06:13,398:INFO:             sklearn: 1.4.1.post1
2024-02-28 22:06:13,398:INFO:                pyod: 1.1.3
2024-02-28 22:06:13,398:INFO:            imblearn: 0.12.0
2024-02-28 22:06:13,398:INFO:   category_encoders: 2.6.3
2024-02-28 22:06:13,398:INFO:            lightgbm: 4.3.0
2024-02-28 22:06:13,398:INFO:               numba: 0.58.1
2024-02-28 22:06:13,398:INFO:            requests: 2.31.0
2024-02-28 22:06:13,398:INFO:          matplotlib: 3.7.5
2024-02-28 22:06:13,398:INFO:          scikitplot: 0.3.7
2024-02-28 22:06:13,398:INFO:         yellowbrick: 1.5
2024-02-28 22:06:13,398:INFO:              plotly: 5.19.0
2024-02-28 22:06:13,398:INFO:    plotly-resampler: Not installed
2024-02-28 22:06:13,401:INFO:             kaleido: 0.2.1
2024-02-28 22:06:13,401:INFO:           schemdraw: 0.15
2024-02-28 22:06:13,401:INFO:         statsmodels: 0.14.1
2024-02-28 22:06:13,401:INFO:              sktime: 0.27.0
2024-02-28 22:06:13,401:INFO:               tbats: 1.1.3
2024-02-28 22:06:13,401:INFO:            pmdarima: 2.0.4
2024-02-28 22:06:13,401:INFO:              psutil: 5.9.8
2024-02-28 22:06:13,401:INFO:          markupsafe: 2.1.5
2024-02-28 22:06:13,401:INFO:             pickle5: Not installed
2024-02-28 22:06:13,401:INFO:         cloudpickle: 3.0.0
2024-02-28 22:06:13,401:INFO:         deprecation: 2.1.0
2024-02-28 22:06:13,401:INFO:              xxhash: 3.4.1
2024-02-28 22:06:13,401:INFO:           wurlitzer: Not installed
2024-02-28 22:06:13,401:INFO:PyCaret optional dependencies:
2024-02-28 22:06:13,401:INFO:                shap: 0.44.1
2024-02-28 22:06:13,401:INFO:           interpret: 0.5.1
2024-02-28 22:06:13,401:INFO:                umap: 0.5.5
2024-02-28 22:06:13,401:INFO:     ydata_profiling: 4.6.5
2024-02-28 22:06:13,401:INFO:  explainerdashboard: 0.4.5
2024-02-28 22:06:13,401:INFO:             autoviz: Not installed
2024-02-28 22:06:13,401:INFO:           fairlearn: 0.7.0
2024-02-28 22:06:13,401:INFO:          deepchecks: Not installed
2024-02-28 22:06:13,401:INFO:             xgboost: 2.0.3
2024-02-28 22:06:13,401:INFO:            catboost: 1.2.3
2024-02-28 22:06:13,401:INFO:              kmodes: 0.12.2
2024-02-28 22:06:13,401:INFO:             mlxtend: 0.23.1
2024-02-28 22:06:13,401:INFO:       statsforecast: 1.5.0
2024-02-28 22:06:13,401:INFO:        tune_sklearn: 0.5.0
2024-02-28 22:06:13,401:INFO:                 ray: 2.9.3
2024-02-28 22:06:13,401:INFO:            hyperopt: 0.2.7
2024-02-28 22:06:13,401:INFO:              optuna: 3.5.0
2024-02-28 22:06:13,401:INFO:               skopt: 0.9.0
2024-02-28 22:06:13,401:INFO:              mlflow: 2.10.2
2024-02-28 22:06:13,401:INFO:              gradio: 4.19.2
2024-02-28 22:06:13,401:INFO:             fastapi: 0.110.0
2024-02-28 22:06:13,401:INFO:             uvicorn: 0.27.1
2024-02-28 22:06:13,401:INFO:              m2cgen: 0.10.0
2024-02-28 22:06:13,401:INFO:           evidently: 0.4.16
2024-02-28 22:06:13,401:INFO:               fugue: 0.8.6
2024-02-28 22:06:13,401:INFO:           streamlit: Not installed
2024-02-28 22:06:13,401:INFO:             prophet: Not installed
2024-02-28 22:06:13,401:INFO:None
2024-02-28 22:06:13,401:INFO:Set up GPU usage.
2024-02-28 22:06:13,401:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:06:13,401:WARNING:cuML is outdated or not found. Required version is >=23.08.
                Please visit https://rapids.ai/install for installation instructions.
2024-02-28 22:06:13,401:INFO:Set up data.
2024-02-28 22:06:13,401:INFO:Set up folding strategy.
2024-02-28 22:06:13,401:INFO:Set up train/test split.
2024-02-28 22:06:13,401:INFO:Set up index.
2024-02-28 22:06:13,401:INFO:Assigning column types.
2024-02-28 22:06:13,401:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-02-28 22:06:13,401:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:06:13,401:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-02-28 22:06:13,401:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:06:13,414:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-02-28 22:06:13,414:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:06:13,417:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-02-28 22:06:13,417:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:06:13,455:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-02-28 22:06:13,455:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:06:13,483:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-28 22:06:13,483:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:06:13,483:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:06:13,483:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:06:16,399:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:06:16,399:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:06:16,399:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-02-28 22:06:16,399:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:06:16,415:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-02-28 22:06:16,415:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:06:16,415:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-02-28 22:06:16,415:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:06:16,444:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-02-28 22:06:16,444:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:06:16,485:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-28 22:06:16,485:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:06:16,485:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:06:16,485:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:06:16,585:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:06:16,585:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-02-28 22:06:16,585:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:06:16,585:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:06:16,585:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-02-28 22:06:16,585:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:06:16,585:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-02-28 22:06:16,585:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:06:16,644:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-02-28 22:06:16,644:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:06:16,684:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-28 22:06:16,684:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:06:16,684:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:06:16,684:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:06:16,776:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:06:16,776:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:06:16,776:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:06:16,792:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-02-28 22:06:16,792:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:06:16,793:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-02-28 22:06:16,793:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:06:16,844:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-02-28 22:06:16,844:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:06:16,890:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-28 22:06:16,890:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:06:16,890:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:06:16,890:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:06:16,984:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:06:16,984:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-02-28 22:06:16,984:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:06:16,984:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:06:16,984:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:06:16,984:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-02-28 22:06:16,984:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:06:17,040:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-02-28 22:06:17,040:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:06:17,071:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-28 22:06:17,071:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:06:17,071:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:06:17,071:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:06:17,160:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:06:17,160:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:06:17,160:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:06:17,160:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:06:17,160:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-02-28 22:06:17,160:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:06:17,206:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-02-28 22:06:17,206:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:06:17,231:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-28 22:06:17,231:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:06:17,231:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:06:17,231:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:06:17,338:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:06:17,338:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-02-28 22:06:17,338:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:06:17,338:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:06:17,347:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:06:17,347:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:06:17,400:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-02-28 22:06:17,400:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:06:17,437:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-28 22:06:17,437:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:06:17,437:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:06:17,437:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:06:17,524:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:06:17,524:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:06:17,524:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:06:17,524:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:06:17,544:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:06:17,591:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-02-28 22:06:17,591:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:06:17,631:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-28 22:06:17,631:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:06:17,631:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:06:17,631:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:06:17,729:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:06:17,729:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-02-28 22:06:17,729:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:06:17,729:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:06:17,729:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:06:17,739:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:06:17,770:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-02-28 22:06:17,770:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:06:17,806:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:06:17,806:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:06:17,806:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:06:17,895:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:06:17,895:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:06:17,895:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:06:17,895:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:06:17,895:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:06:17,954:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-02-28 22:06:17,954:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:06:17,983:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:06:17,983:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:06:17,983:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:06:18,063:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:06:18,063:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-02-28 22:06:18,063:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:06:18,063:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:06:18,078:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:06:18,078:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:06:18,110:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:06:18,141:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:06:18,141:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:06:18,141:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:06:18,229:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:06:18,229:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:06:18,229:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:06:18,229:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:06:18,245:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:06:18,301:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:06:18,333:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:06:18,333:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:06:18,333:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:06:18,444:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:06:18,444:INFO:Preparing preprocessing pipeline...
2024-02-28 22:06:18,444:INFO:Set up simple imputation.
2024-02-28 22:06:18,452:INFO:Finished creating preprocessing pipeline.
2024-02-28 22:06:18,452:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['cylinders', 'displacement',
                                             'horsepower', 'weight',
                                             'acceleration'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2024-02-28 22:06:18,452:INFO:Creating final display dataframe.
2024-02-28 22:06:18,493:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target               mpg
2                   Target type        Regression
3           Original data shape          (392, 6)
4        Transformed data shape          (392, 6)
5   Transformed train set shape          (274, 6)
6    Transformed test set shape          (118, 6)
7              Numeric features                 5
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU              True
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              d436
2024-02-28 22:06:18,493:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:06:18,493:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:06:18,509:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:06:18,509:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:06:18,560:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:06:18,583:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:06:18,583:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:06:18,583:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:06:18,683:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:06:18,683:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:06:18,683:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:06:18,683:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:06:18,695:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:06:18,732:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:06:18,775:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:06:18,775:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:06:18,775:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:06:18,865:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:06:18,866:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\internal\metrics.py:51: FutureWarning: The `needs_threshold` and `needs_proba` parameter are deprecated in version 1.4 and will be removed in 1.6. You can either let `response_method` be `None` or set it to `predict` to preserve the same behaviour.
  warnings.warn(

2024-02-28 22:06:18,866:INFO:setup() successfully completed in 5.47s...............
2024-02-28 22:07:36,597:INFO:PyCaret RegressionExperiment
2024-02-28 22:07:36,597:INFO:Logging name: reg-default-name
2024-02-28 22:07:36,597:INFO:ML Usecase: MLUsecase.REGRESSION
2024-02-28 22:07:36,597:INFO:version 3.3.0
2024-02-28 22:07:36,597:INFO:Initializing setup()
2024-02-28 22:07:36,597:INFO:self.USI: 7798
2024-02-28 22:07:36,597:INFO:self._variable_keys: {'memory', 'seed', 'fold_generator', 'exp_name_log', 'html_param', '_ml_usecase', 'gpu_n_jobs_param', 'fold_shuffle_param', 'X_train', 'logging_param', 'y_test', 'transform_target_param', 'X_test', 'idx', 'pipeline', 'y_train', 'data', 'gpu_param', '_available_plots', 'n_jobs_param', 'exp_id', 'y', 'X', 'fold_groups_param', 'USI', 'log_plots_param', 'target_param'}
2024-02-28 22:07:36,597:INFO:Checking environment
2024-02-28 22:07:36,597:INFO:python_version: 3.9.18
2024-02-28 22:07:36,597:INFO:python_build: ('main', 'Dec 23 2023 16:29:04')
2024-02-28 22:07:36,597:INFO:machine: AMD64
2024-02-28 22:07:36,597:INFO:platform: Windows-10-10.0.22621-SP0
2024-02-28 22:07:36,599:INFO:Memory: svmem(total=34228445184, available=22037671936, percent=35.6, used=12190773248, free=22037671936)
2024-02-28 22:07:36,599:INFO:Physical Core: 8
2024-02-28 22:07:36,599:INFO:Logical Core: 16
2024-02-28 22:07:36,599:INFO:Checking libraries
2024-02-28 22:07:36,599:INFO:System:
2024-02-28 22:07:36,599:INFO:    python: 3.9.18 | packaged by conda-forge | (main, Dec 23 2023, 16:29:04) [MSC v.1929 64 bit (AMD64)]
2024-02-28 22:07:36,599:INFO:executable: c:\Users\Administrator\anaconda3\envs\EXAM_ML\python.exe
2024-02-28 22:07:36,599:INFO:   machine: Windows-10-10.0.22621-SP0
2024-02-28 22:07:36,599:INFO:PyCaret required dependencies:
2024-02-28 22:07:36,600:INFO:                 pip: 24.0
2024-02-28 22:07:36,600:INFO:          setuptools: 69.1.1
2024-02-28 22:07:36,600:INFO:             pycaret: 3.3.0
2024-02-28 22:07:36,600:INFO:             IPython: 8.12.0
2024-02-28 22:07:36,600:INFO:          ipywidgets: 8.1.2
2024-02-28 22:07:36,600:INFO:                tqdm: 4.66.2
2024-02-28 22:07:36,600:INFO:               numpy: 1.25.2
2024-02-28 22:07:36,600:INFO:              pandas: 1.5.3
2024-02-28 22:07:36,600:INFO:              jinja2: 3.1.3
2024-02-28 22:07:36,600:INFO:               scipy: 1.11.4
2024-02-28 22:07:36,600:INFO:              joblib: 1.3.2
2024-02-28 22:07:36,600:INFO:             sklearn: 1.4.1.post1
2024-02-28 22:07:36,600:INFO:                pyod: 1.1.3
2024-02-28 22:07:36,600:INFO:            imblearn: 0.12.0
2024-02-28 22:07:36,600:INFO:   category_encoders: 2.6.3
2024-02-28 22:07:36,600:INFO:            lightgbm: 4.3.0
2024-02-28 22:07:36,600:INFO:               numba: 0.58.1
2024-02-28 22:07:36,600:INFO:            requests: 2.31.0
2024-02-28 22:07:36,600:INFO:          matplotlib: 3.7.5
2024-02-28 22:07:36,600:INFO:          scikitplot: 0.3.7
2024-02-28 22:07:36,600:INFO:         yellowbrick: 1.5
2024-02-28 22:07:36,600:INFO:              plotly: 5.19.0
2024-02-28 22:07:36,600:INFO:    plotly-resampler: Not installed
2024-02-28 22:07:36,600:INFO:             kaleido: 0.2.1
2024-02-28 22:07:36,600:INFO:           schemdraw: 0.15
2024-02-28 22:07:36,600:INFO:         statsmodels: 0.14.1
2024-02-28 22:07:36,600:INFO:              sktime: 0.27.0
2024-02-28 22:07:36,600:INFO:               tbats: 1.1.3
2024-02-28 22:07:36,600:INFO:            pmdarima: 2.0.4
2024-02-28 22:07:36,600:INFO:              psutil: 5.9.8
2024-02-28 22:07:36,600:INFO:          markupsafe: 2.1.5
2024-02-28 22:07:36,601:INFO:             pickle5: Not installed
2024-02-28 22:07:36,601:INFO:         cloudpickle: 3.0.0
2024-02-28 22:07:36,601:INFO:         deprecation: 2.1.0
2024-02-28 22:07:36,601:INFO:              xxhash: 3.4.1
2024-02-28 22:07:36,601:INFO:           wurlitzer: Not installed
2024-02-28 22:07:36,601:INFO:PyCaret optional dependencies:
2024-02-28 22:07:36,601:INFO:                shap: 0.44.1
2024-02-28 22:07:36,601:INFO:           interpret: 0.5.1
2024-02-28 22:07:36,602:INFO:                umap: 0.5.5
2024-02-28 22:07:36,602:INFO:     ydata_profiling: 4.6.5
2024-02-28 22:07:36,602:INFO:  explainerdashboard: 0.4.5
2024-02-28 22:07:36,602:INFO:             autoviz: Not installed
2024-02-28 22:07:36,602:INFO:           fairlearn: 0.7.0
2024-02-28 22:07:36,602:INFO:          deepchecks: Not installed
2024-02-28 22:07:36,602:INFO:             xgboost: 2.0.3
2024-02-28 22:07:36,602:INFO:            catboost: 1.2.3
2024-02-28 22:07:36,602:INFO:              kmodes: 0.12.2
2024-02-28 22:07:36,602:INFO:             mlxtend: 0.23.1
2024-02-28 22:07:36,602:INFO:       statsforecast: 1.5.0
2024-02-28 22:07:36,602:INFO:        tune_sklearn: 0.5.0
2024-02-28 22:07:36,602:INFO:                 ray: 2.9.3
2024-02-28 22:07:36,602:INFO:            hyperopt: 0.2.7
2024-02-28 22:07:36,602:INFO:              optuna: 3.5.0
2024-02-28 22:07:36,602:INFO:               skopt: 0.9.0
2024-02-28 22:07:36,602:INFO:              mlflow: 2.10.2
2024-02-28 22:07:36,602:INFO:              gradio: 4.19.2
2024-02-28 22:07:36,602:INFO:             fastapi: 0.110.0
2024-02-28 22:07:36,602:INFO:             uvicorn: 0.27.1
2024-02-28 22:07:36,602:INFO:              m2cgen: 0.10.0
2024-02-28 22:07:36,602:INFO:           evidently: 0.4.16
2024-02-28 22:07:36,602:INFO:               fugue: 0.8.6
2024-02-28 22:07:36,602:INFO:           streamlit: Not installed
2024-02-28 22:07:36,602:INFO:             prophet: Not installed
2024-02-28 22:07:36,602:INFO:None
2024-02-28 22:07:36,602:INFO:Set up data.
2024-02-28 22:07:41,980:INFO:PyCaret RegressionExperiment
2024-02-28 22:07:41,980:INFO:Logging name: reg-default-name
2024-02-28 22:07:41,980:INFO:ML Usecase: MLUsecase.REGRESSION
2024-02-28 22:07:41,980:INFO:version 3.3.0
2024-02-28 22:07:41,980:INFO:Initializing setup()
2024-02-28 22:07:41,980:INFO:self.USI: bed6
2024-02-28 22:07:41,980:INFO:self._variable_keys: {'memory', 'seed', 'fold_generator', 'exp_name_log', 'html_param', '_ml_usecase', 'gpu_n_jobs_param', 'fold_shuffle_param', 'X_train', 'logging_param', 'y_test', 'transform_target_param', 'X_test', 'idx', 'pipeline', 'y_train', 'data', 'gpu_param', '_available_plots', 'n_jobs_param', 'exp_id', 'y', 'X', 'fold_groups_param', 'USI', 'log_plots_param', 'target_param'}
2024-02-28 22:07:41,980:INFO:Checking environment
2024-02-28 22:07:41,980:INFO:python_version: 3.9.18
2024-02-28 22:07:41,980:INFO:python_build: ('main', 'Dec 23 2023 16:29:04')
2024-02-28 22:07:41,980:INFO:machine: AMD64
2024-02-28 22:07:41,980:INFO:platform: Windows-10-10.0.22621-SP0
2024-02-28 22:07:41,980:INFO:Memory: svmem(total=34228445184, available=22029250560, percent=35.6, used=12199194624, free=22029250560)
2024-02-28 22:07:41,980:INFO:Physical Core: 8
2024-02-28 22:07:41,980:INFO:Logical Core: 16
2024-02-28 22:07:41,980:INFO:Checking libraries
2024-02-28 22:07:41,980:INFO:System:
2024-02-28 22:07:41,980:INFO:    python: 3.9.18 | packaged by conda-forge | (main, Dec 23 2023, 16:29:04) [MSC v.1929 64 bit (AMD64)]
2024-02-28 22:07:41,980:INFO:executable: c:\Users\Administrator\anaconda3\envs\EXAM_ML\python.exe
2024-02-28 22:07:41,980:INFO:   machine: Windows-10-10.0.22621-SP0
2024-02-28 22:07:41,980:INFO:PyCaret required dependencies:
2024-02-28 22:07:41,980:INFO:                 pip: 24.0
2024-02-28 22:07:41,980:INFO:          setuptools: 69.1.1
2024-02-28 22:07:41,980:INFO:             pycaret: 3.3.0
2024-02-28 22:07:41,980:INFO:             IPython: 8.12.0
2024-02-28 22:07:41,980:INFO:          ipywidgets: 8.1.2
2024-02-28 22:07:41,980:INFO:                tqdm: 4.66.2
2024-02-28 22:07:41,980:INFO:               numpy: 1.25.2
2024-02-28 22:07:41,980:INFO:              pandas: 1.5.3
2024-02-28 22:07:41,980:INFO:              jinja2: 3.1.3
2024-02-28 22:07:41,980:INFO:               scipy: 1.11.4
2024-02-28 22:07:41,980:INFO:              joblib: 1.3.2
2024-02-28 22:07:41,980:INFO:             sklearn: 1.4.1.post1
2024-02-28 22:07:41,980:INFO:                pyod: 1.1.3
2024-02-28 22:07:41,980:INFO:            imblearn: 0.12.0
2024-02-28 22:07:41,980:INFO:   category_encoders: 2.6.3
2024-02-28 22:07:41,980:INFO:            lightgbm: 4.3.0
2024-02-28 22:07:41,980:INFO:               numba: 0.58.1
2024-02-28 22:07:41,980:INFO:            requests: 2.31.0
2024-02-28 22:07:41,980:INFO:          matplotlib: 3.7.5
2024-02-28 22:07:41,980:INFO:          scikitplot: 0.3.7
2024-02-28 22:07:41,980:INFO:         yellowbrick: 1.5
2024-02-28 22:07:41,980:INFO:              plotly: 5.19.0
2024-02-28 22:07:41,980:INFO:    plotly-resampler: Not installed
2024-02-28 22:07:41,980:INFO:             kaleido: 0.2.1
2024-02-28 22:07:41,980:INFO:           schemdraw: 0.15
2024-02-28 22:07:41,980:INFO:         statsmodels: 0.14.1
2024-02-28 22:07:41,980:INFO:              sktime: 0.27.0
2024-02-28 22:07:41,980:INFO:               tbats: 1.1.3
2024-02-28 22:07:41,980:INFO:            pmdarima: 2.0.4
2024-02-28 22:07:41,980:INFO:              psutil: 5.9.8
2024-02-28 22:07:41,980:INFO:          markupsafe: 2.1.5
2024-02-28 22:07:41,980:INFO:             pickle5: Not installed
2024-02-28 22:07:41,980:INFO:         cloudpickle: 3.0.0
2024-02-28 22:07:41,980:INFO:         deprecation: 2.1.0
2024-02-28 22:07:41,980:INFO:              xxhash: 3.4.1
2024-02-28 22:07:41,980:INFO:           wurlitzer: Not installed
2024-02-28 22:07:41,980:INFO:PyCaret optional dependencies:
2024-02-28 22:07:41,980:INFO:                shap: 0.44.1
2024-02-28 22:07:41,980:INFO:           interpret: 0.5.1
2024-02-28 22:07:41,984:INFO:                umap: 0.5.5
2024-02-28 22:07:41,984:INFO:     ydata_profiling: 4.6.5
2024-02-28 22:07:41,984:INFO:  explainerdashboard: 0.4.5
2024-02-28 22:07:41,984:INFO:             autoviz: Not installed
2024-02-28 22:07:41,984:INFO:           fairlearn: 0.7.0
2024-02-28 22:07:41,984:INFO:          deepchecks: Not installed
2024-02-28 22:07:41,984:INFO:             xgboost: 2.0.3
2024-02-28 22:07:41,984:INFO:            catboost: 1.2.3
2024-02-28 22:07:41,984:INFO:              kmodes: 0.12.2
2024-02-28 22:07:41,984:INFO:             mlxtend: 0.23.1
2024-02-28 22:07:41,984:INFO:       statsforecast: 1.5.0
2024-02-28 22:07:41,984:INFO:        tune_sklearn: 0.5.0
2024-02-28 22:07:41,984:INFO:                 ray: 2.9.3
2024-02-28 22:07:41,984:INFO:            hyperopt: 0.2.7
2024-02-28 22:07:41,984:INFO:              optuna: 3.5.0
2024-02-28 22:07:41,984:INFO:               skopt: 0.9.0
2024-02-28 22:07:41,984:INFO:              mlflow: 2.10.2
2024-02-28 22:07:41,984:INFO:              gradio: 4.19.2
2024-02-28 22:07:41,984:INFO:             fastapi: 0.110.0
2024-02-28 22:07:41,984:INFO:             uvicorn: 0.27.1
2024-02-28 22:07:41,984:INFO:              m2cgen: 0.10.0
2024-02-28 22:07:41,984:INFO:           evidently: 0.4.16
2024-02-28 22:07:41,984:INFO:               fugue: 0.8.6
2024-02-28 22:07:41,984:INFO:           streamlit: Not installed
2024-02-28 22:07:41,984:INFO:             prophet: Not installed
2024-02-28 22:07:41,984:INFO:None
2024-02-28 22:07:41,984:INFO:Set up data.
2024-02-28 22:07:41,985:INFO:Set up folding strategy.
2024-02-28 22:07:41,985:INFO:Set up train/test split.
2024-02-28 22:07:41,985:INFO:Set up index.
2024-02-28 22:07:41,985:INFO:Assigning column types.
2024-02-28 22:07:41,992:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-02-28 22:07:41,993:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-02-28 22:07:41,996:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-02-28 22:07:41,999:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-02-28 22:07:42,038:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-02-28 22:07:42,079:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-28 22:07:42,080:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:07:42,084:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:07:42,084:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-02-28 22:07:42,084:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-02-28 22:07:42,092:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-02-28 22:07:42,131:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-02-28 22:07:42,161:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-28 22:07:42,161:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:07:42,161:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:07:42,161:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-02-28 22:07:42,161:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-02-28 22:07:42,171:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-02-28 22:07:42,209:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-02-28 22:07:42,239:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-28 22:07:42,240:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:07:42,241:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:07:42,245:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-02-28 22:07:42,248:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-02-28 22:07:42,284:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-02-28 22:07:42,315:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-28 22:07:42,315:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:07:42,315:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:07:42,315:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-02-28 22:07:42,326:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-02-28 22:07:42,361:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-02-28 22:07:42,396:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-28 22:07:42,396:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:07:42,398:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:07:42,404:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-02-28 22:07:42,442:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-02-28 22:07:42,472:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-28 22:07:42,472:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:07:42,474:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:07:42,475:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-02-28 22:07:42,515:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-02-28 22:07:42,549:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-28 22:07:42,549:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:07:42,549:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:07:42,592:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-02-28 22:07:42,623:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-28 22:07:42,623:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:07:42,623:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:07:42,623:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-02-28 22:07:42,669:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-02-28 22:07:42,700:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:07:42,700:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:07:42,746:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-02-28 22:07:42,777:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:07:42,777:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:07:42,777:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-02-28 22:07:42,855:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:07:42,855:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:07:42,931:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:07:42,931:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:07:42,938:INFO:Preparing preprocessing pipeline...
2024-02-28 22:07:42,938:INFO:Set up simple imputation.
2024-02-28 22:07:42,948:INFO:Finished creating preprocessing pipeline.
2024-02-28 22:07:42,949:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['cylinders', 'displacement',
                                             'horsepower', 'weight',
                                             'acceleration'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2024-02-28 22:07:42,949:INFO:Creating final display dataframe.
2024-02-28 22:07:42,986:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target               mpg
2                   Target type        Regression
3           Original data shape          (392, 6)
4        Transformed data shape          (392, 6)
5   Transformed train set shape          (274, 6)
6    Transformed test set shape          (118, 6)
7              Numeric features                 5
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              bed6
2024-02-28 22:07:43,065:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:07:43,069:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:07:43,134:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:07:43,134:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:07:43,150:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\internal\metrics.py:51: FutureWarning: The `needs_threshold` and `needs_proba` parameter are deprecated in version 1.4 and will be removed in 1.6. You can either let `response_method` be `None` or set it to `predict` to preserve the same behaviour.
  warnings.warn(

2024-02-28 22:07:43,150:INFO:setup() successfully completed in 1.17s...............
2024-02-28 22:07:49,019:INFO:PyCaret RegressionExperiment
2024-02-28 22:07:49,019:INFO:Logging name: reg-default-name
2024-02-28 22:07:49,019:INFO:ML Usecase: MLUsecase.REGRESSION
2024-02-28 22:07:49,019:INFO:version 3.3.0
2024-02-28 22:07:49,019:INFO:Initializing setup()
2024-02-28 22:07:49,020:INFO:self.USI: 496b
2024-02-28 22:07:49,020:INFO:self._variable_keys: {'memory', 'seed', 'fold_generator', 'exp_name_log', 'html_param', '_ml_usecase', 'gpu_n_jobs_param', 'fold_shuffle_param', 'X_train', 'logging_param', 'y_test', 'transform_target_param', 'X_test', 'idx', 'pipeline', 'y_train', 'data', 'gpu_param', '_available_plots', 'n_jobs_param', 'exp_id', 'y', 'X', 'fold_groups_param', 'USI', 'log_plots_param', 'target_param'}
2024-02-28 22:07:49,020:INFO:Checking environment
2024-02-28 22:07:49,020:INFO:python_version: 3.9.18
2024-02-28 22:07:49,020:INFO:python_build: ('main', 'Dec 23 2023 16:29:04')
2024-02-28 22:07:49,020:INFO:machine: AMD64
2024-02-28 22:07:49,020:INFO:platform: Windows-10-10.0.22621-SP0
2024-02-28 22:07:49,020:INFO:Memory: svmem(total=34228445184, available=21936414720, percent=35.9, used=12292030464, free=21936414720)
2024-02-28 22:07:49,020:INFO:Physical Core: 8
2024-02-28 22:07:49,020:INFO:Logical Core: 16
2024-02-28 22:07:49,020:INFO:Checking libraries
2024-02-28 22:07:49,020:INFO:System:
2024-02-28 22:07:49,020:INFO:    python: 3.9.18 | packaged by conda-forge | (main, Dec 23 2023, 16:29:04) [MSC v.1929 64 bit (AMD64)]
2024-02-28 22:07:49,020:INFO:executable: c:\Users\Administrator\anaconda3\envs\EXAM_ML\python.exe
2024-02-28 22:07:49,020:INFO:   machine: Windows-10-10.0.22621-SP0
2024-02-28 22:07:49,020:INFO:PyCaret required dependencies:
2024-02-28 22:07:49,020:INFO:                 pip: 24.0
2024-02-28 22:07:49,020:INFO:          setuptools: 69.1.1
2024-02-28 22:07:49,020:INFO:             pycaret: 3.3.0
2024-02-28 22:07:49,020:INFO:             IPython: 8.12.0
2024-02-28 22:07:49,020:INFO:          ipywidgets: 8.1.2
2024-02-28 22:07:49,020:INFO:                tqdm: 4.66.2
2024-02-28 22:07:49,020:INFO:               numpy: 1.25.2
2024-02-28 22:07:49,020:INFO:              pandas: 1.5.3
2024-02-28 22:07:49,020:INFO:              jinja2: 3.1.3
2024-02-28 22:07:49,020:INFO:               scipy: 1.11.4
2024-02-28 22:07:49,020:INFO:              joblib: 1.3.2
2024-02-28 22:07:49,020:INFO:             sklearn: 1.4.1.post1
2024-02-28 22:07:49,020:INFO:                pyod: 1.1.3
2024-02-28 22:07:49,020:INFO:            imblearn: 0.12.0
2024-02-28 22:07:49,020:INFO:   category_encoders: 2.6.3
2024-02-28 22:07:49,020:INFO:            lightgbm: 4.3.0
2024-02-28 22:07:49,020:INFO:               numba: 0.58.1
2024-02-28 22:07:49,020:INFO:            requests: 2.31.0
2024-02-28 22:07:49,020:INFO:          matplotlib: 3.7.5
2024-02-28 22:07:49,020:INFO:          scikitplot: 0.3.7
2024-02-28 22:07:49,020:INFO:         yellowbrick: 1.5
2024-02-28 22:07:49,020:INFO:              plotly: 5.19.0
2024-02-28 22:07:49,020:INFO:    plotly-resampler: Not installed
2024-02-28 22:07:49,020:INFO:             kaleido: 0.2.1
2024-02-28 22:07:49,020:INFO:           schemdraw: 0.15
2024-02-28 22:07:49,020:INFO:         statsmodels: 0.14.1
2024-02-28 22:07:49,020:INFO:              sktime: 0.27.0
2024-02-28 22:07:49,020:INFO:               tbats: 1.1.3
2024-02-28 22:07:49,020:INFO:            pmdarima: 2.0.4
2024-02-28 22:07:49,020:INFO:              psutil: 5.9.8
2024-02-28 22:07:49,020:INFO:          markupsafe: 2.1.5
2024-02-28 22:07:49,023:INFO:             pickle5: Not installed
2024-02-28 22:07:49,023:INFO:         cloudpickle: 3.0.0
2024-02-28 22:07:49,023:INFO:         deprecation: 2.1.0
2024-02-28 22:07:49,023:INFO:              xxhash: 3.4.1
2024-02-28 22:07:49,023:INFO:           wurlitzer: Not installed
2024-02-28 22:07:49,023:INFO:PyCaret optional dependencies:
2024-02-28 22:07:49,023:INFO:                shap: 0.44.1
2024-02-28 22:07:49,023:INFO:           interpret: 0.5.1
2024-02-28 22:07:49,023:INFO:                umap: 0.5.5
2024-02-28 22:07:49,023:INFO:     ydata_profiling: 4.6.5
2024-02-28 22:07:49,023:INFO:  explainerdashboard: 0.4.5
2024-02-28 22:07:49,023:INFO:             autoviz: Not installed
2024-02-28 22:07:49,023:INFO:           fairlearn: 0.7.0
2024-02-28 22:07:49,023:INFO:          deepchecks: Not installed
2024-02-28 22:07:49,023:INFO:             xgboost: 2.0.3
2024-02-28 22:07:49,023:INFO:            catboost: 1.2.3
2024-02-28 22:07:49,023:INFO:              kmodes: 0.12.2
2024-02-28 22:07:49,023:INFO:             mlxtend: 0.23.1
2024-02-28 22:07:49,023:INFO:       statsforecast: 1.5.0
2024-02-28 22:07:49,023:INFO:        tune_sklearn: 0.5.0
2024-02-28 22:07:49,023:INFO:                 ray: 2.9.3
2024-02-28 22:07:49,023:INFO:            hyperopt: 0.2.7
2024-02-28 22:07:49,023:INFO:              optuna: 3.5.0
2024-02-28 22:07:49,023:INFO:               skopt: 0.9.0
2024-02-28 22:07:49,023:INFO:              mlflow: 2.10.2
2024-02-28 22:07:49,023:INFO:              gradio: 4.19.2
2024-02-28 22:07:49,023:INFO:             fastapi: 0.110.0
2024-02-28 22:07:49,023:INFO:             uvicorn: 0.27.1
2024-02-28 22:07:49,023:INFO:              m2cgen: 0.10.0
2024-02-28 22:07:49,023:INFO:           evidently: 0.4.16
2024-02-28 22:07:49,023:INFO:               fugue: 0.8.6
2024-02-28 22:07:49,023:INFO:           streamlit: Not installed
2024-02-28 22:07:49,023:INFO:             prophet: Not installed
2024-02-28 22:07:49,023:INFO:None
2024-02-28 22:07:49,023:INFO:Set up GPU usage.
2024-02-28 22:07:49,023:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:07:49,024:WARNING:cuML is outdated or not found. Required version is >=23.08.
                Please visit https://rapids.ai/install for installation instructions.
2024-02-28 22:07:49,024:INFO:Set up data.
2024-02-28 22:07:49,026:INFO:Set up folding strategy.
2024-02-28 22:07:49,026:INFO:Set up train/test split.
2024-02-28 22:07:49,027:INFO:Set up index.
2024-02-28 22:07:49,027:INFO:Assigning column types.
2024-02-28 22:07:49,032:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-02-28 22:07:49,032:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:07:49,032:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:07:49,035:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:07:49,038:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:07:49,076:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:07:49,108:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:07:49,108:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:07:49,108:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:07:49,223:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:07:49,223:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:07:49,223:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:07:49,223:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:07:49,223:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:07:49,277:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:07:49,301:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:07:49,301:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:07:49,301:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:07:49,414:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:07:49,414:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-02-28 22:07:49,414:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:07:49,414:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:07:49,414:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:07:49,414:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:07:49,453:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:07:49,493:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:07:49,493:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:07:49,493:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:07:49,579:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:07:49,580:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:07:49,580:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:07:49,584:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:07:49,584:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:07:49,624:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:07:49,669:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:07:49,669:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:07:49,669:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:07:49,758:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:07:49,758:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-02-28 22:07:49,758:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:07:49,758:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:07:49,758:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:07:49,758:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:07:49,800:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:07:49,848:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:07:49,848:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:07:49,848:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:07:49,932:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:07:49,932:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:07:49,932:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:07:49,932:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:07:49,940:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:07:49,978:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:07:50,009:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:07:50,011:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:07:50,011:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:07:50,082:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:07:50,082:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-02-28 22:07:50,082:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:07:50,082:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:07:50,098:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:07:50,098:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:07:50,146:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:07:50,177:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:07:50,177:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:07:50,177:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:07:50,271:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:07:50,271:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:07:50,272:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:07:50,272:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:07:50,278:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:07:50,317:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:07:50,355:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:07:50,355:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:07:50,355:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:07:50,458:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:07:50,458:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-02-28 22:07:50,458:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:07:50,458:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:07:50,464:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:07:50,468:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:07:50,519:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:07:50,551:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:07:50,551:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:07:50,551:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:07:50,631:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:07:50,631:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:07:50,631:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:07:50,631:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:07:50,642:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:07:50,684:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:07:50,723:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:07:50,723:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:07:50,723:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:07:50,808:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:07:50,808:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-02-28 22:07:50,808:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:07:50,808:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:07:50,808:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:07:50,808:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:07:50,861:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:07:50,902:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:07:50,903:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:07:50,903:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:07:50,996:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:07:50,997:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:07:50,997:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:07:51,000:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:07:51,005:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:07:51,046:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:07:51,069:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:07:51,069:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:07:51,069:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:07:51,170:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:07:51,170:INFO:Preparing preprocessing pipeline...
2024-02-28 22:07:51,170:INFO:Set up simple imputation.
2024-02-28 22:07:51,170:INFO:Finished creating preprocessing pipeline.
2024-02-28 22:07:51,170:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['cylinders', 'displacement',
                                             'horsepower', 'weight',
                                             'acceleration'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2024-02-28 22:07:51,170:INFO:Creating final display dataframe.
2024-02-28 22:07:51,215:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target               mpg
2                   Target type        Regression
3           Original data shape          (392, 6)
4        Transformed data shape          (392, 6)
5   Transformed train set shape          (274, 6)
6    Transformed test set shape          (118, 6)
7              Numeric features                 5
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU              True
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              496b
2024-02-28 22:07:51,223:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:07:51,223:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:07:51,223:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:07:51,223:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:07:51,274:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:07:51,292:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:07:51,292:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:07:51,292:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:07:51,408:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:07:51,408:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:07:51,408:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:07:51,408:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:07:51,408:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:07:51,465:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:07:51,500:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:07:51,500:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:07:51,500:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:07:51,585:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:07:51,585:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\internal\metrics.py:51: FutureWarning: The `needs_threshold` and `needs_proba` parameter are deprecated in version 1.4 and will be removed in 1.6. You can either let `response_method` be `None` or set it to `predict` to preserve the same behaviour.
  warnings.warn(

2024-02-28 22:07:51,585:INFO:setup() successfully completed in 2.57s...............
2024-02-28 22:08:15,923:INFO:Initializing compare_models()
2024-02-28 22:08:15,923:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196B364F130>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000196B364F130>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-02-28 22:08:15,923:INFO:Checking exceptions
2024-02-28 22:08:15,924:INFO:Preparing display monitor
2024-02-28 22:08:15,940:INFO:Initializing Linear Regression
2024-02-28 22:08:15,941:INFO:Total runtime is 1.660585403442383e-05 minutes
2024-02-28 22:08:15,943:INFO:SubProcess create_model() called ==================================
2024-02-28 22:08:15,943:INFO:Initializing create_model()
2024-02-28 22:08:15,943:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196B364F130>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196AD67EDF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:08:15,943:INFO:Checking exceptions
2024-02-28 22:08:15,943:INFO:Importing libraries
2024-02-28 22:08:15,943:INFO:Copying training dataset
2024-02-28 22:08:15,945:INFO:Defining folds
2024-02-28 22:08:15,945:INFO:Declaring metric variables
2024-02-28 22:08:15,948:INFO:Importing untrained model
2024-02-28 22:08:15,950:INFO:Linear Regression Imported successfully
2024-02-28 22:08:15,955:INFO:Starting cross validation
2024-02-28 22:08:15,957:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:08:16,070:INFO:Calculating mean and std
2024-02-28 22:08:16,070:INFO:Creating metrics dataframe
2024-02-28 22:08:16,070:INFO:Uploading results into container
2024-02-28 22:08:16,070:INFO:Uploading model into container now
2024-02-28 22:08:16,070:INFO:_master_model_container: 1
2024-02-28 22:08:16,070:INFO:_display_container: 2
2024-02-28 22:08:16,070:INFO:LinearRegression(n_jobs=-1)
2024-02-28 22:08:16,070:INFO:create_model() successfully completed......................................
2024-02-28 22:08:16,162:INFO:SubProcess create_model() end ==================================
2024-02-28 22:08:16,162:INFO:Creating metrics dataframe
2024-02-28 22:08:16,172:INFO:Initializing Lasso Regression
2024-02-28 22:08:16,172:INFO:Total runtime is 0.0038542985916137696 minutes
2024-02-28 22:08:16,174:INFO:SubProcess create_model() called ==================================
2024-02-28 22:08:16,174:INFO:Initializing create_model()
2024-02-28 22:08:16,174:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196B364F130>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196AD67EDF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:08:16,174:INFO:Checking exceptions
2024-02-28 22:08:16,174:INFO:Importing libraries
2024-02-28 22:08:16,174:INFO:Copying training dataset
2024-02-28 22:08:16,176:INFO:Defining folds
2024-02-28 22:08:16,177:INFO:Declaring metric variables
2024-02-28 22:08:16,178:INFO:Importing untrained model
2024-02-28 22:08:16,181:INFO:Lasso Regression Imported successfully
2024-02-28 22:08:16,185:INFO:Starting cross validation
2024-02-28 22:08:16,186:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:08:16,291:INFO:Calculating mean and std
2024-02-28 22:08:16,292:INFO:Creating metrics dataframe
2024-02-28 22:08:16,292:INFO:Uploading results into container
2024-02-28 22:08:16,292:INFO:Uploading model into container now
2024-02-28 22:08:16,294:INFO:_master_model_container: 2
2024-02-28 22:08:16,294:INFO:_display_container: 2
2024-02-28 22:08:16,294:INFO:Lasso(random_state=123)
2024-02-28 22:08:16,294:INFO:create_model() successfully completed......................................
2024-02-28 22:08:16,376:INFO:SubProcess create_model() end ==================================
2024-02-28 22:08:16,376:INFO:Creating metrics dataframe
2024-02-28 22:08:16,381:INFO:Initializing Ridge Regression
2024-02-28 22:08:16,381:INFO:Total runtime is 0.007348700364430746 minutes
2024-02-28 22:08:16,384:INFO:SubProcess create_model() called ==================================
2024-02-28 22:08:16,385:INFO:Initializing create_model()
2024-02-28 22:08:16,385:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196B364F130>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196AD67EDF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:08:16,385:INFO:Checking exceptions
2024-02-28 22:08:16,385:INFO:Importing libraries
2024-02-28 22:08:16,385:INFO:Copying training dataset
2024-02-28 22:08:16,385:INFO:Defining folds
2024-02-28 22:08:16,385:INFO:Declaring metric variables
2024-02-28 22:08:16,385:INFO:Importing untrained model
2024-02-28 22:08:16,385:INFO:Ridge Regression Imported successfully
2024-02-28 22:08:16,385:INFO:Starting cross validation
2024-02-28 22:08:16,385:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:08:16,487:INFO:Calculating mean and std
2024-02-28 22:08:16,488:INFO:Creating metrics dataframe
2024-02-28 22:08:16,490:INFO:Uploading results into container
2024-02-28 22:08:16,490:INFO:Uploading model into container now
2024-02-28 22:08:16,490:INFO:_master_model_container: 3
2024-02-28 22:08:16,490:INFO:_display_container: 2
2024-02-28 22:08:16,490:INFO:Ridge(random_state=123)
2024-02-28 22:08:16,490:INFO:create_model() successfully completed......................................
2024-02-28 22:08:16,570:INFO:SubProcess create_model() end ==================================
2024-02-28 22:08:16,570:INFO:Creating metrics dataframe
2024-02-28 22:08:16,578:INFO:Initializing Elastic Net
2024-02-28 22:08:16,578:INFO:Total runtime is 0.010618646939595541 minutes
2024-02-28 22:08:16,578:INFO:SubProcess create_model() called ==================================
2024-02-28 22:08:16,578:INFO:Initializing create_model()
2024-02-28 22:08:16,578:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196B364F130>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196AD67EDF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:08:16,578:INFO:Checking exceptions
2024-02-28 22:08:16,578:INFO:Importing libraries
2024-02-28 22:08:16,578:INFO:Copying training dataset
2024-02-28 22:08:16,578:INFO:Defining folds
2024-02-28 22:08:16,578:INFO:Declaring metric variables
2024-02-28 22:08:16,585:INFO:Importing untrained model
2024-02-28 22:08:16,585:INFO:Elastic Net Imported successfully
2024-02-28 22:08:16,593:INFO:Starting cross validation
2024-02-28 22:08:16,594:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:08:16,685:INFO:Calculating mean and std
2024-02-28 22:08:16,685:INFO:Creating metrics dataframe
2024-02-28 22:08:16,685:INFO:Uploading results into container
2024-02-28 22:08:16,685:INFO:Uploading model into container now
2024-02-28 22:08:16,685:INFO:_master_model_container: 4
2024-02-28 22:08:16,685:INFO:_display_container: 2
2024-02-28 22:08:16,685:INFO:ElasticNet(random_state=123)
2024-02-28 22:08:16,685:INFO:create_model() successfully completed......................................
2024-02-28 22:08:16,770:INFO:SubProcess create_model() end ==================================
2024-02-28 22:08:16,770:INFO:Creating metrics dataframe
2024-02-28 22:08:16,777:INFO:Initializing Least Angle Regression
2024-02-28 22:08:16,777:INFO:Total runtime is 0.013950045903523764 minutes
2024-02-28 22:08:16,777:INFO:SubProcess create_model() called ==================================
2024-02-28 22:08:16,777:INFO:Initializing create_model()
2024-02-28 22:08:16,777:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196B364F130>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196AD67EDF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:08:16,777:INFO:Checking exceptions
2024-02-28 22:08:16,777:INFO:Importing libraries
2024-02-28 22:08:16,777:INFO:Copying training dataset
2024-02-28 22:08:16,785:INFO:Defining folds
2024-02-28 22:08:16,785:INFO:Declaring metric variables
2024-02-28 22:08:16,785:INFO:Importing untrained model
2024-02-28 22:08:16,785:INFO:Least Angle Regression Imported successfully
2024-02-28 22:08:16,793:INFO:Starting cross validation
2024-02-28 22:08:16,793:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:08:16,901:INFO:Calculating mean and std
2024-02-28 22:08:16,901:INFO:Creating metrics dataframe
2024-02-28 22:08:16,901:INFO:Uploading results into container
2024-02-28 22:08:16,901:INFO:Uploading model into container now
2024-02-28 22:08:16,901:INFO:_master_model_container: 5
2024-02-28 22:08:16,901:INFO:_display_container: 2
2024-02-28 22:08:16,901:INFO:Lars(random_state=123)
2024-02-28 22:08:16,901:INFO:create_model() successfully completed......................................
2024-02-28 22:08:16,985:INFO:SubProcess create_model() end ==================================
2024-02-28 22:08:16,985:INFO:Creating metrics dataframe
2024-02-28 22:08:16,993:INFO:Initializing Lasso Least Angle Regression
2024-02-28 22:08:16,993:INFO:Total runtime is 0.017539687951405845 minutes
2024-02-28 22:08:16,993:INFO:SubProcess create_model() called ==================================
2024-02-28 22:08:16,993:INFO:Initializing create_model()
2024-02-28 22:08:16,993:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196B364F130>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196AD67EDF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:08:16,993:INFO:Checking exceptions
2024-02-28 22:08:16,993:INFO:Importing libraries
2024-02-28 22:08:16,993:INFO:Copying training dataset
2024-02-28 22:08:16,993:INFO:Defining folds
2024-02-28 22:08:16,993:INFO:Declaring metric variables
2024-02-28 22:08:17,001:INFO:Importing untrained model
2024-02-28 22:08:17,001:INFO:Lasso Least Angle Regression Imported successfully
2024-02-28 22:08:17,008:INFO:Starting cross validation
2024-02-28 22:08:17,008:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:08:17,101:INFO:Calculating mean and std
2024-02-28 22:08:17,101:INFO:Creating metrics dataframe
2024-02-28 22:08:17,101:INFO:Uploading results into container
2024-02-28 22:08:17,101:INFO:Uploading model into container now
2024-02-28 22:08:17,101:INFO:_master_model_container: 6
2024-02-28 22:08:17,101:INFO:_display_container: 2
2024-02-28 22:08:17,101:INFO:LassoLars(random_state=123)
2024-02-28 22:08:17,101:INFO:create_model() successfully completed......................................
2024-02-28 22:08:17,187:INFO:SubProcess create_model() end ==================================
2024-02-28 22:08:17,187:INFO:Creating metrics dataframe
2024-02-28 22:08:17,193:INFO:Initializing Orthogonal Matching Pursuit
2024-02-28 22:08:17,193:INFO:Total runtime is 0.02087299426396688 minutes
2024-02-28 22:08:17,193:INFO:SubProcess create_model() called ==================================
2024-02-28 22:08:17,193:INFO:Initializing create_model()
2024-02-28 22:08:17,193:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196B364F130>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196AD67EDF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:08:17,193:INFO:Checking exceptions
2024-02-28 22:08:17,193:INFO:Importing libraries
2024-02-28 22:08:17,193:INFO:Copying training dataset
2024-02-28 22:08:17,193:INFO:Defining folds
2024-02-28 22:08:17,193:INFO:Declaring metric variables
2024-02-28 22:08:17,201:INFO:Importing untrained model
2024-02-28 22:08:17,201:INFO:Orthogonal Matching Pursuit Imported successfully
2024-02-28 22:08:17,201:INFO:Starting cross validation
2024-02-28 22:08:17,208:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:08:17,295:INFO:Calculating mean and std
2024-02-28 22:08:17,295:INFO:Creating metrics dataframe
2024-02-28 22:08:17,295:INFO:Uploading results into container
2024-02-28 22:08:17,295:INFO:Uploading model into container now
2024-02-28 22:08:17,295:INFO:_master_model_container: 7
2024-02-28 22:08:17,295:INFO:_display_container: 2
2024-02-28 22:08:17,295:INFO:OrthogonalMatchingPursuit()
2024-02-28 22:08:17,295:INFO:create_model() successfully completed......................................
2024-02-28 22:08:17,377:INFO:SubProcess create_model() end ==================================
2024-02-28 22:08:17,377:INFO:Creating metrics dataframe
2024-02-28 22:08:17,387:INFO:Initializing Bayesian Ridge
2024-02-28 22:08:17,387:INFO:Total runtime is 0.024113122622172037 minutes
2024-02-28 22:08:17,387:INFO:SubProcess create_model() called ==================================
2024-02-28 22:08:17,387:INFO:Initializing create_model()
2024-02-28 22:08:17,387:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196B364F130>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196AD67EDF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:08:17,387:INFO:Checking exceptions
2024-02-28 22:08:17,387:INFO:Importing libraries
2024-02-28 22:08:17,387:INFO:Copying training dataset
2024-02-28 22:08:17,394:INFO:Defining folds
2024-02-28 22:08:17,394:INFO:Declaring metric variables
2024-02-28 22:08:17,395:INFO:Importing untrained model
2024-02-28 22:08:17,395:INFO:Bayesian Ridge Imported successfully
2024-02-28 22:08:17,404:INFO:Starting cross validation
2024-02-28 22:08:17,405:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:08:17,547:INFO:Calculating mean and std
2024-02-28 22:08:17,547:INFO:Creating metrics dataframe
2024-02-28 22:08:17,547:INFO:Uploading results into container
2024-02-28 22:08:17,547:INFO:Uploading model into container now
2024-02-28 22:08:17,547:INFO:_master_model_container: 8
2024-02-28 22:08:17,547:INFO:_display_container: 2
2024-02-28 22:08:17,547:INFO:BayesianRidge()
2024-02-28 22:08:17,547:INFO:create_model() successfully completed......................................
2024-02-28 22:08:17,631:INFO:SubProcess create_model() end ==================================
2024-02-28 22:08:17,631:INFO:Creating metrics dataframe
2024-02-28 22:08:17,647:INFO:Initializing Passive Aggressive Regressor
2024-02-28 22:08:17,647:INFO:Total runtime is 0.028433680534362793 minutes
2024-02-28 22:08:17,647:INFO:SubProcess create_model() called ==================================
2024-02-28 22:08:17,647:INFO:Initializing create_model()
2024-02-28 22:08:17,647:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196B364F130>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196AD67EDF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:08:17,647:INFO:Checking exceptions
2024-02-28 22:08:17,647:INFO:Importing libraries
2024-02-28 22:08:17,647:INFO:Copying training dataset
2024-02-28 22:08:17,647:INFO:Defining folds
2024-02-28 22:08:17,647:INFO:Declaring metric variables
2024-02-28 22:08:17,654:INFO:Importing untrained model
2024-02-28 22:08:17,654:INFO:Passive Aggressive Regressor Imported successfully
2024-02-28 22:08:17,663:INFO:Starting cross validation
2024-02-28 22:08:17,663:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:08:17,754:INFO:Calculating mean and std
2024-02-28 22:08:17,754:INFO:Creating metrics dataframe
2024-02-28 22:08:17,754:INFO:Uploading results into container
2024-02-28 22:08:17,754:INFO:Uploading model into container now
2024-02-28 22:08:17,754:INFO:_master_model_container: 9
2024-02-28 22:08:17,762:INFO:_display_container: 2
2024-02-28 22:08:17,762:INFO:PassiveAggressiveRegressor(random_state=123)
2024-02-28 22:08:17,762:INFO:create_model() successfully completed......................................
2024-02-28 22:08:17,839:INFO:SubProcess create_model() end ==================================
2024-02-28 22:08:17,839:INFO:Creating metrics dataframe
2024-02-28 22:08:17,847:INFO:Initializing Huber Regressor
2024-02-28 22:08:17,847:INFO:Total runtime is 0.03177188634872437 minutes
2024-02-28 22:08:17,847:INFO:SubProcess create_model() called ==================================
2024-02-28 22:08:17,854:INFO:Initializing create_model()
2024-02-28 22:08:17,855:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196B364F130>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196AD67EDF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:08:17,855:INFO:Checking exceptions
2024-02-28 22:08:17,855:INFO:Importing libraries
2024-02-28 22:08:17,855:INFO:Copying training dataset
2024-02-28 22:08:17,855:INFO:Defining folds
2024-02-28 22:08:17,855:INFO:Declaring metric variables
2024-02-28 22:08:17,855:INFO:Importing untrained model
2024-02-28 22:08:17,862:INFO:Huber Regressor Imported successfully
2024-02-28 22:08:17,866:INFO:Starting cross validation
2024-02-28 22:08:17,867:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:08:17,893:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-02-28 22:08:17,916:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-02-28 22:08:17,954:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-02-28 22:08:17,977:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-02-28 22:08:17,993:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-02-28 22:08:18,039:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-02-28 22:08:18,062:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-02-28 22:08:18,077:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-02-28 22:08:18,085:INFO:Calculating mean and std
2024-02-28 22:08:18,085:INFO:Creating metrics dataframe
2024-02-28 22:08:18,085:INFO:Uploading results into container
2024-02-28 22:08:18,085:INFO:Uploading model into container now
2024-02-28 22:08:18,085:INFO:_master_model_container: 10
2024-02-28 22:08:18,085:INFO:_display_container: 2
2024-02-28 22:08:18,085:INFO:HuberRegressor()
2024-02-28 22:08:18,085:INFO:create_model() successfully completed......................................
2024-02-28 22:08:18,170:INFO:SubProcess create_model() end ==================================
2024-02-28 22:08:18,170:INFO:Creating metrics dataframe
2024-02-28 22:08:18,177:INFO:Initializing K Neighbors Regressor
2024-02-28 22:08:18,177:INFO:Total runtime is 0.03728311856587728 minutes
2024-02-28 22:08:18,185:INFO:SubProcess create_model() called ==================================
2024-02-28 22:08:18,185:INFO:Initializing create_model()
2024-02-28 22:08:18,185:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196B364F130>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196AD67EDF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:08:18,185:INFO:Checking exceptions
2024-02-28 22:08:18,185:INFO:Importing libraries
2024-02-28 22:08:18,185:INFO:Copying training dataset
2024-02-28 22:08:18,185:INFO:Defining folds
2024-02-28 22:08:18,185:INFO:Declaring metric variables
2024-02-28 22:08:18,185:INFO:Importing untrained model
2024-02-28 22:08:18,195:INFO:K Neighbors Regressor Imported successfully
2024-02-28 22:08:18,197:INFO:Starting cross validation
2024-02-28 22:08:18,197:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:08:18,300:INFO:Calculating mean and std
2024-02-28 22:08:18,300:INFO:Creating metrics dataframe
2024-02-28 22:08:18,308:INFO:Uploading results into container
2024-02-28 22:08:18,308:INFO:Uploading model into container now
2024-02-28 22:08:18,308:INFO:_master_model_container: 11
2024-02-28 22:08:18,308:INFO:_display_container: 2
2024-02-28 22:08:18,308:INFO:KNeighborsRegressor(n_jobs=-1)
2024-02-28 22:08:18,308:INFO:create_model() successfully completed......................................
2024-02-28 22:08:18,393:INFO:SubProcess create_model() end ==================================
2024-02-28 22:08:18,393:INFO:Creating metrics dataframe
2024-02-28 22:08:18,401:INFO:Initializing Decision Tree Regressor
2024-02-28 22:08:18,401:INFO:Total runtime is 0.04100050926208496 minutes
2024-02-28 22:08:18,401:INFO:SubProcess create_model() called ==================================
2024-02-28 22:08:18,401:INFO:Initializing create_model()
2024-02-28 22:08:18,401:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196B364F130>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196AD67EDF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:08:18,401:INFO:Checking exceptions
2024-02-28 22:08:18,401:INFO:Importing libraries
2024-02-28 22:08:18,401:INFO:Copying training dataset
2024-02-28 22:08:18,408:INFO:Defining folds
2024-02-28 22:08:18,408:INFO:Declaring metric variables
2024-02-28 22:08:18,408:INFO:Importing untrained model
2024-02-28 22:08:18,408:INFO:Decision Tree Regressor Imported successfully
2024-02-28 22:08:18,417:INFO:Starting cross validation
2024-02-28 22:08:18,418:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:08:18,516:INFO:Calculating mean and std
2024-02-28 22:08:18,516:INFO:Creating metrics dataframe
2024-02-28 22:08:18,516:INFO:Uploading results into container
2024-02-28 22:08:18,516:INFO:Uploading model into container now
2024-02-28 22:08:18,516:INFO:_master_model_container: 12
2024-02-28 22:08:18,516:INFO:_display_container: 2
2024-02-28 22:08:18,516:INFO:DecisionTreeRegressor(random_state=123)
2024-02-28 22:08:18,516:INFO:create_model() successfully completed......................................
2024-02-28 22:08:18,601:INFO:SubProcess create_model() end ==================================
2024-02-28 22:08:18,601:INFO:Creating metrics dataframe
2024-02-28 22:08:18,616:INFO:Initializing Random Forest Regressor
2024-02-28 22:08:18,616:INFO:Total runtime is 0.044590826829274496 minutes
2024-02-28 22:08:18,616:INFO:SubProcess create_model() called ==================================
2024-02-28 22:08:18,616:INFO:Initializing create_model()
2024-02-28 22:08:18,616:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196B364F130>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196AD67EDF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:08:18,616:INFO:Checking exceptions
2024-02-28 22:08:18,616:INFO:Importing libraries
2024-02-28 22:08:18,616:INFO:Copying training dataset
2024-02-28 22:08:18,616:INFO:Defining folds
2024-02-28 22:08:18,616:INFO:Declaring metric variables
2024-02-28 22:08:18,623:INFO:Importing untrained model
2024-02-28 22:08:18,624:INFO:Random Forest Regressor Imported successfully
2024-02-28 22:08:18,633:INFO:Starting cross validation
2024-02-28 22:08:18,633:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:08:18,657:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:08:18,670:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:08:18,685:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:08:18,699:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:08:18,708:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:08:18,724:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:08:18,739:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:08:18,747:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:08:18,762:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:08:18,777:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:08:18,777:INFO:Calculating mean and std
2024-02-28 22:08:18,777:INFO:Creating metrics dataframe
2024-02-28 22:08:18,777:INFO:Uploading results into container
2024-02-28 22:08:18,777:INFO:Uploading model into container now
2024-02-28 22:08:18,777:INFO:_master_model_container: 13
2024-02-28 22:08:18,777:INFO:_display_container: 2
2024-02-28 22:08:18,777:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-02-28 22:08:18,777:INFO:create_model() successfully completed......................................
2024-02-28 22:08:18,862:INFO:SubProcess create_model() end ==================================
2024-02-28 22:08:18,862:INFO:Creating metrics dataframe
2024-02-28 22:08:18,870:INFO:Initializing Extra Trees Regressor
2024-02-28 22:08:18,870:INFO:Total runtime is 0.048820618788401285 minutes
2024-02-28 22:08:18,878:INFO:SubProcess create_model() called ==================================
2024-02-28 22:08:18,878:INFO:Initializing create_model()
2024-02-28 22:08:18,878:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196B364F130>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196AD67EDF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:08:18,878:INFO:Checking exceptions
2024-02-28 22:08:18,878:INFO:Importing libraries
2024-02-28 22:08:18,878:INFO:Copying training dataset
2024-02-28 22:08:18,878:INFO:Defining folds
2024-02-28 22:08:18,878:INFO:Declaring metric variables
2024-02-28 22:08:18,878:INFO:Importing untrained model
2024-02-28 22:08:18,885:INFO:Extra Trees Regressor Imported successfully
2024-02-28 22:08:18,885:INFO:Starting cross validation
2024-02-28 22:08:18,885:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:08:18,907:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:08:18,921:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:08:18,935:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:08:18,947:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:08:18,965:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:08:18,978:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:08:18,993:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:08:19,001:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:08:19,016:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:08:19,031:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:08:19,031:INFO:Calculating mean and std
2024-02-28 22:08:19,031:INFO:Creating metrics dataframe
2024-02-28 22:08:19,039:INFO:Uploading results into container
2024-02-28 22:08:19,039:INFO:Uploading model into container now
2024-02-28 22:08:19,039:INFO:_master_model_container: 14
2024-02-28 22:08:19,039:INFO:_display_container: 2
2024-02-28 22:08:19,039:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-02-28 22:08:19,039:INFO:create_model() successfully completed......................................
2024-02-28 22:08:19,124:INFO:SubProcess create_model() end ==================================
2024-02-28 22:08:19,124:INFO:Creating metrics dataframe
2024-02-28 22:08:19,131:INFO:Initializing AdaBoost Regressor
2024-02-28 22:08:19,131:INFO:Total runtime is 0.05318150917689005 minutes
2024-02-28 22:08:19,139:INFO:SubProcess create_model() called ==================================
2024-02-28 22:08:19,139:INFO:Initializing create_model()
2024-02-28 22:08:19,139:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196B364F130>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196AD67EDF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:08:19,139:INFO:Checking exceptions
2024-02-28 22:08:19,139:INFO:Importing libraries
2024-02-28 22:08:19,139:INFO:Copying training dataset
2024-02-28 22:08:19,139:INFO:Defining folds
2024-02-28 22:08:19,139:INFO:Declaring metric variables
2024-02-28 22:08:19,139:INFO:Importing untrained model
2024-02-28 22:08:19,147:INFO:AdaBoost Regressor Imported successfully
2024-02-28 22:08:19,147:INFO:Starting cross validation
2024-02-28 22:08:19,147:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:08:19,708:INFO:Calculating mean and std
2024-02-28 22:08:19,708:INFO:Creating metrics dataframe
2024-02-28 22:08:19,716:INFO:Uploading results into container
2024-02-28 22:08:19,716:INFO:Uploading model into container now
2024-02-28 22:08:19,716:INFO:_master_model_container: 15
2024-02-28 22:08:19,716:INFO:_display_container: 2
2024-02-28 22:08:19,716:INFO:AdaBoostRegressor(random_state=123)
2024-02-28 22:08:19,716:INFO:create_model() successfully completed......................................
2024-02-28 22:08:19,801:INFO:SubProcess create_model() end ==================================
2024-02-28 22:08:19,801:INFO:Creating metrics dataframe
2024-02-28 22:08:19,808:INFO:Initializing Gradient Boosting Regressor
2024-02-28 22:08:19,808:INFO:Total runtime is 0.0644638180732727 minutes
2024-02-28 22:08:19,808:INFO:SubProcess create_model() called ==================================
2024-02-28 22:08:19,808:INFO:Initializing create_model()
2024-02-28 22:08:19,808:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196B364F130>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196AD67EDF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:08:19,808:INFO:Checking exceptions
2024-02-28 22:08:19,808:INFO:Importing libraries
2024-02-28 22:08:19,808:INFO:Copying training dataset
2024-02-28 22:08:19,816:INFO:Defining folds
2024-02-28 22:08:19,816:INFO:Declaring metric variables
2024-02-28 22:08:19,816:INFO:Importing untrained model
2024-02-28 22:08:19,816:INFO:Gradient Boosting Regressor Imported successfully
2024-02-28 22:08:19,825:INFO:Starting cross validation
2024-02-28 22:08:19,825:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:08:20,347:INFO:Calculating mean and std
2024-02-28 22:08:20,347:INFO:Creating metrics dataframe
2024-02-28 22:08:20,347:INFO:Uploading results into container
2024-02-28 22:08:20,347:INFO:Uploading model into container now
2024-02-28 22:08:20,347:INFO:_master_model_container: 16
2024-02-28 22:08:20,347:INFO:_display_container: 2
2024-02-28 22:08:20,347:INFO:GradientBoostingRegressor(random_state=123)
2024-02-28 22:08:20,347:INFO:create_model() successfully completed......................................
2024-02-28 22:08:20,431:INFO:SubProcess create_model() end ==================================
2024-02-28 22:08:20,431:INFO:Creating metrics dataframe
2024-02-28 22:08:20,447:INFO:Initializing Extreme Gradient Boosting
2024-02-28 22:08:20,447:INFO:Total runtime is 0.07510409355163573 minutes
2024-02-28 22:08:20,447:INFO:SubProcess create_model() called ==================================
2024-02-28 22:08:20,447:INFO:Initializing create_model()
2024-02-28 22:08:20,447:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196B364F130>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196AD67EDF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:08:20,447:INFO:Checking exceptions
2024-02-28 22:08:20,447:INFO:Importing libraries
2024-02-28 22:08:20,447:INFO:Copying training dataset
2024-02-28 22:08:20,447:INFO:Defining folds
2024-02-28 22:08:20,447:INFO:Declaring metric variables
2024-02-28 22:08:20,454:INFO:Importing untrained model
2024-02-28 22:08:20,454:INFO:Extreme Gradient Boosting Imported successfully
2024-02-28 22:08:20,462:INFO:Starting cross validation
2024-02-28 22:08:20,462:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:08:22,862:INFO:Calculating mean and std
2024-02-28 22:08:22,862:INFO:Creating metrics dataframe
2024-02-28 22:08:22,862:INFO:Uploading results into container
2024-02-28 22:08:22,862:INFO:Uploading model into container now
2024-02-28 22:08:22,862:INFO:_master_model_container: 17
2024-02-28 22:08:22,862:INFO:_display_container: 2
2024-02-28 22:08:22,862:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='gpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=123, ...)
2024-02-28 22:08:22,862:INFO:create_model() successfully completed......................................
2024-02-28 22:08:22,970:INFO:SubProcess create_model() end ==================================
2024-02-28 22:08:22,970:INFO:Creating metrics dataframe
2024-02-28 22:08:22,979:INFO:Initializing Light Gradient Boosting Machine
2024-02-28 22:08:22,979:INFO:Total runtime is 0.11731451352437336 minutes
2024-02-28 22:08:22,985:INFO:SubProcess create_model() called ==================================
2024-02-28 22:08:22,985:INFO:Initializing create_model()
2024-02-28 22:08:22,985:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196B364F130>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196AD67EDF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:08:22,985:INFO:Checking exceptions
2024-02-28 22:08:22,985:INFO:Importing libraries
2024-02-28 22:08:22,985:INFO:Copying training dataset
2024-02-28 22:08:22,985:INFO:Defining folds
2024-02-28 22:08:22,985:INFO:Declaring metric variables
2024-02-28 22:08:22,985:INFO:Importing untrained model
2024-02-28 22:08:22,985:INFO:Light Gradient Boosting Machine Imported successfully
2024-02-28 22:08:22,997:INFO:Starting cross validation
2024-02-28 22:08:22,997:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:08:23,003:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-02-28 22:08:23,003:INFO:[LightGBM] [Info] Total Bins 217
2024-02-28 22:08:23,003:INFO:[LightGBM] [Info] Number of data points in the train set: 246, number of used features: 5
2024-02-28 22:08:23,062:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-02-28 22:08:23,062:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-02-28 22:08:25,885:INFO:[LightGBM] [Info] GPU programs have been built
2024-02-28 22:08:25,893:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-02-28 22:08:25,893:INFO:[LightGBM] [Info] 5 dense feature groups (0.00 MB) transferred to GPU in 0.000453 secs. 0 sparse feature groups
2024-02-28 22:08:25,893:INFO:[LightGBM] [Info] Start training from score 23.452033
2024-02-28 22:08:25,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:25,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:25,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:25,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:25,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:25,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:25,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:25,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:25,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:25,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:25,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:25,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:25,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:25,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:25,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:25,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:25,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:25,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:25,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:25,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:25,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:25,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:25,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:25,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:25,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:25,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:25,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:25,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:25,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:25,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:25,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:25,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:25,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:25,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:25,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:25,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:25,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:25,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:25,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:25,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:25,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:25,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:25,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:25,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:25,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:25,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:25,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:25,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:25,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:25,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:25,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:25,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:25,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:25,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:25,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:25,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:25,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:25,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:25,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:25,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:25,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:25,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:25,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:25,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:25,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:25,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:25,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:25,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:25,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:25,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:25,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:25,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:25,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:25,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:25,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:25,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:25,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:25,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:25,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,062:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-02-28 22:08:26,062:INFO:[LightGBM] [Info] Total Bins 220
2024-02-28 22:08:26,062:INFO:[LightGBM] [Info] Number of data points in the train set: 246, number of used features: 5
2024-02-28 22:08:26,125:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-02-28 22:08:26,125:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-02-28 22:08:26,131:INFO:[LightGBM] [Info] GPU programs have been built
2024-02-28 22:08:26,131:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-02-28 22:08:26,131:INFO:[LightGBM] [Info] 5 dense feature groups (0.00 MB) transferred to GPU in 0.000373 secs. 0 sparse feature groups
2024-02-28 22:08:26,131:INFO:[LightGBM] [Info] Start training from score 23.622358
2024-02-28 22:08:26,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,302:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-02-28 22:08:26,302:INFO:[LightGBM] [Info] Total Bins 214
2024-02-28 22:08:26,302:INFO:[LightGBM] [Info] Number of data points in the train set: 246, number of used features: 5
2024-02-28 22:08:26,362:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-02-28 22:08:26,362:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-02-28 22:08:26,362:INFO:[LightGBM] [Info] GPU programs have been built
2024-02-28 22:08:26,369:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-02-28 22:08:26,369:INFO:[LightGBM] [Info] 5 dense feature groups (0.00 MB) transferred to GPU in 0.000346 secs. 0 sparse feature groups
2024-02-28 22:08:26,371:INFO:[LightGBM] [Info] Start training from score 23.693902
2024-02-28 22:08:26,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,534:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-02-28 22:08:26,534:INFO:[LightGBM] [Info] Total Bins 218
2024-02-28 22:08:26,534:INFO:[LightGBM] [Info] Number of data points in the train set: 246, number of used features: 5
2024-02-28 22:08:26,593:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-02-28 22:08:26,593:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-02-28 22:08:26,600:INFO:[LightGBM] [Info] GPU programs have been built
2024-02-28 22:08:26,602:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-02-28 22:08:26,602:INFO:[LightGBM] [Info] 5 dense feature groups (0.00 MB) transferred to GPU in 0.000378 secs. 0 sparse feature groups
2024-02-28 22:08:26,603:INFO:[LightGBM] [Info] Start training from score 23.815041
2024-02-28 22:08:26,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,765:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-02-28 22:08:26,765:INFO:[LightGBM] [Info] Total Bins 218
2024-02-28 22:08:26,765:INFO:[LightGBM] [Info] Number of data points in the train set: 247, number of used features: 5
2024-02-28 22:08:26,815:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-02-28 22:08:26,815:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-02-28 22:08:26,827:INFO:[LightGBM] [Info] GPU programs have been built
2024-02-28 22:08:26,828:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-02-28 22:08:26,829:INFO:[LightGBM] [Info] 5 dense feature groups (0.00 MB) transferred to GPU in 0.000380 secs. 0 sparse feature groups
2024-02-28 22:08:26,829:INFO:[LightGBM] [Info] Start training from score 23.681781
2024-02-28 22:08:26,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:26,995:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-02-28 22:08:26,995:INFO:[LightGBM] [Info] Total Bins 219
2024-02-28 22:08:26,995:INFO:[LightGBM] [Info] Number of data points in the train set: 247, number of used features: 5
2024-02-28 22:08:27,054:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-02-28 22:08:27,054:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-02-28 22:08:27,054:INFO:[LightGBM] [Info] GPU programs have been built
2024-02-28 22:08:27,062:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-02-28 22:08:27,062:INFO:[LightGBM] [Info] 5 dense feature groups (0.00 MB) transferred to GPU in 0.000342 secs. 0 sparse feature groups
2024-02-28 22:08:27,062:INFO:[LightGBM] [Info] Start training from score 23.918623
2024-02-28 22:08:27,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,202:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-02-28 22:08:27,202:INFO:[LightGBM] [Info] Total Bins 214
2024-02-28 22:08:27,202:INFO:[LightGBM] [Info] Number of data points in the train set: 247, number of used features: 5
2024-02-28 22:08:27,254:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-02-28 22:08:27,254:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-02-28 22:08:27,262:INFO:[LightGBM] [Info] GPU programs have been built
2024-02-28 22:08:27,262:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-02-28 22:08:27,262:INFO:[LightGBM] [Info] 5 dense feature groups (0.00 MB) transferred to GPU in 0.000376 secs. 0 sparse feature groups
2024-02-28 22:08:27,262:INFO:[LightGBM] [Info] Start training from score 23.956275
2024-02-28 22:08:27,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,431:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-02-28 22:08:27,431:INFO:[LightGBM] [Info] Total Bins 215
2024-02-28 22:08:27,431:INFO:[LightGBM] [Info] Number of data points in the train set: 247, number of used features: 5
2024-02-28 22:08:27,491:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-02-28 22:08:27,491:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-02-28 22:08:27,493:INFO:[LightGBM] [Info] GPU programs have been built
2024-02-28 22:08:27,498:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-02-28 22:08:27,498:INFO:[LightGBM] [Info] 5 dense feature groups (0.00 MB) transferred to GPU in 0.000330 secs. 0 sparse feature groups
2024-02-28 22:08:27,500:INFO:[LightGBM] [Info] Start training from score 23.765182
2024-02-28 22:08:27,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,654:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-02-28 22:08:27,654:INFO:[LightGBM] [Info] Total Bins 214
2024-02-28 22:08:27,654:INFO:[LightGBM] [Info] Number of data points in the train set: 247, number of used features: 5
2024-02-28 22:08:27,718:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-02-28 22:08:27,718:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-02-28 22:08:27,723:INFO:[LightGBM] [Info] GPU programs have been built
2024-02-28 22:08:27,725:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-02-28 22:08:27,725:INFO:[LightGBM] [Info] 5 dense feature groups (0.00 MB) transferred to GPU in 0.000383 secs. 0 sparse feature groups
2024-02-28 22:08:27,726:INFO:[LightGBM] [Info] Start training from score 23.770040
2024-02-28 22:08:27,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,877:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-02-28 22:08:27,877:INFO:[LightGBM] [Info] Total Bins 218
2024-02-28 22:08:27,877:INFO:[LightGBM] [Info] Number of data points in the train set: 247, number of used features: 5
2024-02-28 22:08:27,931:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-02-28 22:08:27,931:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-02-28 22:08:27,941:INFO:[LightGBM] [Info] GPU programs have been built
2024-02-28 22:08:27,941:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-02-28 22:08:27,941:INFO:[LightGBM] [Info] 5 dense feature groups (0.00 MB) transferred to GPU in 0.000344 secs. 0 sparse feature groups
2024-02-28 22:08:27,941:INFO:[LightGBM] [Info] Start training from score 23.837652
2024-02-28 22:08:27,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:27,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:28,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:28,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:28,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:28,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:28,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:28,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:28,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:28,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:28,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:28,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:28,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:28,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:28,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:28,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:28,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:28,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:28,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:28,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:28,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:28,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:28,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:28,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:28,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:28,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:28,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:28,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:28,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:28,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:28,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:28,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:28,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:28,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:28,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:28,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:28,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:28,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:28,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:28,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:28,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:28,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:28,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:28,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:28,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:28,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:28,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:28,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:28,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:28,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:28,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:28,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:28,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:08:28,093:INFO:Calculating mean and std
2024-02-28 22:08:28,093:INFO:Creating metrics dataframe
2024-02-28 22:08:28,098:INFO:Uploading results into container
2024-02-28 22:08:28,098:INFO:Uploading model into container now
2024-02-28 22:08:28,098:INFO:_master_model_container: 18
2024-02-28 22:08:28,098:INFO:_display_container: 2
2024-02-28 22:08:28,098:INFO:LGBMRegressor(device='gpu', n_jobs=-1, random_state=123)
2024-02-28 22:08:28,098:INFO:create_model() successfully completed......................................
2024-02-28 22:08:28,210:INFO:SubProcess create_model() end ==================================
2024-02-28 22:08:28,210:INFO:Creating metrics dataframe
2024-02-28 22:08:28,216:INFO:Initializing CatBoost Regressor
2024-02-28 22:08:28,216:INFO:Total runtime is 0.20458405017852782 minutes
2024-02-28 22:08:28,216:INFO:SubProcess create_model() called ==================================
2024-02-28 22:08:28,216:INFO:Initializing create_model()
2024-02-28 22:08:28,216:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196B364F130>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196AD67EDF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:08:28,216:INFO:Checking exceptions
2024-02-28 22:08:28,216:INFO:Importing libraries
2024-02-28 22:08:28,216:INFO:Copying training dataset
2024-02-28 22:08:28,225:INFO:Defining folds
2024-02-28 22:08:28,225:INFO:Declaring metric variables
2024-02-28 22:08:28,227:INFO:Importing untrained model
2024-02-28 22:08:28,229:INFO:CatBoost Regressor Imported successfully
2024-02-28 22:08:28,235:INFO:Starting cross validation
2024-02-28 22:08:28,236:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:09:46,048:INFO:Calculating mean and std
2024-02-28 22:09:46,048:INFO:Creating metrics dataframe
2024-02-28 22:09:46,056:INFO:Uploading results into container
2024-02-28 22:09:46,057:INFO:Uploading model into container now
2024-02-28 22:09:46,057:INFO:_master_model_container: 19
2024-02-28 22:09:46,057:INFO:_display_container: 2
2024-02-28 22:09:46,057:INFO:<catboost.core.CatBoostRegressor object at 0x00000196BA9AE940>
2024-02-28 22:09:46,057:INFO:create_model() successfully completed......................................
2024-02-28 22:09:46,140:INFO:SubProcess create_model() end ==================================
2024-02-28 22:09:46,140:INFO:Creating metrics dataframe
2024-02-28 22:09:46,140:INFO:Initializing Dummy Regressor
2024-02-28 22:09:46,140:INFO:Total runtime is 1.5033265789349874 minutes
2024-02-28 22:09:46,140:INFO:SubProcess create_model() called ==================================
2024-02-28 22:09:46,140:INFO:Initializing create_model()
2024-02-28 22:09:46,140:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196B364F130>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000196AD67EDF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:09:46,140:INFO:Checking exceptions
2024-02-28 22:09:46,140:INFO:Importing libraries
2024-02-28 22:09:46,140:INFO:Copying training dataset
2024-02-28 22:09:46,158:INFO:Defining folds
2024-02-28 22:09:46,158:INFO:Declaring metric variables
2024-02-28 22:09:46,160:INFO:Importing untrained model
2024-02-28 22:09:46,162:INFO:Dummy Regressor Imported successfully
2024-02-28 22:09:46,164:INFO:Starting cross validation
2024-02-28 22:09:46,164:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:09:46,240:INFO:Calculating mean and std
2024-02-28 22:09:46,240:INFO:Creating metrics dataframe
2024-02-28 22:09:46,240:INFO:Uploading results into container
2024-02-28 22:09:46,240:INFO:Uploading model into container now
2024-02-28 22:09:46,240:INFO:_master_model_container: 20
2024-02-28 22:09:46,240:INFO:_display_container: 2
2024-02-28 22:09:46,240:INFO:DummyRegressor()
2024-02-28 22:09:46,240:INFO:create_model() successfully completed......................................
2024-02-28 22:09:46,330:INFO:SubProcess create_model() end ==================================
2024-02-28 22:09:46,330:INFO:Creating metrics dataframe
2024-02-28 22:09:46,340:INFO:Initializing create_model()
2024-02-28 22:09:46,340:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000196B364F130>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:09:46,340:INFO:Checking exceptions
2024-02-28 22:09:46,340:INFO:Importing libraries
2024-02-28 22:09:46,340:INFO:Copying training dataset
2024-02-28 22:09:46,340:INFO:Defining folds
2024-02-28 22:09:46,340:INFO:Declaring metric variables
2024-02-28 22:09:46,340:INFO:Importing untrained model
2024-02-28 22:09:46,340:INFO:Declaring custom model
2024-02-28 22:09:46,340:INFO:Random Forest Regressor Imported successfully
2024-02-28 22:09:46,340:INFO:Cross validation set to False
2024-02-28 22:09:46,340:INFO:Fitting Model
2024-02-28 22:09:46,358:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-02-28 22:09:46,358:INFO:create_model() successfully completed......................................
2024-02-28 22:09:46,467:INFO:_master_model_container: 20
2024-02-28 22:09:46,468:INFO:_display_container: 2
2024-02-28 22:09:46,468:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-02-28 22:09:46,468:INFO:compare_models() successfully completed......................................
2024-02-28 22:12:53,051:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:53,051:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:53,051:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:53,051:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:53,128:INFO:PyCaret RegressionExperiment
2024-02-28 22:12:53,128:INFO:Logging name: reg-default-name
2024-02-28 22:12:53,128:INFO:ML Usecase: MLUsecase.REGRESSION
2024-02-28 22:12:53,128:INFO:version 3.3.0
2024-02-28 22:12:53,128:INFO:Initializing setup()
2024-02-28 22:12:53,128:INFO:self.USI: 6ffb
2024-02-28 22:12:53,128:INFO:self._variable_keys: {'logging_param', '_ml_usecase', 'target_param', 'X_train', 'idx', 'data', 'y', 'exp_name_log', 'X_test', 'transform_target_param', 'log_plots_param', 'memory', 'html_param', '_available_plots', 'gpu_n_jobs_param', 'y_train', 'seed', 'USI', 'pipeline', 'exp_id', 'y_test', 'gpu_param', 'fold_shuffle_param', 'fold_generator', 'fold_groups_param', 'X', 'n_jobs_param'}
2024-02-28 22:12:53,128:INFO:Checking environment
2024-02-28 22:12:53,128:INFO:python_version: 3.9.18
2024-02-28 22:12:53,128:INFO:python_build: ('main', 'Dec 23 2023 16:29:04')
2024-02-28 22:12:53,128:INFO:machine: AMD64
2024-02-28 22:12:53,128:INFO:platform: Windows-10-10.0.22621-SP0
2024-02-28 22:12:53,128:INFO:Memory: svmem(total=34228445184, available=23004844032, percent=32.8, used=11223601152, free=23004844032)
2024-02-28 22:12:53,128:INFO:Physical Core: 8
2024-02-28 22:12:53,128:INFO:Logical Core: 16
2024-02-28 22:12:53,128:INFO:Checking libraries
2024-02-28 22:12:53,128:INFO:System:
2024-02-28 22:12:53,128:INFO:    python: 3.9.18 | packaged by conda-forge | (main, Dec 23 2023, 16:29:04) [MSC v.1929 64 bit (AMD64)]
2024-02-28 22:12:53,128:INFO:executable: c:\Users\Administrator\anaconda3\envs\EXAM_ML\python.exe
2024-02-28 22:12:53,128:INFO:   machine: Windows-10-10.0.22621-SP0
2024-02-28 22:12:53,128:INFO:PyCaret required dependencies:
2024-02-28 22:12:53,513:INFO:                 pip: 24.0
2024-02-28 22:12:53,513:INFO:          setuptools: 69.1.1
2024-02-28 22:12:53,513:INFO:             pycaret: 3.3.0
2024-02-28 22:12:53,513:INFO:             IPython: 8.12.0
2024-02-28 22:12:53,513:INFO:          ipywidgets: 8.1.2
2024-02-28 22:12:53,513:INFO:                tqdm: 4.66.2
2024-02-28 22:12:53,513:INFO:               numpy: 1.25.2
2024-02-28 22:12:53,513:INFO:              pandas: 1.5.3
2024-02-28 22:12:53,513:INFO:              jinja2: 3.1.3
2024-02-28 22:12:53,513:INFO:               scipy: 1.11.4
2024-02-28 22:12:53,513:INFO:              joblib: 1.3.2
2024-02-28 22:12:53,513:INFO:             sklearn: 1.4.1.post1
2024-02-28 22:12:53,513:INFO:                pyod: 1.1.3
2024-02-28 22:12:53,513:INFO:            imblearn: 0.12.0
2024-02-28 22:12:53,513:INFO:   category_encoders: 2.6.3
2024-02-28 22:12:53,513:INFO:            lightgbm: 4.3.0
2024-02-28 22:12:53,513:INFO:               numba: 0.58.1
2024-02-28 22:12:53,513:INFO:            requests: 2.31.0
2024-02-28 22:12:53,513:INFO:          matplotlib: 3.7.5
2024-02-28 22:12:53,513:INFO:          scikitplot: 0.3.7
2024-02-28 22:12:53,513:INFO:         yellowbrick: 1.5
2024-02-28 22:12:53,513:INFO:              plotly: 5.19.0
2024-02-28 22:12:53,513:INFO:    plotly-resampler: Not installed
2024-02-28 22:12:53,513:INFO:             kaleido: 0.2.1
2024-02-28 22:12:53,513:INFO:           schemdraw: 0.15
2024-02-28 22:12:53,513:INFO:         statsmodels: 0.14.1
2024-02-28 22:12:53,513:INFO:              sktime: 0.27.0
2024-02-28 22:12:53,513:INFO:               tbats: 1.1.3
2024-02-28 22:12:53,513:INFO:            pmdarima: 2.0.4
2024-02-28 22:12:53,513:INFO:              psutil: 5.9.8
2024-02-28 22:12:53,513:INFO:          markupsafe: 2.1.5
2024-02-28 22:12:53,513:INFO:             pickle5: Not installed
2024-02-28 22:12:53,513:INFO:         cloudpickle: 3.0.0
2024-02-28 22:12:53,513:INFO:         deprecation: 2.1.0
2024-02-28 22:12:53,513:INFO:              xxhash: 3.4.1
2024-02-28 22:12:53,513:INFO:           wurlitzer: Not installed
2024-02-28 22:12:53,513:INFO:PyCaret optional dependencies:
2024-02-28 22:12:55,274:INFO:                shap: 0.44.1
2024-02-28 22:12:55,274:INFO:           interpret: 0.5.1
2024-02-28 22:12:55,274:INFO:                umap: 0.5.5
2024-02-28 22:12:55,274:INFO:     ydata_profiling: 4.6.5
2024-02-28 22:12:55,274:INFO:  explainerdashboard: 0.4.5
2024-02-28 22:12:55,274:INFO:             autoviz: Not installed
2024-02-28 22:12:55,274:INFO:           fairlearn: 0.7.0
2024-02-28 22:12:55,274:INFO:          deepchecks: Not installed
2024-02-28 22:12:55,274:INFO:             xgboost: 2.0.3
2024-02-28 22:12:55,274:INFO:            catboost: 1.2.3
2024-02-28 22:12:55,274:INFO:              kmodes: 0.12.2
2024-02-28 22:12:55,274:INFO:             mlxtend: 0.23.1
2024-02-28 22:12:55,274:INFO:       statsforecast: 1.5.0
2024-02-28 22:12:55,274:INFO:        tune_sklearn: 0.5.0
2024-02-28 22:12:55,274:INFO:                 ray: 2.9.3
2024-02-28 22:12:55,274:INFO:            hyperopt: 0.2.7
2024-02-28 22:12:55,274:INFO:              optuna: 3.5.0
2024-02-28 22:12:55,274:INFO:               skopt: 0.9.0
2024-02-28 22:12:55,274:INFO:              mlflow: 2.10.2
2024-02-28 22:12:55,274:INFO:              gradio: 4.19.2
2024-02-28 22:12:55,274:INFO:             fastapi: 0.110.0
2024-02-28 22:12:55,274:INFO:             uvicorn: 0.27.1
2024-02-28 22:12:55,274:INFO:              m2cgen: 0.10.0
2024-02-28 22:12:55,274:INFO:           evidently: 0.4.16
2024-02-28 22:12:55,274:INFO:               fugue: 0.8.6
2024-02-28 22:12:55,282:INFO:           streamlit: Not installed
2024-02-28 22:12:55,282:INFO:             prophet: Not installed
2024-02-28 22:12:55,282:INFO:None
2024-02-28 22:12:55,282:INFO:Set up GPU usage.
2024-02-28 22:12:55,282:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:55,282:WARNING:cuML is outdated or not found. Required version is >=23.08.
                Please visit https://rapids.ai/install for installation instructions.
2024-02-28 22:12:55,282:INFO:Set up data.
2024-02-28 22:12:55,282:INFO:Set up folding strategy.
2024-02-28 22:12:55,282:INFO:Set up train/test split.
2024-02-28 22:12:55,320:INFO:Set up index.
2024-02-28 22:12:55,321:INFO:Assigning column types.
2024-02-28 22:12:55,321:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-02-28 22:12:55,321:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:55,321:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-02-28 22:12:55,321:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:55,321:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-02-28 22:12:55,321:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:55,329:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-02-28 22:12:55,329:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:55,367:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-02-28 22:12:55,367:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:55,398:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-28 22:12:55,398:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:55,398:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:55,398:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:12:55,631:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:12:55,643:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:55,643:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-02-28 22:12:55,643:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:55,651:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-02-28 22:12:55,651:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:55,651:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-02-28 22:12:55,651:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:55,690:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-02-28 22:12:55,690:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:55,720:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-28 22:12:55,720:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:55,720:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:55,720:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:12:55,812:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:12:55,813:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-02-28 22:12:55,813:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:55,813:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:55,813:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-02-28 22:12:55,813:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:55,813:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-02-28 22:12:55,813:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:55,851:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-02-28 22:12:55,851:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:55,882:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-28 22:12:55,882:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:55,882:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:55,882:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:12:55,974:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:12:55,974:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:55,974:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:55,974:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-02-28 22:12:55,974:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:55,982:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-02-28 22:12:55,982:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:56,020:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-02-28 22:12:56,020:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:56,051:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-28 22:12:56,051:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:56,051:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:56,051:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:12:56,143:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:12:56,145:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-02-28 22:12:56,145:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:56,145:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:56,147:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:56,151:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-02-28 22:12:56,151:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:56,197:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-02-28 22:12:56,197:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:56,236:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-28 22:12:56,236:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:56,237:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:56,237:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:12:56,320:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:12:56,320:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:56,320:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:56,328:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:56,328:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-02-28 22:12:56,328:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:56,390:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-02-28 22:12:56,390:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:56,420:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-28 22:12:56,420:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:56,420:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:56,420:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:12:56,513:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:12:56,513:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-02-28 22:12:56,513:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:56,513:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:56,513:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:56,513:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:56,574:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-02-28 22:12:56,574:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:56,605:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-28 22:12:56,605:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:56,605:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:56,605:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:12:56,692:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:12:56,692:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:56,692:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:56,697:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:56,697:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:56,746:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-02-28 22:12:56,746:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:56,776:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-28 22:12:56,776:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:56,776:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:56,776:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:12:56,867:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:12:56,874:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-02-28 22:12:56,874:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:56,874:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:56,874:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:56,874:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:56,920:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-02-28 22:12:56,920:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:56,943:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:56,943:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:56,951:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:12:57,051:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:12:57,051:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:57,051:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:57,051:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:57,051:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:57,097:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-02-28 22:12:57,097:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:57,128:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:57,128:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:57,128:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:12:57,221:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:12:57,221:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-02-28 22:12:57,221:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:57,221:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:57,221:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:57,228:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:57,273:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:57,305:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:57,305:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:57,306:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:12:57,397:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:12:57,397:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:57,397:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:57,405:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:57,405:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:57,459:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:57,492:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:57,492:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:57,493:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:12:57,587:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:12:57,589:INFO:Preparing preprocessing pipeline...
2024-02-28 22:12:57,589:INFO:Set up simple imputation.
2024-02-28 22:12:57,601:INFO:Finished creating preprocessing pipeline.
2024-02-28 22:12:57,606:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['cylinders', 'displacement',
                                             'horsepower', 'weight',
                                             'acceleration'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2024-02-28 22:12:57,606:INFO:Creating final display dataframe.
2024-02-28 22:12:57,644:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target               mpg
2                   Target type        Regression
3           Original data shape          (392, 6)
4        Transformed data shape          (392, 6)
5   Transformed train set shape          (274, 6)
6    Transformed test set shape          (118, 6)
7              Numeric features                 5
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU              True
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              6ffb
2024-02-28 22:12:57,652:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:57,652:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:57,652:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:57,659:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:57,697:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:57,728:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:57,728:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:57,728:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:12:57,821:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:12:57,821:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:57,821:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:57,828:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:57,828:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:57,867:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:57,897:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:57,897:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:12:57,897:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:12:57,982:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:12:57,982:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\internal\metrics.py:51: FutureWarning: The `needs_threshold` and `needs_proba` parameter are deprecated in version 1.4 and will be removed in 1.6. You can either let `response_method` be `None` or set it to `predict` to preserve the same behaviour.
  warnings.warn(

2024-02-28 22:12:57,982:INFO:setup() successfully completed in 4.85s...............
2024-02-28 22:13:07,398:INFO:PyCaret RegressionExperiment
2024-02-28 22:13:07,398:INFO:Logging name: reg-default-name
2024-02-28 22:13:07,398:INFO:ML Usecase: MLUsecase.REGRESSION
2024-02-28 22:13:07,398:INFO:version 3.3.0
2024-02-28 22:13:07,398:INFO:Initializing setup()
2024-02-28 22:13:07,398:INFO:self.USI: 6f08
2024-02-28 22:13:07,398:INFO:self._variable_keys: {'logging_param', '_ml_usecase', 'target_param', 'X_train', 'idx', 'data', 'y', 'exp_name_log', 'X_test', 'transform_target_param', 'log_plots_param', 'memory', 'html_param', '_available_plots', 'gpu_n_jobs_param', 'y_train', 'seed', 'USI', 'pipeline', 'exp_id', 'y_test', 'gpu_param', 'fold_shuffle_param', 'fold_generator', 'fold_groups_param', 'X', 'n_jobs_param'}
2024-02-28 22:13:07,398:INFO:Checking environment
2024-02-28 22:13:07,398:INFO:python_version: 3.9.18
2024-02-28 22:13:07,398:INFO:python_build: ('main', 'Dec 23 2023 16:29:04')
2024-02-28 22:13:07,398:INFO:machine: AMD64
2024-02-28 22:13:07,398:INFO:platform: Windows-10-10.0.22621-SP0
2024-02-28 22:13:07,398:INFO:Memory: svmem(total=34228445184, available=22813839360, percent=33.3, used=11414605824, free=22813839360)
2024-02-28 22:13:07,398:INFO:Physical Core: 8
2024-02-28 22:13:07,398:INFO:Logical Core: 16
2024-02-28 22:13:07,398:INFO:Checking libraries
2024-02-28 22:13:07,398:INFO:System:
2024-02-28 22:13:07,398:INFO:    python: 3.9.18 | packaged by conda-forge | (main, Dec 23 2023, 16:29:04) [MSC v.1929 64 bit (AMD64)]
2024-02-28 22:13:07,398:INFO:executable: c:\Users\Administrator\anaconda3\envs\EXAM_ML\python.exe
2024-02-28 22:13:07,398:INFO:   machine: Windows-10-10.0.22621-SP0
2024-02-28 22:13:07,398:INFO:PyCaret required dependencies:
2024-02-28 22:13:07,398:INFO:                 pip: 24.0
2024-02-28 22:13:07,398:INFO:          setuptools: 69.1.1
2024-02-28 22:13:07,398:INFO:             pycaret: 3.3.0
2024-02-28 22:13:07,398:INFO:             IPython: 8.12.0
2024-02-28 22:13:07,398:INFO:          ipywidgets: 8.1.2
2024-02-28 22:13:07,398:INFO:                tqdm: 4.66.2
2024-02-28 22:13:07,398:INFO:               numpy: 1.25.2
2024-02-28 22:13:07,398:INFO:              pandas: 1.5.3
2024-02-28 22:13:07,398:INFO:              jinja2: 3.1.3
2024-02-28 22:13:07,398:INFO:               scipy: 1.11.4
2024-02-28 22:13:07,398:INFO:              joblib: 1.3.2
2024-02-28 22:13:07,398:INFO:             sklearn: 1.4.1.post1
2024-02-28 22:13:07,398:INFO:                pyod: 1.1.3
2024-02-28 22:13:07,398:INFO:            imblearn: 0.12.0
2024-02-28 22:13:07,398:INFO:   category_encoders: 2.6.3
2024-02-28 22:13:07,398:INFO:            lightgbm: 4.3.0
2024-02-28 22:13:07,398:INFO:               numba: 0.58.1
2024-02-28 22:13:07,398:INFO:            requests: 2.31.0
2024-02-28 22:13:07,398:INFO:          matplotlib: 3.7.5
2024-02-28 22:13:07,398:INFO:          scikitplot: 0.3.7
2024-02-28 22:13:07,398:INFO:         yellowbrick: 1.5
2024-02-28 22:13:07,398:INFO:              plotly: 5.19.0
2024-02-28 22:13:07,398:INFO:    plotly-resampler: Not installed
2024-02-28 22:13:07,398:INFO:             kaleido: 0.2.1
2024-02-28 22:13:07,398:INFO:           schemdraw: 0.15
2024-02-28 22:13:07,398:INFO:         statsmodels: 0.14.1
2024-02-28 22:13:07,398:INFO:              sktime: 0.27.0
2024-02-28 22:13:07,398:INFO:               tbats: 1.1.3
2024-02-28 22:13:07,398:INFO:            pmdarima: 2.0.4
2024-02-28 22:13:07,398:INFO:              psutil: 5.9.8
2024-02-28 22:13:07,398:INFO:          markupsafe: 2.1.5
2024-02-28 22:13:07,398:INFO:             pickle5: Not installed
2024-02-28 22:13:07,398:INFO:         cloudpickle: 3.0.0
2024-02-28 22:13:07,398:INFO:         deprecation: 2.1.0
2024-02-28 22:13:07,398:INFO:              xxhash: 3.4.1
2024-02-28 22:13:07,398:INFO:           wurlitzer: Not installed
2024-02-28 22:13:07,398:INFO:PyCaret optional dependencies:
2024-02-28 22:13:07,398:INFO:                shap: 0.44.1
2024-02-28 22:13:07,398:INFO:           interpret: 0.5.1
2024-02-28 22:13:07,398:INFO:                umap: 0.5.5
2024-02-28 22:13:07,398:INFO:     ydata_profiling: 4.6.5
2024-02-28 22:13:07,398:INFO:  explainerdashboard: 0.4.5
2024-02-28 22:13:07,398:INFO:             autoviz: Not installed
2024-02-28 22:13:07,398:INFO:           fairlearn: 0.7.0
2024-02-28 22:13:07,398:INFO:          deepchecks: Not installed
2024-02-28 22:13:07,398:INFO:             xgboost: 2.0.3
2024-02-28 22:13:07,398:INFO:            catboost: 1.2.3
2024-02-28 22:13:07,398:INFO:              kmodes: 0.12.2
2024-02-28 22:13:07,398:INFO:             mlxtend: 0.23.1
2024-02-28 22:13:07,398:INFO:       statsforecast: 1.5.0
2024-02-28 22:13:07,398:INFO:        tune_sklearn: 0.5.0
2024-02-28 22:13:07,398:INFO:                 ray: 2.9.3
2024-02-28 22:13:07,398:INFO:            hyperopt: 0.2.7
2024-02-28 22:13:07,398:INFO:              optuna: 3.5.0
2024-02-28 22:13:07,398:INFO:               skopt: 0.9.0
2024-02-28 22:13:07,398:INFO:              mlflow: 2.10.2
2024-02-28 22:13:07,398:INFO:              gradio: 4.19.2
2024-02-28 22:13:07,398:INFO:             fastapi: 0.110.0
2024-02-28 22:13:07,398:INFO:             uvicorn: 0.27.1
2024-02-28 22:13:07,398:INFO:              m2cgen: 0.10.0
2024-02-28 22:13:07,398:INFO:           evidently: 0.4.16
2024-02-28 22:13:07,398:INFO:               fugue: 0.8.6
2024-02-28 22:13:07,398:INFO:           streamlit: Not installed
2024-02-28 22:13:07,398:INFO:             prophet: Not installed
2024-02-28 22:13:07,398:INFO:None
2024-02-28 22:13:07,398:INFO:Set up GPU usage.
2024-02-28 22:13:07,398:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:13:07,398:WARNING:cuML is outdated or not found. Required version is >=23.08.
                Please visit https://rapids.ai/install for installation instructions.
2024-02-28 22:13:07,398:INFO:Set up data.
2024-02-28 22:13:07,398:INFO:Set up folding strategy.
2024-02-28 22:13:07,398:INFO:Set up train/test split.
2024-02-28 22:13:07,398:INFO:Set up index.
2024-02-28 22:13:07,398:INFO:Assigning column types.
2024-02-28 22:13:07,398:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-02-28 22:13:07,398:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:13:07,398:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-02-28 22:13:07,398:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:13:07,415:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-02-28 22:13:07,415:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:13:07,418:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-02-28 22:13:07,418:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:13:07,455:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-02-28 22:13:07,455:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:13:07,487:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-28 22:13:07,487:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:13:07,487:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:13:07,487:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:13:07,598:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:13:07,598:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:13:07,598:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-02-28 22:13:07,598:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:13:07,605:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-02-28 22:13:07,605:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:13:07,608:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-02-28 22:13:07,608:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:13:07,644:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-02-28 22:13:07,644:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:13:07,690:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-28 22:13:07,690:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:13:07,690:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:13:07,690:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:13:07,808:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:13:07,808:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-02-28 22:13:07,808:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:13:07,808:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:13:07,812:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-02-28 22:13:07,812:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:13:07,813:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-02-28 22:13:07,813:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:13:07,853:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-02-28 22:13:07,853:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:13:07,885:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-28 22:13:07,885:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:13:07,888:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:13:07,888:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:13:07,979:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:13:07,980:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:13:07,980:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:13:07,984:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-02-28 22:13:07,984:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:13:07,988:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-02-28 22:13:07,988:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:13:08,032:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-02-28 22:13:08,032:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:13:08,065:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-28 22:13:08,065:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:13:08,065:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:13:08,065:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:13:08,152:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:13:08,153:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-02-28 22:13:08,153:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:13:08,153:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:13:08,156:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:13:08,159:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-02-28 22:13:08,159:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:13:08,190:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-02-28 22:13:08,190:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:13:08,228:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-28 22:13:08,228:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:13:08,229:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:13:08,229:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:13:08,313:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:13:08,313:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:13:08,313:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:13:08,321:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:13:08,321:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-02-28 22:13:08,321:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:13:08,362:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-02-28 22:13:08,362:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:13:08,397:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-28 22:13:08,397:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:13:08,397:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:13:08,405:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:13:08,490:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:13:08,490:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-02-28 22:13:08,490:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:13:08,490:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:13:08,490:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:13:08,490:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:13:08,544:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-02-28 22:13:08,544:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:13:08,583:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-28 22:13:08,583:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:13:08,583:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:13:08,583:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:13:08,669:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:13:08,669:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:13:08,669:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:13:08,675:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:13:08,678:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:13:08,720:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-02-28 22:13:08,720:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:13:08,751:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-28 22:13:08,751:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:13:08,751:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:13:08,751:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:13:08,844:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:13:08,844:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-02-28 22:13:08,844:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:13:08,844:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:13:08,844:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:13:08,851:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:13:08,905:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-02-28 22:13:08,905:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:13:08,944:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:13:08,944:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:13:08,944:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:13:09,028:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:13:09,028:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:13:09,028:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:13:09,028:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:13:09,036:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:13:09,075:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-02-28 22:13:09,075:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:13:09,105:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:13:09,105:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:13:09,105:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:13:09,190:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:13:09,191:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-02-28 22:13:09,191:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:13:09,191:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:13:09,191:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:13:09,198:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:13:09,246:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:13:09,275:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:13:09,275:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:13:09,275:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:13:09,370:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:13:09,371:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:13:09,371:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:13:09,374:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:13:09,377:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:13:09,419:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:13:09,457:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:13:09,457:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:13:09,457:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:13:09,548:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:13:09,549:INFO:Preparing preprocessing pipeline...
2024-02-28 22:13:09,549:INFO:Set up simple imputation.
2024-02-28 22:13:09,562:INFO:Finished creating preprocessing pipeline.
2024-02-28 22:13:09,564:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['cylinders', 'displacement',
                                             'horsepower', 'weight',
                                             'acceleration'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2024-02-28 22:13:09,565:INFO:Creating final display dataframe.
2024-02-28 22:13:09,602:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target               mpg
2                   Target type        Regression
3           Original data shape          (392, 6)
4        Transformed data shape          (392, 6)
5   Transformed train set shape          (274, 6)
6    Transformed test set shape          (118, 6)
7              Numeric features                 5
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU              True
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              6f08
2024-02-28 22:13:09,606:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:13:09,606:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:13:09,609:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:13:09,613:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:13:09,653:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:13:09,689:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:13:09,689:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:13:09,690:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:13:09,782:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:13:09,782:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:13:09,782:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:13:09,782:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:13:09,782:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:13:09,828:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:13:09,874:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:13:09,874:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:13:09,874:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:13:09,959:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:13:09,960:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\internal\metrics.py:51: FutureWarning: The `needs_threshold` and `needs_proba` parameter are deprecated in version 1.4 and will be removed in 1.6. You can either let `response_method` be `None` or set it to `predict` to preserve the same behaviour.
  warnings.warn(

2024-02-28 22:13:09,960:INFO:setup() successfully completed in 2.56s...............
2024-02-28 22:13:28,103:INFO:Initializing compare_models()
2024-02-28 22:13:28,103:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571861F0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000160571861F0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-02-28 22:13:28,103:INFO:Checking exceptions
2024-02-28 22:13:28,103:INFO:Preparing display monitor
2024-02-28 22:13:28,126:INFO:Initializing Linear Regression
2024-02-28 22:13:28,126:INFO:Total runtime is 0.0 minutes
2024-02-28 22:13:28,128:INFO:SubProcess create_model() called ==================================
2024-02-28 22:13:28,129:INFO:Initializing create_model()
2024-02-28 22:13:28,129:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571861F0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016056F47F40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:13:28,129:INFO:Checking exceptions
2024-02-28 22:13:28,129:INFO:Importing libraries
2024-02-28 22:13:28,129:INFO:Copying training dataset
2024-02-28 22:13:28,131:INFO:Defining folds
2024-02-28 22:13:28,132:INFO:Declaring metric variables
2024-02-28 22:13:28,136:INFO:Importing untrained model
2024-02-28 22:13:28,140:INFO:Linear Regression Imported successfully
2024-02-28 22:13:28,147:INFO:Starting cross validation
2024-02-28 22:13:28,150:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:13:28,259:INFO:Calculating mean and std
2024-02-28 22:13:28,259:INFO:Creating metrics dataframe
2024-02-28 22:13:28,261:INFO:Uploading results into container
2024-02-28 22:13:28,262:INFO:Uploading model into container now
2024-02-28 22:13:28,262:INFO:_master_model_container: 1
2024-02-28 22:13:28,262:INFO:_display_container: 2
2024-02-28 22:13:28,262:INFO:LinearRegression(n_jobs=-1)
2024-02-28 22:13:28,262:INFO:create_model() successfully completed......................................
2024-02-28 22:13:28,344:INFO:SubProcess create_model() end ==================================
2024-02-28 22:13:28,344:INFO:Creating metrics dataframe
2024-02-28 22:13:28,344:INFO:Initializing Lasso Regression
2024-02-28 22:13:28,344:INFO:Total runtime is 0.0036359826723734536 minutes
2024-02-28 22:13:28,352:INFO:SubProcess create_model() called ==================================
2024-02-28 22:13:28,352:INFO:Initializing create_model()
2024-02-28 22:13:28,352:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571861F0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016056F47F40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:13:28,352:INFO:Checking exceptions
2024-02-28 22:13:28,352:INFO:Importing libraries
2024-02-28 22:13:28,352:INFO:Copying training dataset
2024-02-28 22:13:28,352:INFO:Defining folds
2024-02-28 22:13:28,352:INFO:Declaring metric variables
2024-02-28 22:13:28,358:INFO:Importing untrained model
2024-02-28 22:13:28,361:INFO:Lasso Regression Imported successfully
2024-02-28 22:13:28,366:INFO:Starting cross validation
2024-02-28 22:13:28,367:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:13:28,452:INFO:Calculating mean and std
2024-02-28 22:13:28,459:INFO:Creating metrics dataframe
2024-02-28 22:13:28,460:INFO:Uploading results into container
2024-02-28 22:13:28,460:INFO:Uploading model into container now
2024-02-28 22:13:28,460:INFO:_master_model_container: 2
2024-02-28 22:13:28,460:INFO:_display_container: 2
2024-02-28 22:13:28,460:INFO:Lasso(random_state=123)
2024-02-28 22:13:28,460:INFO:create_model() successfully completed......................................
2024-02-28 22:13:28,529:INFO:SubProcess create_model() end ==================================
2024-02-28 22:13:28,529:INFO:Creating metrics dataframe
2024-02-28 22:13:28,538:INFO:Initializing Ridge Regression
2024-02-28 22:13:28,538:INFO:Total runtime is 0.006867162386576335 minutes
2024-02-28 22:13:28,544:INFO:SubProcess create_model() called ==================================
2024-02-28 22:13:28,544:INFO:Initializing create_model()
2024-02-28 22:13:28,544:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571861F0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016056F47F40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:13:28,544:INFO:Checking exceptions
2024-02-28 22:13:28,544:INFO:Importing libraries
2024-02-28 22:13:28,544:INFO:Copying training dataset
2024-02-28 22:13:28,544:INFO:Defining folds
2024-02-28 22:13:28,544:INFO:Declaring metric variables
2024-02-28 22:13:28,544:INFO:Importing untrained model
2024-02-28 22:13:28,544:INFO:Ridge Regression Imported successfully
2024-02-28 22:13:28,552:INFO:Starting cross validation
2024-02-28 22:13:28,552:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:13:28,644:INFO:Calculating mean and std
2024-02-28 22:13:28,644:INFO:Creating metrics dataframe
2024-02-28 22:13:28,646:INFO:Uploading results into container
2024-02-28 22:13:28,646:INFO:Uploading model into container now
2024-02-28 22:13:28,646:INFO:_master_model_container: 3
2024-02-28 22:13:28,646:INFO:_display_container: 2
2024-02-28 22:13:28,646:INFO:Ridge(random_state=123)
2024-02-28 22:13:28,646:INFO:create_model() successfully completed......................................
2024-02-28 22:13:28,714:INFO:SubProcess create_model() end ==================================
2024-02-28 22:13:28,714:INFO:Creating metrics dataframe
2024-02-28 22:13:28,723:INFO:Initializing Elastic Net
2024-02-28 22:13:28,723:INFO:Total runtime is 0.009949704011281332 minutes
2024-02-28 22:13:28,729:INFO:SubProcess create_model() called ==================================
2024-02-28 22:13:28,729:INFO:Initializing create_model()
2024-02-28 22:13:28,729:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571861F0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016056F47F40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:13:28,729:INFO:Checking exceptions
2024-02-28 22:13:28,730:INFO:Importing libraries
2024-02-28 22:13:28,730:INFO:Copying training dataset
2024-02-28 22:13:28,730:INFO:Defining folds
2024-02-28 22:13:28,730:INFO:Declaring metric variables
2024-02-28 22:13:28,730:INFO:Importing untrained model
2024-02-28 22:13:28,736:INFO:Elastic Net Imported successfully
2024-02-28 22:13:28,736:INFO:Starting cross validation
2024-02-28 22:13:28,736:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:13:28,829:INFO:Calculating mean and std
2024-02-28 22:13:28,829:INFO:Creating metrics dataframe
2024-02-28 22:13:28,836:INFO:Uploading results into container
2024-02-28 22:13:28,836:INFO:Uploading model into container now
2024-02-28 22:13:28,837:INFO:_master_model_container: 4
2024-02-28 22:13:28,837:INFO:_display_container: 2
2024-02-28 22:13:28,837:INFO:ElasticNet(random_state=123)
2024-02-28 22:13:28,837:INFO:create_model() successfully completed......................................
2024-02-28 22:13:28,906:INFO:SubProcess create_model() end ==================================
2024-02-28 22:13:28,906:INFO:Creating metrics dataframe
2024-02-28 22:13:28,913:INFO:Initializing Least Angle Regression
2024-02-28 22:13:28,913:INFO:Total runtime is 0.01312156915664673 minutes
2024-02-28 22:13:28,913:INFO:SubProcess create_model() called ==================================
2024-02-28 22:13:28,913:INFO:Initializing create_model()
2024-02-28 22:13:28,913:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571861F0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016056F47F40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:13:28,913:INFO:Checking exceptions
2024-02-28 22:13:28,913:INFO:Importing libraries
2024-02-28 22:13:28,913:INFO:Copying training dataset
2024-02-28 22:13:28,921:INFO:Defining folds
2024-02-28 22:13:28,921:INFO:Declaring metric variables
2024-02-28 22:13:28,921:INFO:Importing untrained model
2024-02-28 22:13:28,921:INFO:Least Angle Regression Imported successfully
2024-02-28 22:13:28,929:INFO:Starting cross validation
2024-02-28 22:13:28,929:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:13:29,029:INFO:Calculating mean and std
2024-02-28 22:13:29,029:INFO:Creating metrics dataframe
2024-02-28 22:13:29,029:INFO:Uploading results into container
2024-02-28 22:13:29,029:INFO:Uploading model into container now
2024-02-28 22:13:29,029:INFO:_master_model_container: 5
2024-02-28 22:13:29,029:INFO:_display_container: 2
2024-02-28 22:13:29,029:INFO:Lars(random_state=123)
2024-02-28 22:13:29,029:INFO:create_model() successfully completed......................................
2024-02-28 22:13:29,106:INFO:SubProcess create_model() end ==================================
2024-02-28 22:13:29,106:INFO:Creating metrics dataframe
2024-02-28 22:13:29,114:INFO:Initializing Lasso Least Angle Regression
2024-02-28 22:13:29,114:INFO:Total runtime is 0.016455801328023274 minutes
2024-02-28 22:13:29,114:INFO:SubProcess create_model() called ==================================
2024-02-28 22:13:29,114:INFO:Initializing create_model()
2024-02-28 22:13:29,114:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571861F0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016056F47F40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:13:29,114:INFO:Checking exceptions
2024-02-28 22:13:29,114:INFO:Importing libraries
2024-02-28 22:13:29,114:INFO:Copying training dataset
2024-02-28 22:13:29,114:INFO:Defining folds
2024-02-28 22:13:29,114:INFO:Declaring metric variables
2024-02-28 22:13:29,121:INFO:Importing untrained model
2024-02-28 22:13:29,121:INFO:Lasso Least Angle Regression Imported successfully
2024-02-28 22:13:29,129:INFO:Starting cross validation
2024-02-28 22:13:29,130:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:13:29,222:INFO:Calculating mean and std
2024-02-28 22:13:29,222:INFO:Creating metrics dataframe
2024-02-28 22:13:29,224:INFO:Uploading results into container
2024-02-28 22:13:29,224:INFO:Uploading model into container now
2024-02-28 22:13:29,224:INFO:_master_model_container: 6
2024-02-28 22:13:29,225:INFO:_display_container: 2
2024-02-28 22:13:29,225:INFO:LassoLars(random_state=123)
2024-02-28 22:13:29,225:INFO:create_model() successfully completed......................................
2024-02-28 22:13:29,301:INFO:SubProcess create_model() end ==================================
2024-02-28 22:13:29,301:INFO:Creating metrics dataframe
2024-02-28 22:13:29,307:INFO:Initializing Orthogonal Matching Pursuit
2024-02-28 22:13:29,307:INFO:Total runtime is 0.019683913389841715 minutes
2024-02-28 22:13:29,310:INFO:SubProcess create_model() called ==================================
2024-02-28 22:13:29,310:INFO:Initializing create_model()
2024-02-28 22:13:29,311:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571861F0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016056F47F40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:13:29,311:INFO:Checking exceptions
2024-02-28 22:13:29,311:INFO:Importing libraries
2024-02-28 22:13:29,311:INFO:Copying training dataset
2024-02-28 22:13:29,313:INFO:Defining folds
2024-02-28 22:13:29,313:INFO:Declaring metric variables
2024-02-28 22:13:29,316:INFO:Importing untrained model
2024-02-28 22:13:29,318:INFO:Orthogonal Matching Pursuit Imported successfully
2024-02-28 22:13:29,324:INFO:Starting cross validation
2024-02-28 22:13:29,324:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:13:29,413:INFO:Calculating mean and std
2024-02-28 22:13:29,413:INFO:Creating metrics dataframe
2024-02-28 22:13:29,415:INFO:Uploading results into container
2024-02-28 22:13:29,416:INFO:Uploading model into container now
2024-02-28 22:13:29,416:INFO:_master_model_container: 7
2024-02-28 22:13:29,416:INFO:_display_container: 2
2024-02-28 22:13:29,416:INFO:OrthogonalMatchingPursuit()
2024-02-28 22:13:29,416:INFO:create_model() successfully completed......................................
2024-02-28 22:13:29,490:INFO:SubProcess create_model() end ==================================
2024-02-28 22:13:29,490:INFO:Creating metrics dataframe
2024-02-28 22:13:29,498:INFO:Initializing Bayesian Ridge
2024-02-28 22:13:29,498:INFO:Total runtime is 0.022867234547932942 minutes
2024-02-28 22:13:29,501:INFO:SubProcess create_model() called ==================================
2024-02-28 22:13:29,501:INFO:Initializing create_model()
2024-02-28 22:13:29,501:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571861F0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016056F47F40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:13:29,501:INFO:Checking exceptions
2024-02-28 22:13:29,501:INFO:Importing libraries
2024-02-28 22:13:29,501:INFO:Copying training dataset
2024-02-28 22:13:29,501:INFO:Defining folds
2024-02-28 22:13:29,501:INFO:Declaring metric variables
2024-02-28 22:13:29,506:INFO:Importing untrained model
2024-02-28 22:13:29,508:INFO:Bayesian Ridge Imported successfully
2024-02-28 22:13:29,513:INFO:Starting cross validation
2024-02-28 22:13:29,513:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:13:29,613:INFO:Calculating mean and std
2024-02-28 22:13:29,613:INFO:Creating metrics dataframe
2024-02-28 22:13:29,613:INFO:Uploading results into container
2024-02-28 22:13:29,613:INFO:Uploading model into container now
2024-02-28 22:13:29,621:INFO:_master_model_container: 8
2024-02-28 22:13:29,621:INFO:_display_container: 2
2024-02-28 22:13:29,621:INFO:BayesianRidge()
2024-02-28 22:13:29,621:INFO:create_model() successfully completed......................................
2024-02-28 22:13:29,692:INFO:SubProcess create_model() end ==================================
2024-02-28 22:13:29,692:INFO:Creating metrics dataframe
2024-02-28 22:13:29,698:INFO:Initializing Passive Aggressive Regressor
2024-02-28 22:13:29,698:INFO:Total runtime is 0.026194441318511962 minutes
2024-02-28 22:13:29,698:INFO:SubProcess create_model() called ==================================
2024-02-28 22:13:29,705:INFO:Initializing create_model()
2024-02-28 22:13:29,705:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571861F0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016056F47F40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:13:29,706:INFO:Checking exceptions
2024-02-28 22:13:29,706:INFO:Importing libraries
2024-02-28 22:13:29,706:INFO:Copying training dataset
2024-02-28 22:13:29,706:INFO:Defining folds
2024-02-28 22:13:29,706:INFO:Declaring metric variables
2024-02-28 22:13:29,706:INFO:Importing untrained model
2024-02-28 22:13:29,706:INFO:Passive Aggressive Regressor Imported successfully
2024-02-28 22:13:29,713:INFO:Starting cross validation
2024-02-28 22:13:29,713:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:13:29,806:INFO:Calculating mean and std
2024-02-28 22:13:29,806:INFO:Creating metrics dataframe
2024-02-28 22:13:29,813:INFO:Uploading results into container
2024-02-28 22:13:29,813:INFO:Uploading model into container now
2024-02-28 22:13:29,813:INFO:_master_model_container: 9
2024-02-28 22:13:29,814:INFO:_display_container: 2
2024-02-28 22:13:29,814:INFO:PassiveAggressiveRegressor(random_state=123)
2024-02-28 22:13:29,814:INFO:create_model() successfully completed......................................
2024-02-28 22:13:29,890:INFO:SubProcess create_model() end ==================================
2024-02-28 22:13:29,890:INFO:Creating metrics dataframe
2024-02-28 22:13:29,898:INFO:Initializing Huber Regressor
2024-02-28 22:13:29,898:INFO:Total runtime is 0.02952899932861328 minutes
2024-02-28 22:13:29,900:INFO:SubProcess create_model() called ==================================
2024-02-28 22:13:29,901:INFO:Initializing create_model()
2024-02-28 22:13:29,901:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571861F0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016056F47F40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:13:29,901:INFO:Checking exceptions
2024-02-28 22:13:29,901:INFO:Importing libraries
2024-02-28 22:13:29,901:INFO:Copying training dataset
2024-02-28 22:13:29,903:INFO:Defining folds
2024-02-28 22:13:29,903:INFO:Declaring metric variables
2024-02-28 22:13:29,905:INFO:Importing untrained model
2024-02-28 22:13:29,908:INFO:Huber Regressor Imported successfully
2024-02-28 22:13:29,913:INFO:Starting cross validation
2024-02-28 22:13:29,914:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:13:29,931:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-02-28 22:13:29,952:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-02-28 22:13:29,990:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-02-28 22:13:30,014:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-02-28 22:13:30,029:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-02-28 22:13:30,068:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-02-28 22:13:30,090:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-02-28 22:13:30,114:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-02-28 22:13:30,114:INFO:Calculating mean and std
2024-02-28 22:13:30,114:INFO:Creating metrics dataframe
2024-02-28 22:13:30,114:INFO:Uploading results into container
2024-02-28 22:13:30,114:INFO:Uploading model into container now
2024-02-28 22:13:30,114:INFO:_master_model_container: 10
2024-02-28 22:13:30,114:INFO:_display_container: 2
2024-02-28 22:13:30,121:INFO:HuberRegressor()
2024-02-28 22:13:30,121:INFO:create_model() successfully completed......................................
2024-02-28 22:13:30,191:INFO:SubProcess create_model() end ==================================
2024-02-28 22:13:30,191:INFO:Creating metrics dataframe
2024-02-28 22:13:30,198:INFO:Initializing K Neighbors Regressor
2024-02-28 22:13:30,198:INFO:Total runtime is 0.03453548351923624 minutes
2024-02-28 22:13:30,206:INFO:SubProcess create_model() called ==================================
2024-02-28 22:13:30,206:INFO:Initializing create_model()
2024-02-28 22:13:30,206:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571861F0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016056F47F40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:13:30,206:INFO:Checking exceptions
2024-02-28 22:13:30,206:INFO:Importing libraries
2024-02-28 22:13:30,206:INFO:Copying training dataset
2024-02-28 22:13:30,206:INFO:Defining folds
2024-02-28 22:13:30,206:INFO:Declaring metric variables
2024-02-28 22:13:30,212:INFO:Importing untrained model
2024-02-28 22:13:30,215:INFO:K Neighbors Regressor Imported successfully
2024-02-28 22:13:30,215:INFO:Starting cross validation
2024-02-28 22:13:30,215:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:13:30,314:INFO:Calculating mean and std
2024-02-28 22:13:30,314:INFO:Creating metrics dataframe
2024-02-28 22:13:30,314:INFO:Uploading results into container
2024-02-28 22:13:30,314:INFO:Uploading model into container now
2024-02-28 22:13:30,314:INFO:_master_model_container: 11
2024-02-28 22:13:30,321:INFO:_display_container: 2
2024-02-28 22:13:30,321:INFO:KNeighborsRegressor(n_jobs=-1)
2024-02-28 22:13:30,321:INFO:create_model() successfully completed......................................
2024-02-28 22:13:30,391:INFO:SubProcess create_model() end ==================================
2024-02-28 22:13:30,391:INFO:Creating metrics dataframe
2024-02-28 22:13:30,399:INFO:Initializing Decision Tree Regressor
2024-02-28 22:13:30,399:INFO:Total runtime is 0.03788222074508667 minutes
2024-02-28 22:13:30,407:INFO:SubProcess create_model() called ==================================
2024-02-28 22:13:30,407:INFO:Initializing create_model()
2024-02-28 22:13:30,407:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571861F0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016056F47F40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:13:30,407:INFO:Checking exceptions
2024-02-28 22:13:30,407:INFO:Importing libraries
2024-02-28 22:13:30,407:INFO:Copying training dataset
2024-02-28 22:13:30,407:INFO:Defining folds
2024-02-28 22:13:30,407:INFO:Declaring metric variables
2024-02-28 22:13:30,407:INFO:Importing untrained model
2024-02-28 22:13:30,414:INFO:Decision Tree Regressor Imported successfully
2024-02-28 22:13:30,420:INFO:Starting cross validation
2024-02-28 22:13:30,421:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:13:30,513:INFO:Calculating mean and std
2024-02-28 22:13:30,513:INFO:Creating metrics dataframe
2024-02-28 22:13:30,515:INFO:Uploading results into container
2024-02-28 22:13:30,516:INFO:Uploading model into container now
2024-02-28 22:13:30,516:INFO:_master_model_container: 12
2024-02-28 22:13:30,516:INFO:_display_container: 2
2024-02-28 22:13:30,516:INFO:DecisionTreeRegressor(random_state=123)
2024-02-28 22:13:30,516:INFO:create_model() successfully completed......................................
2024-02-28 22:13:30,582:INFO:SubProcess create_model() end ==================================
2024-02-28 22:13:30,582:INFO:Creating metrics dataframe
2024-02-28 22:13:30,598:INFO:Initializing Random Forest Regressor
2024-02-28 22:13:30,598:INFO:Total runtime is 0.04120024840037028 minutes
2024-02-28 22:13:30,598:INFO:SubProcess create_model() called ==================================
2024-02-28 22:13:30,598:INFO:Initializing create_model()
2024-02-28 22:13:30,598:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571861F0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016056F47F40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:13:30,598:INFO:Checking exceptions
2024-02-28 22:13:30,598:INFO:Importing libraries
2024-02-28 22:13:30,598:INFO:Copying training dataset
2024-02-28 22:13:30,598:INFO:Defining folds
2024-02-28 22:13:30,598:INFO:Declaring metric variables
2024-02-28 22:13:30,606:INFO:Importing untrained model
2024-02-28 22:13:30,607:INFO:Random Forest Regressor Imported successfully
2024-02-28 22:13:30,613:INFO:Starting cross validation
2024-02-28 22:13:30,614:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:13:30,626:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:13:30,637:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:13:30,652:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:13:30,668:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:13:30,675:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:13:30,690:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:13:30,706:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:13:30,721:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:13:30,736:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:13:30,752:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:13:30,752:INFO:Calculating mean and std
2024-02-28 22:13:30,752:INFO:Creating metrics dataframe
2024-02-28 22:13:30,752:INFO:Uploading results into container
2024-02-28 22:13:30,752:INFO:Uploading model into container now
2024-02-28 22:13:30,752:INFO:_master_model_container: 13
2024-02-28 22:13:30,752:INFO:_display_container: 2
2024-02-28 22:13:30,752:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-02-28 22:13:30,752:INFO:create_model() successfully completed......................................
2024-02-28 22:13:30,829:INFO:SubProcess create_model() end ==================================
2024-02-28 22:13:30,829:INFO:Creating metrics dataframe
2024-02-28 22:13:30,844:INFO:Initializing Extra Trees Regressor
2024-02-28 22:13:30,844:INFO:Total runtime is 0.04529647827148438 minutes
2024-02-28 22:13:30,846:INFO:SubProcess create_model() called ==================================
2024-02-28 22:13:30,846:INFO:Initializing create_model()
2024-02-28 22:13:30,846:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571861F0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016056F47F40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:13:30,846:INFO:Checking exceptions
2024-02-28 22:13:30,846:INFO:Importing libraries
2024-02-28 22:13:30,846:INFO:Copying training dataset
2024-02-28 22:13:30,846:INFO:Defining folds
2024-02-28 22:13:30,846:INFO:Declaring metric variables
2024-02-28 22:13:30,852:INFO:Importing untrained model
2024-02-28 22:13:30,855:INFO:Extra Trees Regressor Imported successfully
2024-02-28 22:13:30,859:INFO:Starting cross validation
2024-02-28 22:13:30,860:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:13:30,873:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:13:30,888:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:13:30,898:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:13:30,913:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:13:30,929:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:13:30,947:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:13:30,959:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:13:30,975:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:13:30,990:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:13:30,998:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:13:31,006:INFO:Calculating mean and std
2024-02-28 22:13:31,006:INFO:Creating metrics dataframe
2024-02-28 22:13:31,006:INFO:Uploading results into container
2024-02-28 22:13:31,006:INFO:Uploading model into container now
2024-02-28 22:13:31,006:INFO:_master_model_container: 14
2024-02-28 22:13:31,006:INFO:_display_container: 2
2024-02-28 22:13:31,006:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-02-28 22:13:31,006:INFO:create_model() successfully completed......................................
2024-02-28 22:13:31,083:INFO:SubProcess create_model() end ==================================
2024-02-28 22:13:31,083:INFO:Creating metrics dataframe
2024-02-28 22:13:31,098:INFO:Initializing AdaBoost Regressor
2024-02-28 22:13:31,098:INFO:Total runtime is 0.04952655633290609 minutes
2024-02-28 22:13:31,098:INFO:SubProcess create_model() called ==================================
2024-02-28 22:13:31,098:INFO:Initializing create_model()
2024-02-28 22:13:31,098:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571861F0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016056F47F40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:13:31,098:INFO:Checking exceptions
2024-02-28 22:13:31,098:INFO:Importing libraries
2024-02-28 22:13:31,098:INFO:Copying training dataset
2024-02-28 22:13:31,098:INFO:Defining folds
2024-02-28 22:13:31,098:INFO:Declaring metric variables
2024-02-28 22:13:31,098:INFO:Importing untrained model
2024-02-28 22:13:31,106:INFO:AdaBoost Regressor Imported successfully
2024-02-28 22:13:31,106:INFO:Starting cross validation
2024-02-28 22:13:31,106:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:13:31,644:INFO:Calculating mean and std
2024-02-28 22:13:31,644:INFO:Creating metrics dataframe
2024-02-28 22:13:31,652:INFO:Uploading results into container
2024-02-28 22:13:31,652:INFO:Uploading model into container now
2024-02-28 22:13:31,652:INFO:_master_model_container: 15
2024-02-28 22:13:31,652:INFO:_display_container: 2
2024-02-28 22:13:31,652:INFO:AdaBoostRegressor(random_state=123)
2024-02-28 22:13:31,652:INFO:create_model() successfully completed......................................
2024-02-28 22:13:31,721:INFO:SubProcess create_model() end ==================================
2024-02-28 22:13:31,721:INFO:Creating metrics dataframe
2024-02-28 22:13:31,729:INFO:Initializing Gradient Boosting Regressor
2024-02-28 22:13:31,729:INFO:Total runtime is 0.06004808346430461 minutes
2024-02-28 22:13:31,737:INFO:SubProcess create_model() called ==================================
2024-02-28 22:13:31,737:INFO:Initializing create_model()
2024-02-28 22:13:31,737:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571861F0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016056F47F40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:13:31,737:INFO:Checking exceptions
2024-02-28 22:13:31,737:INFO:Importing libraries
2024-02-28 22:13:31,737:INFO:Copying training dataset
2024-02-28 22:13:31,737:INFO:Defining folds
2024-02-28 22:13:31,737:INFO:Declaring metric variables
2024-02-28 22:13:31,737:INFO:Importing untrained model
2024-02-28 22:13:31,744:INFO:Gradient Boosting Regressor Imported successfully
2024-02-28 22:13:31,744:INFO:Starting cross validation
2024-02-28 22:13:31,744:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:13:32,260:INFO:Calculating mean and std
2024-02-28 22:13:32,260:INFO:Creating metrics dataframe
2024-02-28 22:13:32,260:INFO:Uploading results into container
2024-02-28 22:13:32,260:INFO:Uploading model into container now
2024-02-28 22:13:32,260:INFO:_master_model_container: 16
2024-02-28 22:13:32,260:INFO:_display_container: 2
2024-02-28 22:13:32,260:INFO:GradientBoostingRegressor(random_state=123)
2024-02-28 22:13:32,260:INFO:create_model() successfully completed......................................
2024-02-28 22:13:32,337:INFO:SubProcess create_model() end ==================================
2024-02-28 22:13:32,337:INFO:Creating metrics dataframe
2024-02-28 22:13:32,344:INFO:Initializing Extreme Gradient Boosting
2024-02-28 22:13:32,344:INFO:Total runtime is 0.0703029235204061 minutes
2024-02-28 22:13:32,352:INFO:SubProcess create_model() called ==================================
2024-02-28 22:13:32,352:INFO:Initializing create_model()
2024-02-28 22:13:32,352:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571861F0>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016056F47F40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:13:32,352:INFO:Checking exceptions
2024-02-28 22:13:32,353:INFO:Importing libraries
2024-02-28 22:13:32,353:INFO:Copying training dataset
2024-02-28 22:13:32,353:INFO:Defining folds
2024-02-28 22:13:32,353:INFO:Declaring metric variables
2024-02-28 22:13:32,353:INFO:Importing untrained model
2024-02-28 22:13:32,359:INFO:Extreme Gradient Boosting Imported successfully
2024-02-28 22:13:32,363:INFO:Starting cross validation
2024-02-28 22:13:32,364:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:13:34,675:INFO:Calculating mean and std
2024-02-28 22:13:34,675:INFO:Creating metrics dataframe
2024-02-28 22:13:34,680:INFO:Uploading results into container
2024-02-28 22:13:34,680:INFO:Uploading model into container now
2024-02-28 22:13:34,681:INFO:_master_model_container: 17
2024-02-28 22:13:34,681:INFO:_display_container: 2
2024-02-28 22:13:34,681:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='gpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=123, ...)
2024-02-28 22:13:34,681:INFO:create_model() successfully completed......................................
2024-02-28 22:13:34,775:INFO:SubProcess create_model() end ==================================
2024-02-28 22:13:34,775:INFO:Creating metrics dataframe
2024-02-28 22:13:34,783:INFO:Initializing Light Gradient Boosting Machine
2024-02-28 22:13:34,783:INFO:Total runtime is 0.11094030539194744 minutes
2024-02-28 22:13:34,790:INFO:SubProcess create_model() called ==================================
2024-02-28 22:13:34,790:INFO:Initializing create_model()
2024-02-28 22:13:34,790:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571861F0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016056F47F40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:13:34,790:INFO:Checking exceptions
2024-02-28 22:13:34,790:INFO:Importing libraries
2024-02-28 22:13:34,790:INFO:Copying training dataset
2024-02-28 22:13:34,790:INFO:Defining folds
2024-02-28 22:13:34,790:INFO:Declaring metric variables
2024-02-28 22:13:34,797:INFO:Importing untrained model
2024-02-28 22:13:34,800:INFO:Light Gradient Boosting Machine Imported successfully
2024-02-28 22:13:34,800:INFO:Starting cross validation
2024-02-28 22:13:34,800:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:13:34,813:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-02-28 22:13:34,813:INFO:[LightGBM] [Info] Total Bins 217
2024-02-28 22:13:34,813:INFO:[LightGBM] [Info] Number of data points in the train set: 246, number of used features: 5
2024-02-28 22:13:34,867:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-02-28 22:13:34,867:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-02-28 22:13:34,875:INFO:[LightGBM] [Info] GPU programs have been built
2024-02-28 22:13:34,875:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-02-28 22:13:34,875:INFO:[LightGBM] [Info] 5 dense feature groups (0.00 MB) transferred to GPU in 0.000341 secs. 0 sparse feature groups
2024-02-28 22:13:34,875:INFO:[LightGBM] [Info] Start training from score 23.452033
2024-02-28 22:13:34,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:34,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:34,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:34,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:34,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:34,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:34,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:34,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:34,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:34,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:34,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:34,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:34,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:34,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:34,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:34,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:34,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:34,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:34,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:34,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:34,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:34,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:34,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:34,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:34,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:34,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:34,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:34,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:34,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:34,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:34,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:34,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:34,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:34,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:34,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:34,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:34,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:34,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:34,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:34,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:34,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:34,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:34,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:34,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:34,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:34,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:34,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:34,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:34,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:34,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:34,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:34,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:34,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:34,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:34,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:34,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:34,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:34,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:34,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:34,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:34,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:34,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:34,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:34,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:34,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:34,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:34,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:34,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:34,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:34,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:34,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:34,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:34,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:34,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:34,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:34,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:34,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:34,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:34,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:34,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:34,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:34,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:34,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:34,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:34,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:34,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:34,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:34,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:34,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:34,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:34,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:34,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:34,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:34,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:34,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:34,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:34,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:34,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:34,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,039:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-02-28 22:13:35,044:INFO:[LightGBM] [Info] Total Bins 220
2024-02-28 22:13:35,044:INFO:[LightGBM] [Info] Number of data points in the train set: 246, number of used features: 5
2024-02-28 22:13:35,098:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-02-28 22:13:35,098:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-02-28 22:13:35,106:INFO:[LightGBM] [Info] GPU programs have been built
2024-02-28 22:13:35,106:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-02-28 22:13:35,113:INFO:[LightGBM] [Info] 5 dense feature groups (0.00 MB) transferred to GPU in 0.000506 secs. 0 sparse feature groups
2024-02-28 22:13:35,113:INFO:[LightGBM] [Info] Start training from score 23.622358
2024-02-28 22:13:35,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,267:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-02-28 22:13:35,267:INFO:[LightGBM] [Info] Total Bins 214
2024-02-28 22:13:35,267:INFO:[LightGBM] [Info] Number of data points in the train set: 246, number of used features: 5
2024-02-28 22:13:35,329:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-02-28 22:13:35,329:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-02-28 22:13:35,337:INFO:[LightGBM] [Info] GPU programs have been built
2024-02-28 22:13:35,337:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-02-28 22:13:35,337:INFO:[LightGBM] [Info] 5 dense feature groups (0.00 MB) transferred to GPU in 0.000375 secs. 0 sparse feature groups
2024-02-28 22:13:35,337:INFO:[LightGBM] [Info] Start training from score 23.693902
2024-02-28 22:13:35,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,500:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-02-28 22:13:35,500:INFO:[LightGBM] [Info] Total Bins 218
2024-02-28 22:13:35,500:INFO:[LightGBM] [Info] Number of data points in the train set: 246, number of used features: 5
2024-02-28 22:13:35,560:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-02-28 22:13:35,560:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-02-28 22:13:35,567:INFO:[LightGBM] [Info] GPU programs have been built
2024-02-28 22:13:35,567:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-02-28 22:13:35,567:INFO:[LightGBM] [Info] 5 dense feature groups (0.00 MB) transferred to GPU in 0.000395 secs. 0 sparse feature groups
2024-02-28 22:13:35,567:INFO:[LightGBM] [Info] Start training from score 23.815041
2024-02-28 22:13:35,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,721:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-02-28 22:13:35,721:INFO:[LightGBM] [Info] Total Bins 218
2024-02-28 22:13:35,721:INFO:[LightGBM] [Info] Number of data points in the train set: 247, number of used features: 5
2024-02-28 22:13:35,783:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-02-28 22:13:35,783:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-02-28 22:13:35,790:INFO:[LightGBM] [Info] GPU programs have been built
2024-02-28 22:13:35,790:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-02-28 22:13:35,790:INFO:[LightGBM] [Info] 5 dense feature groups (0.00 MB) transferred to GPU in 0.000359 secs. 0 sparse feature groups
2024-02-28 22:13:35,790:INFO:[LightGBM] [Info] Start training from score 23.681781
2024-02-28 22:13:35,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:35,944:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-02-28 22:13:35,944:INFO:[LightGBM] [Info] Total Bins 219
2024-02-28 22:13:35,944:INFO:[LightGBM] [Info] Number of data points in the train set: 247, number of used features: 5
2024-02-28 22:13:36,006:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-02-28 22:13:36,006:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-02-28 22:13:36,013:INFO:[LightGBM] [Info] GPU programs have been built
2024-02-28 22:13:36,013:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-02-28 22:13:36,013:INFO:[LightGBM] [Info] 5 dense feature groups (0.00 MB) transferred to GPU in 0.000389 secs. 0 sparse feature groups
2024-02-28 22:13:36,013:INFO:[LightGBM] [Info] Start training from score 23.918623
2024-02-28 22:13:36,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,175:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-02-28 22:13:36,175:INFO:[LightGBM] [Info] Total Bins 214
2024-02-28 22:13:36,175:INFO:[LightGBM] [Info] Number of data points in the train set: 247, number of used features: 5
2024-02-28 22:13:36,244:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-02-28 22:13:36,244:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-02-28 22:13:36,250:INFO:[LightGBM] [Info] GPU programs have been built
2024-02-28 22:13:36,252:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-02-28 22:13:36,252:INFO:[LightGBM] [Info] 5 dense feature groups (0.00 MB) transferred to GPU in 0.000479 secs. 0 sparse feature groups
2024-02-28 22:13:36,252:INFO:[LightGBM] [Info] Start training from score 23.956275
2024-02-28 22:13:36,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,413:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-02-28 22:13:36,413:INFO:[LightGBM] [Info] Total Bins 215
2024-02-28 22:13:36,413:INFO:[LightGBM] [Info] Number of data points in the train set: 247, number of used features: 5
2024-02-28 22:13:36,475:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-02-28 22:13:36,475:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-02-28 22:13:36,483:INFO:[LightGBM] [Info] GPU programs have been built
2024-02-28 22:13:36,483:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-02-28 22:13:36,483:INFO:[LightGBM] [Info] 5 dense feature groups (0.00 MB) transferred to GPU in 0.000358 secs. 0 sparse feature groups
2024-02-28 22:13:36,483:INFO:[LightGBM] [Info] Start training from score 23.765182
2024-02-28 22:13:36,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,636:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-02-28 22:13:36,644:INFO:[LightGBM] [Info] Total Bins 214
2024-02-28 22:13:36,644:INFO:[LightGBM] [Info] Number of data points in the train set: 247, number of used features: 5
2024-02-28 22:13:36,698:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-02-28 22:13:36,705:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-02-28 22:13:36,706:INFO:[LightGBM] [Info] GPU programs have been built
2024-02-28 22:13:36,713:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-02-28 22:13:36,713:INFO:[LightGBM] [Info] 5 dense feature groups (0.00 MB) transferred to GPU in 0.000424 secs. 0 sparse feature groups
2024-02-28 22:13:36,713:INFO:[LightGBM] [Info] Start training from score 23.770040
2024-02-28 22:13:36,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,867:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-02-28 22:13:36,867:INFO:[LightGBM] [Info] Total Bins 218
2024-02-28 22:13:36,867:INFO:[LightGBM] [Info] Number of data points in the train set: 247, number of used features: 5
2024-02-28 22:13:36,929:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-02-28 22:13:36,929:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-02-28 22:13:36,936:INFO:[LightGBM] [Info] GPU programs have been built
2024-02-28 22:13:36,936:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-02-28 22:13:36,936:INFO:[LightGBM] [Info] 5 dense feature groups (0.00 MB) transferred to GPU in 0.000443 secs. 0 sparse feature groups
2024-02-28 22:13:36,936:INFO:[LightGBM] [Info] Start training from score 23.837652
2024-02-28 22:13:36,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:36,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:37,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:37,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:37,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:37,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:37,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:37,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:37,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:37,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:37,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:37,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:37,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:37,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:37,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:37,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:37,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:37,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:37,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:37,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:37,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:37,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:37,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:37,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:37,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:37,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:37,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:37,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:37,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:37,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:37,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:37,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:37,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:37,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:37,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:37,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:37,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:37,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:37,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:37,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:37,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:37,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:37,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:37,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:37,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:37,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:37,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:37,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:37,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:37,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:37,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:37,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:13:37,090:INFO:Calculating mean and std
2024-02-28 22:13:37,098:INFO:Creating metrics dataframe
2024-02-28 22:13:37,101:INFO:Uploading results into container
2024-02-28 22:13:37,101:INFO:Uploading model into container now
2024-02-28 22:13:37,101:INFO:_master_model_container: 18
2024-02-28 22:13:37,101:INFO:_display_container: 2
2024-02-28 22:13:37,102:INFO:LGBMRegressor(device='gpu', n_jobs=-1, random_state=123)
2024-02-28 22:13:37,102:INFO:create_model() successfully completed......................................
2024-02-28 22:13:37,198:INFO:SubProcess create_model() end ==================================
2024-02-28 22:13:37,198:INFO:Creating metrics dataframe
2024-02-28 22:13:37,206:INFO:Initializing CatBoost Regressor
2024-02-28 22:13:37,206:INFO:Total runtime is 0.15132612784703572 minutes
2024-02-28 22:13:37,206:INFO:SubProcess create_model() called ==================================
2024-02-28 22:13:37,213:INFO:Initializing create_model()
2024-02-28 22:13:37,213:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571861F0>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016056F47F40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:13:37,213:INFO:Checking exceptions
2024-02-28 22:13:37,213:INFO:Importing libraries
2024-02-28 22:13:37,213:INFO:Copying training dataset
2024-02-28 22:13:37,216:INFO:Defining folds
2024-02-28 22:13:37,216:INFO:Declaring metric variables
2024-02-28 22:13:37,220:INFO:Importing untrained model
2024-02-28 22:13:37,222:INFO:CatBoost Regressor Imported successfully
2024-02-28 22:13:37,223:INFO:Starting cross validation
2024-02-28 22:13:37,229:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:14:56,161:INFO:Calculating mean and std
2024-02-28 22:14:56,161:INFO:Creating metrics dataframe
2024-02-28 22:14:56,169:INFO:Uploading results into container
2024-02-28 22:14:56,169:INFO:Uploading model into container now
2024-02-28 22:14:56,169:INFO:_master_model_container: 19
2024-02-28 22:14:56,169:INFO:_display_container: 2
2024-02-28 22:14:56,169:INFO:<catboost.core.CatBoostRegressor object at 0x00000160653EAA00>
2024-02-28 22:14:56,169:INFO:create_model() successfully completed......................................
2024-02-28 22:14:56,271:INFO:SubProcess create_model() end ==================================
2024-02-28 22:14:56,271:INFO:Creating metrics dataframe
2024-02-28 22:14:56,282:INFO:Initializing Dummy Regressor
2024-02-28 22:14:56,282:INFO:Total runtime is 1.4692664424578348 minutes
2024-02-28 22:14:56,285:INFO:SubProcess create_model() called ==================================
2024-02-28 22:14:56,285:INFO:Initializing create_model()
2024-02-28 22:14:56,285:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571861F0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016056F47F40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:14:56,285:INFO:Checking exceptions
2024-02-28 22:14:56,285:INFO:Importing libraries
2024-02-28 22:14:56,285:INFO:Copying training dataset
2024-02-28 22:14:56,288:INFO:Defining folds
2024-02-28 22:14:56,288:INFO:Declaring metric variables
2024-02-28 22:14:56,291:INFO:Importing untrained model
2024-02-28 22:14:56,294:INFO:Dummy Regressor Imported successfully
2024-02-28 22:14:56,301:INFO:Starting cross validation
2024-02-28 22:14:56,302:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:14:56,401:INFO:Calculating mean and std
2024-02-28 22:14:56,401:INFO:Creating metrics dataframe
2024-02-28 22:14:56,406:INFO:Uploading results into container
2024-02-28 22:14:56,407:INFO:Uploading model into container now
2024-02-28 22:14:56,407:INFO:_master_model_container: 20
2024-02-28 22:14:56,407:INFO:_display_container: 2
2024-02-28 22:14:56,407:INFO:DummyRegressor()
2024-02-28 22:14:56,407:INFO:create_model() successfully completed......................................
2024-02-28 22:14:56,500:INFO:SubProcess create_model() end ==================================
2024-02-28 22:14:56,500:INFO:Creating metrics dataframe
2024-02-28 22:14:56,517:INFO:Initializing create_model()
2024-02-28 22:14:56,517:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571861F0>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:14:56,517:INFO:Checking exceptions
2024-02-28 22:14:56,522:INFO:Importing libraries
2024-02-28 22:14:56,522:INFO:Copying training dataset
2024-02-28 22:14:56,525:INFO:Defining folds
2024-02-28 22:14:56,525:INFO:Declaring metric variables
2024-02-28 22:14:56,525:INFO:Importing untrained model
2024-02-28 22:14:56,525:INFO:Declaring custom model
2024-02-28 22:14:56,526:INFO:Random Forest Regressor Imported successfully
2024-02-28 22:14:56,526:INFO:Cross validation set to False
2024-02-28 22:14:56,526:INFO:Fitting Model
2024-02-28 22:14:56,535:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-02-28 22:14:56,535:INFO:create_model() successfully completed......................................
2024-02-28 22:14:56,649:INFO:_master_model_container: 20
2024-02-28 22:14:56,649:INFO:_display_container: 2
2024-02-28 22:14:56,650:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-02-28 22:14:56,650:INFO:compare_models() successfully completed......................................
2024-02-28 22:15:09,409:INFO:Initializing plot_model()
2024-02-28 22:15:09,409:INFO:plot_model(plot=residuals, fold=None, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571F1E50>, system=True)
2024-02-28 22:15:09,409:INFO:Checking exceptions
2024-02-28 22:15:09,453:INFO:Preloading libraries
2024-02-28 22:15:09,471:INFO:Copying training dataset
2024-02-28 22:15:09,471:INFO:Plot type: residuals
2024-02-28 22:15:09,553:INFO:Fitting Model
2024-02-28 22:15:09,553:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:15:09,553:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:15:09,553:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:15:09,569:INFO:Scoring test/hold-out set
2024-02-28 22:15:09,569:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:15:09,569:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:15:09,921:INFO:Visual Rendered Successfully
2024-02-28 22:15:10,009:INFO:plot_model() successfully completed......................................
2024-02-28 22:15:14,455:INFO:Initializing plot_model()
2024-02-28 22:15:14,455:INFO:plot_model(plot=residuals, fold=None, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571F1E50>, system=True)
2024-02-28 22:15:14,455:INFO:Checking exceptions
2024-02-28 22:15:14,477:INFO:Preloading libraries
2024-02-28 22:15:14,489:INFO:Copying training dataset
2024-02-28 22:15:14,489:INFO:Plot type: residuals
2024-02-28 22:15:14,538:INFO:Fitting Model
2024-02-28 22:15:14,538:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:15:14,538:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:15:14,538:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:15:14,570:INFO:Scoring test/hold-out set
2024-02-28 22:15:14,570:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:15:14,570:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:15:14,800:INFO:Visual Rendered Successfully
2024-02-28 22:15:14,893:INFO:plot_model() successfully completed......................................
2024-02-28 22:15:25,673:INFO:Initializing plot_model()
2024-02-28 22:15:25,673:INFO:plot_model(plot=residuals, fold=None, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571F1E50>, system=True)
2024-02-28 22:15:25,673:INFO:Checking exceptions
2024-02-28 22:15:25,701:INFO:Preloading libraries
2024-02-28 22:15:25,709:INFO:Copying training dataset
2024-02-28 22:15:25,710:INFO:Plot type: residuals
2024-02-28 22:15:25,765:INFO:Fitting Model
2024-02-28 22:15:25,765:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:15:25,766:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:15:25,767:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:15:25,787:INFO:Scoring test/hold-out set
2024-02-28 22:15:25,787:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:15:25,787:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:15:26,023:INFO:Visual Rendered Successfully
2024-02-28 22:15:26,109:INFO:plot_model() successfully completed......................................
2024-02-28 22:15:26,924:INFO:Initializing plot_model()
2024-02-28 22:15:26,924:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571F1E50>, system=True)
2024-02-28 22:15:26,924:INFO:Checking exceptions
2024-02-28 22:15:26,958:INFO:Preloading libraries
2024-02-28 22:15:26,966:INFO:Copying training dataset
2024-02-28 22:15:26,966:INFO:Plot type: error
2024-02-28 22:15:27,004:INFO:Fitting Model
2024-02-28 22:15:27,005:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:15:27,005:INFO:Scoring test/hold-out set
2024-02-28 22:15:27,005:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:15:27,007:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:15:27,151:INFO:Visual Rendered Successfully
2024-02-28 22:15:27,231:INFO:plot_model() successfully completed......................................
2024-02-28 22:15:34,381:INFO:Initializing plot_model()
2024-02-28 22:15:34,381:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571F1E50>, system=True)
2024-02-28 22:15:34,381:INFO:Checking exceptions
2024-02-28 22:15:34,403:INFO:Preloading libraries
2024-02-28 22:15:34,413:INFO:Copying training dataset
2024-02-28 22:15:34,413:INFO:Plot type: error
2024-02-28 22:15:34,456:INFO:Fitting Model
2024-02-28 22:15:34,456:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:15:34,456:INFO:Scoring test/hold-out set
2024-02-28 22:15:34,457:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:15:34,458:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:15:34,592:INFO:Visual Rendered Successfully
2024-02-28 22:15:34,678:INFO:plot_model() successfully completed......................................
2024-02-28 22:15:35,535:INFO:Initializing plot_model()
2024-02-28 22:15:35,535:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571F1E50>, system=True)
2024-02-28 22:15:35,535:INFO:Checking exceptions
2024-02-28 22:15:35,556:INFO:Preloading libraries
2024-02-28 22:15:35,564:INFO:Copying training dataset
2024-02-28 22:15:35,564:INFO:Plot type: feature
2024-02-28 22:15:35,565:WARNING:No coef_ found. Trying feature_importances_
2024-02-28 22:15:35,662:INFO:Visual Rendered Successfully
2024-02-28 22:15:35,754:INFO:plot_model() successfully completed......................................
2024-02-28 22:15:57,225:INFO:Initializing evaluate_model()
2024-02-28 22:15:57,225:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571F1E50>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-02-28 22:15:57,237:INFO:Initializing plot_model()
2024-02-28 22:15:57,237:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571F1E50>, system=True)
2024-02-28 22:15:57,237:INFO:Checking exceptions
2024-02-28 22:15:57,256:INFO:Preloading libraries
2024-02-28 22:15:57,271:INFO:Copying training dataset
2024-02-28 22:15:57,271:INFO:Plot type: pipeline
2024-02-28 22:15:57,347:INFO:Visual Rendered Successfully
2024-02-28 22:15:57,450:INFO:plot_model() successfully completed......................................
2024-02-28 22:15:59,765:INFO:Initializing plot_model()
2024-02-28 22:15:59,765:INFO:plot_model(plot=parameter, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571F1E50>, system=True)
2024-02-28 22:15:59,765:INFO:Checking exceptions
2024-02-28 22:15:59,786:INFO:Preloading libraries
2024-02-28 22:15:59,793:INFO:Copying training dataset
2024-02-28 22:15:59,793:INFO:Plot type: parameter
2024-02-28 22:15:59,793:INFO:Visual Rendered Successfully
2024-02-28 22:15:59,881:INFO:plot_model() successfully completed......................................
2024-02-28 22:16:00,673:INFO:Initializing plot_model()
2024-02-28 22:16:00,673:INFO:plot_model(plot=residuals, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571F1E50>, system=True)
2024-02-28 22:16:00,673:INFO:Checking exceptions
2024-02-28 22:16:00,709:INFO:Preloading libraries
2024-02-28 22:16:00,709:INFO:Copying training dataset
2024-02-28 22:16:00,709:INFO:Plot type: residuals
2024-02-28 22:16:00,771:INFO:Fitting Model
2024-02-28 22:16:00,771:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:16:00,771:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:16:00,771:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:16:00,787:INFO:Scoring test/hold-out set
2024-02-28 22:16:00,787:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:16:00,787:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:16:01,041:INFO:Visual Rendered Successfully
2024-02-28 22:16:01,131:INFO:plot_model() successfully completed......................................
2024-02-28 22:16:01,340:INFO:Initializing plot_model()
2024-02-28 22:16:01,340:INFO:plot_model(plot=parameter, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571F1E50>, system=True)
2024-02-28 22:16:01,340:INFO:Checking exceptions
2024-02-28 22:16:01,364:INFO:Preloading libraries
2024-02-28 22:16:01,369:INFO:Copying training dataset
2024-02-28 22:16:01,369:INFO:Plot type: parameter
2024-02-28 22:16:01,369:INFO:Visual Rendered Successfully
2024-02-28 22:16:01,447:INFO:plot_model() successfully completed......................................
2024-02-28 22:16:11,981:INFO:Initializing plot_model()
2024-02-28 22:16:11,981:INFO:plot_model(plot=residuals, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571F1E50>, system=True)
2024-02-28 22:16:11,983:INFO:Checking exceptions
2024-02-28 22:16:12,003:INFO:Preloading libraries
2024-02-28 22:16:12,012:INFO:Copying training dataset
2024-02-28 22:16:12,012:INFO:Plot type: residuals
2024-02-28 22:16:12,057:INFO:Fitting Model
2024-02-28 22:16:12,057:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:16:12,057:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:16:12,065:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:16:12,073:INFO:Scoring test/hold-out set
2024-02-28 22:16:12,073:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:16:12,089:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:16:12,322:INFO:Visual Rendered Successfully
2024-02-28 22:16:12,411:INFO:plot_model() successfully completed......................................
2024-02-28 22:16:14,920:INFO:Initializing plot_model()
2024-02-28 22:16:14,921:INFO:plot_model(plot=error, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571F1E50>, system=True)
2024-02-28 22:16:14,921:INFO:Checking exceptions
2024-02-28 22:16:14,940:INFO:Preloading libraries
2024-02-28 22:16:14,947:INFO:Copying training dataset
2024-02-28 22:16:14,947:INFO:Plot type: error
2024-02-28 22:16:14,979:INFO:Fitting Model
2024-02-28 22:16:14,979:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:16:14,979:INFO:Scoring test/hold-out set
2024-02-28 22:16:14,979:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:16:14,995:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:16:15,150:INFO:Visual Rendered Successfully
2024-02-28 22:16:15,236:INFO:plot_model() successfully completed......................................
2024-02-28 22:16:15,711:INFO:Initializing plot_model()
2024-02-28 22:16:15,711:INFO:plot_model(plot=feature_all, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571F1E50>, system=True)
2024-02-28 22:16:15,711:INFO:Checking exceptions
2024-02-28 22:16:15,733:INFO:Preloading libraries
2024-02-28 22:16:15,741:INFO:Copying training dataset
2024-02-28 22:16:15,741:INFO:Plot type: feature_all
2024-02-28 22:16:15,741:WARNING:No coef_ found. Trying feature_importances_
2024-02-28 22:16:15,830:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\matplotlib\_tight_bbox.py:67: RuntimeWarning: divide by zero encountered in scalar divide
  fig.patch.set_bounds(x0 / w1, y0 / h1,

2024-02-28 22:16:15,830:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\matplotlib\_tight_bbox.py:68: RuntimeWarning: divide by zero encountered in scalar divide
  fig.bbox.width / w1, fig.bbox.height / h1)

2024-02-28 22:16:15,830:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\matplotlib\patches.py:739: RuntimeWarning: invalid value encountered in scalar add
  y1 = self.convert_yunits(self._y0 + self._height)

2024-02-28 22:16:15,830:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\matplotlib\transforms.py:2050: RuntimeWarning: invalid value encountered in scalar add
  self._mtx[1, 2] += ty

2024-02-28 22:16:15,850:INFO:Visual Rendered Successfully
2024-02-28 22:16:15,929:INFO:plot_model() successfully completed......................................
2024-02-28 22:16:17,177:INFO:Initializing plot_model()
2024-02-28 22:16:17,177:INFO:plot_model(plot=tree, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571F1E50>, system=True)
2024-02-28 22:16:17,177:INFO:Checking exceptions
2024-02-28 22:16:17,202:INFO:Preloading libraries
2024-02-28 22:16:17,202:INFO:Copying training dataset
2024-02-28 22:16:17,202:INFO:Plot type: tree
2024-02-28 22:16:18,147:INFO:Plotting decision trees
2024-02-28 22:16:18,157:INFO:Plotting tree 0
2024-02-28 22:16:18,781:INFO:Plotting tree 1
2024-02-28 22:16:19,157:INFO:Plotting tree 2
2024-02-28 22:16:19,653:INFO:Plotting tree 3
2024-02-28 22:16:20,016:INFO:Plotting tree 4
2024-02-28 22:16:20,397:INFO:Plotting tree 5
2024-02-28 22:16:20,765:INFO:Plotting tree 6
2024-02-28 22:16:21,111:INFO:Plotting tree 7
2024-02-28 22:16:21,491:INFO:Plotting tree 8
2024-02-28 22:16:21,864:INFO:Plotting tree 9
2024-02-28 22:16:22,236:INFO:Plotting tree 10
2024-02-28 22:16:22,613:INFO:Plotting tree 11
2024-02-28 22:16:22,972:INFO:Plotting tree 12
2024-02-28 22:16:23,447:INFO:Plotting tree 13
2024-02-28 22:16:23,804:INFO:Plotting tree 14
2024-02-28 22:16:24,144:INFO:Plotting tree 15
2024-02-28 22:16:24,507:INFO:Plotting tree 16
2024-02-28 22:16:24,863:INFO:Plotting tree 17
2024-02-28 22:16:25,201:INFO:Plotting tree 18
2024-02-28 22:16:25,532:INFO:Plotting tree 19
2024-02-28 22:16:25,902:INFO:Plotting tree 20
2024-02-28 22:16:26,262:INFO:Plotting tree 21
2024-02-28 22:16:26,648:INFO:Plotting tree 22
2024-02-28 22:16:27,024:INFO:Plotting tree 23
2024-02-28 22:18:53,091:INFO:Initializing evaluate_model()
2024-02-28 22:18:53,091:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571F1E50>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-02-28 22:18:53,095:INFO:Initializing plot_model()
2024-02-28 22:18:53,095:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571F1E50>, system=True)
2024-02-28 22:18:53,095:INFO:Checking exceptions
2024-02-28 22:18:53,119:INFO:Preloading libraries
2024-02-28 22:18:53,131:INFO:Copying training dataset
2024-02-28 22:18:53,131:INFO:Plot type: pipeline
2024-02-28 22:18:53,193:INFO:Visual Rendered Successfully
2024-02-28 22:18:53,508:INFO:plot_model() successfully completed......................................
2024-02-28 22:18:53,533:INFO:Initializing predict_model()
2024-02-28 22:18:53,534:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571F1E50>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000016027FEC280>)
2024-02-28 22:18:53,534:INFO:Checking exceptions
2024-02-28 22:18:53,534:INFO:Preloading libraries
2024-02-28 22:18:53,558:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:18:53,558:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(

2024-02-28 22:18:53,925:INFO:Initializing predict_model()
2024-02-28 22:18:53,925:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571F1E50>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000016027F941F0>)
2024-02-28 22:18:53,925:INFO:Checking exceptions
2024-02-28 22:18:53,925:INFO:Preloading libraries
2024-02-28 22:18:53,950:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:18:53,951:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(

2024-02-28 22:18:54,252:INFO:Initializing plot_model()
2024-02-28 22:18:54,252:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571F1E50>, system=True)
2024-02-28 22:18:54,252:INFO:Checking exceptions
2024-02-28 22:18:54,273:INFO:Preloading libraries
2024-02-28 22:18:54,273:INFO:Copying training dataset
2024-02-28 22:18:54,273:INFO:Plot type: pipeline
2024-02-28 22:18:54,319:INFO:Visual Rendered Successfully
2024-02-28 22:18:54,620:INFO:plot_model() successfully completed......................................
2024-02-28 22:22:17,084:INFO:PyCaret RegressionExperiment
2024-02-28 22:22:17,084:INFO:Logging name: reg-default-name
2024-02-28 22:22:17,084:INFO:ML Usecase: MLUsecase.REGRESSION
2024-02-28 22:22:17,084:INFO:version 3.3.0
2024-02-28 22:22:17,084:INFO:Initializing setup()
2024-02-28 22:22:17,084:INFO:self.USI: 4f76
2024-02-28 22:22:17,084:INFO:self._variable_keys: {'logging_param', '_ml_usecase', 'target_param', 'X_train', 'idx', 'data', 'y', 'exp_name_log', 'X_test', 'transform_target_param', 'log_plots_param', 'memory', 'html_param', '_available_plots', 'gpu_n_jobs_param', 'y_train', 'seed', 'USI', 'pipeline', 'exp_id', 'y_test', 'gpu_param', 'fold_shuffle_param', 'fold_generator', 'fold_groups_param', 'X', 'n_jobs_param'}
2024-02-28 22:22:17,084:INFO:Checking environment
2024-02-28 22:22:17,084:INFO:python_version: 3.9.18
2024-02-28 22:22:17,084:INFO:python_build: ('main', 'Dec 23 2023 16:29:04')
2024-02-28 22:22:17,084:INFO:machine: AMD64
2024-02-28 22:22:17,084:INFO:platform: Windows-10-10.0.22621-SP0
2024-02-28 22:22:17,084:INFO:Memory: svmem(total=34228445184, available=19693494272, percent=42.5, used=14534950912, free=19693494272)
2024-02-28 22:22:17,084:INFO:Physical Core: 8
2024-02-28 22:22:17,084:INFO:Logical Core: 16
2024-02-28 22:22:17,084:INFO:Checking libraries
2024-02-28 22:22:17,084:INFO:System:
2024-02-28 22:22:17,084:INFO:    python: 3.9.18 | packaged by conda-forge | (main, Dec 23 2023, 16:29:04) [MSC v.1929 64 bit (AMD64)]
2024-02-28 22:22:17,084:INFO:executable: c:\Users\Administrator\anaconda3\envs\EXAM_ML\python.exe
2024-02-28 22:22:17,084:INFO:   machine: Windows-10-10.0.22621-SP0
2024-02-28 22:22:17,084:INFO:PyCaret required dependencies:
2024-02-28 22:22:17,084:INFO:                 pip: 24.0
2024-02-28 22:22:17,084:INFO:          setuptools: 69.1.1
2024-02-28 22:22:17,084:INFO:             pycaret: 3.3.0
2024-02-28 22:22:17,084:INFO:             IPython: 8.12.0
2024-02-28 22:22:17,084:INFO:          ipywidgets: 8.1.2
2024-02-28 22:22:17,084:INFO:                tqdm: 4.66.2
2024-02-28 22:22:17,084:INFO:               numpy: 1.25.2
2024-02-28 22:22:17,084:INFO:              pandas: 1.5.3
2024-02-28 22:22:17,084:INFO:              jinja2: 3.1.3
2024-02-28 22:22:17,084:INFO:               scipy: 1.11.4
2024-02-28 22:22:17,084:INFO:              joblib: 1.3.2
2024-02-28 22:22:17,084:INFO:             sklearn: 1.4.1.post1
2024-02-28 22:22:17,084:INFO:                pyod: 1.1.3
2024-02-28 22:22:17,084:INFO:            imblearn: 0.12.0
2024-02-28 22:22:17,084:INFO:   category_encoders: 2.6.3
2024-02-28 22:22:17,084:INFO:            lightgbm: 4.3.0
2024-02-28 22:22:17,084:INFO:               numba: 0.58.1
2024-02-28 22:22:17,084:INFO:            requests: 2.31.0
2024-02-28 22:22:17,084:INFO:          matplotlib: 3.7.5
2024-02-28 22:22:17,084:INFO:          scikitplot: 0.3.7
2024-02-28 22:22:17,084:INFO:         yellowbrick: 1.5
2024-02-28 22:22:17,084:INFO:              plotly: 5.19.0
2024-02-28 22:22:17,084:INFO:    plotly-resampler: Not installed
2024-02-28 22:22:17,084:INFO:             kaleido: 0.2.1
2024-02-28 22:22:17,084:INFO:           schemdraw: 0.15
2024-02-28 22:22:17,084:INFO:         statsmodels: 0.14.1
2024-02-28 22:22:17,084:INFO:              sktime: 0.27.0
2024-02-28 22:22:17,084:INFO:               tbats: 1.1.3
2024-02-28 22:22:17,084:INFO:            pmdarima: 2.0.4
2024-02-28 22:22:17,084:INFO:              psutil: 5.9.8
2024-02-28 22:22:17,084:INFO:          markupsafe: 2.1.5
2024-02-28 22:22:17,084:INFO:             pickle5: Not installed
2024-02-28 22:22:17,084:INFO:         cloudpickle: 3.0.0
2024-02-28 22:22:17,084:INFO:         deprecation: 2.1.0
2024-02-28 22:22:17,084:INFO:              xxhash: 3.4.1
2024-02-28 22:22:17,084:INFO:           wurlitzer: Not installed
2024-02-28 22:22:17,084:INFO:PyCaret optional dependencies:
2024-02-28 22:22:17,084:INFO:                shap: 0.44.1
2024-02-28 22:22:17,084:INFO:           interpret: 0.5.1
2024-02-28 22:22:17,084:INFO:                umap: 0.5.5
2024-02-28 22:22:17,084:INFO:     ydata_profiling: 4.6.5
2024-02-28 22:22:17,084:INFO:  explainerdashboard: 0.4.5
2024-02-28 22:22:17,084:INFO:             autoviz: Not installed
2024-02-28 22:22:17,084:INFO:           fairlearn: 0.7.0
2024-02-28 22:22:17,084:INFO:          deepchecks: Not installed
2024-02-28 22:22:17,084:INFO:             xgboost: 2.0.3
2024-02-28 22:22:17,084:INFO:            catboost: 1.2.3
2024-02-28 22:22:17,084:INFO:              kmodes: 0.12.2
2024-02-28 22:22:17,084:INFO:             mlxtend: 0.23.1
2024-02-28 22:22:17,084:INFO:       statsforecast: 1.5.0
2024-02-28 22:22:17,084:INFO:        tune_sklearn: 0.5.0
2024-02-28 22:22:17,084:INFO:                 ray: 2.9.3
2024-02-28 22:22:17,084:INFO:            hyperopt: 0.2.7
2024-02-28 22:22:17,084:INFO:              optuna: 3.5.0
2024-02-28 22:22:17,084:INFO:               skopt: 0.9.0
2024-02-28 22:22:17,084:INFO:              mlflow: 2.10.2
2024-02-28 22:22:17,084:INFO:              gradio: 4.19.2
2024-02-28 22:22:17,084:INFO:             fastapi: 0.110.0
2024-02-28 22:22:17,084:INFO:             uvicorn: 0.27.1
2024-02-28 22:22:17,084:INFO:              m2cgen: 0.10.0
2024-02-28 22:22:17,084:INFO:           evidently: 0.4.16
2024-02-28 22:22:17,084:INFO:               fugue: 0.8.6
2024-02-28 22:22:17,084:INFO:           streamlit: Not installed
2024-02-28 22:22:17,084:INFO:             prophet: Not installed
2024-02-28 22:22:17,084:INFO:None
2024-02-28 22:22:17,084:INFO:Set up data.
2024-02-28 22:22:17,091:INFO:Set up folding strategy.
2024-02-28 22:22:17,091:INFO:Set up train/test split.
2024-02-28 22:22:17,091:INFO:Set up index.
2024-02-28 22:22:17,091:INFO:Assigning column types.
2024-02-28 22:22:17,099:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-02-28 22:22:17,169:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:22:17,169:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:22:17,270:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:22:17,270:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:22:17,276:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-02-28 22:22:17,355:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:22:17,355:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:22:17,439:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:22:17,439:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:22:17,439:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-02-28 22:22:17,500:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:22:17,516:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:22:17,584:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:22:17,584:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:22:17,584:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-02-28 22:22:17,654:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:22:17,654:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:22:17,739:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:22:17,739:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:22:17,739:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-02-28 22:22:17,808:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:22:17,808:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:22:17,878:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:22:17,894:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:22:17,894:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-02-28 22:22:17,961:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:22:17,969:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:22:18,038:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:22:18,045:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:22:18,045:INFO:Preparing preprocessing pipeline...
2024-02-28 22:22:18,045:INFO:Set up simple imputation.
2024-02-28 22:22:18,054:INFO:Finished creating preprocessing pipeline.
2024-02-28 22:22:18,054:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['cylinders', 'displacement',
                                             'horsepower', 'weight',
                                             'acceleration'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2024-02-28 22:22:18,054:INFO:Creating final display dataframe.
2024-02-28 22:22:18,086:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target               mpg
2                   Target type        Regression
3           Original data shape          (392, 6)
4        Transformed data shape          (392, 6)
5   Transformed train set shape          (274, 6)
6    Transformed test set shape          (118, 6)
7              Numeric features                 5
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              4f76
2024-02-28 22:22:18,179:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:22:18,179:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:22:18,263:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:22:18,263:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:22:18,263:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\internal\metrics.py:51: FutureWarning: The `needs_threshold` and `needs_proba` parameter are deprecated in version 1.4 and will be removed in 1.6. You can either let `response_method` be `None` or set it to `predict` to preserve the same behaviour.
  warnings.warn(

2024-02-28 22:22:18,263:INFO:setup() successfully completed in 1.18s...............
2024-02-28 22:22:21,335:INFO:PyCaret RegressionExperiment
2024-02-28 22:22:21,335:INFO:Logging name: reg-default-name
2024-02-28 22:22:21,335:INFO:ML Usecase: MLUsecase.REGRESSION
2024-02-28 22:22:21,335:INFO:version 3.3.0
2024-02-28 22:22:21,335:INFO:Initializing setup()
2024-02-28 22:22:21,335:INFO:self.USI: c79a
2024-02-28 22:22:21,335:INFO:self._variable_keys: {'logging_param', '_ml_usecase', 'target_param', 'X_train', 'idx', 'data', 'y', 'exp_name_log', 'X_test', 'transform_target_param', 'log_plots_param', 'memory', 'html_param', '_available_plots', 'gpu_n_jobs_param', 'y_train', 'seed', 'USI', 'pipeline', 'exp_id', 'y_test', 'gpu_param', 'fold_shuffle_param', 'fold_generator', 'fold_groups_param', 'X', 'n_jobs_param'}
2024-02-28 22:22:21,335:INFO:Checking environment
2024-02-28 22:22:21,335:INFO:python_version: 3.9.18
2024-02-28 22:22:21,335:INFO:python_build: ('main', 'Dec 23 2023 16:29:04')
2024-02-28 22:22:21,335:INFO:machine: AMD64
2024-02-28 22:22:21,335:INFO:platform: Windows-10-10.0.22621-SP0
2024-02-28 22:22:21,337:INFO:Memory: svmem(total=34228445184, available=19662528512, percent=42.6, used=14565916672, free=19662528512)
2024-02-28 22:22:21,337:INFO:Physical Core: 8
2024-02-28 22:22:21,337:INFO:Logical Core: 16
2024-02-28 22:22:21,337:INFO:Checking libraries
2024-02-28 22:22:21,337:INFO:System:
2024-02-28 22:22:21,337:INFO:    python: 3.9.18 | packaged by conda-forge | (main, Dec 23 2023, 16:29:04) [MSC v.1929 64 bit (AMD64)]
2024-02-28 22:22:21,337:INFO:executable: c:\Users\Administrator\anaconda3\envs\EXAM_ML\python.exe
2024-02-28 22:22:21,337:INFO:   machine: Windows-10-10.0.22621-SP0
2024-02-28 22:22:21,337:INFO:PyCaret required dependencies:
2024-02-28 22:22:21,337:INFO:                 pip: 24.0
2024-02-28 22:22:21,337:INFO:          setuptools: 69.1.1
2024-02-28 22:22:21,338:INFO:             pycaret: 3.3.0
2024-02-28 22:22:21,338:INFO:             IPython: 8.12.0
2024-02-28 22:22:21,338:INFO:          ipywidgets: 8.1.2
2024-02-28 22:22:21,338:INFO:                tqdm: 4.66.2
2024-02-28 22:22:21,338:INFO:               numpy: 1.25.2
2024-02-28 22:22:21,338:INFO:              pandas: 1.5.3
2024-02-28 22:22:21,338:INFO:              jinja2: 3.1.3
2024-02-28 22:22:21,338:INFO:               scipy: 1.11.4
2024-02-28 22:22:21,338:INFO:              joblib: 1.3.2
2024-02-28 22:22:21,338:INFO:             sklearn: 1.4.1.post1
2024-02-28 22:22:21,338:INFO:                pyod: 1.1.3
2024-02-28 22:22:21,338:INFO:            imblearn: 0.12.0
2024-02-28 22:22:21,338:INFO:   category_encoders: 2.6.3
2024-02-28 22:22:21,338:INFO:            lightgbm: 4.3.0
2024-02-28 22:22:21,338:INFO:               numba: 0.58.1
2024-02-28 22:22:21,338:INFO:            requests: 2.31.0
2024-02-28 22:22:21,338:INFO:          matplotlib: 3.7.5
2024-02-28 22:22:21,338:INFO:          scikitplot: 0.3.7
2024-02-28 22:22:21,338:INFO:         yellowbrick: 1.5
2024-02-28 22:22:21,338:INFO:              plotly: 5.19.0
2024-02-28 22:22:21,338:INFO:    plotly-resampler: Not installed
2024-02-28 22:22:21,338:INFO:             kaleido: 0.2.1
2024-02-28 22:22:21,338:INFO:           schemdraw: 0.15
2024-02-28 22:22:21,338:INFO:         statsmodels: 0.14.1
2024-02-28 22:22:21,338:INFO:              sktime: 0.27.0
2024-02-28 22:22:21,338:INFO:               tbats: 1.1.3
2024-02-28 22:22:21,338:INFO:            pmdarima: 2.0.4
2024-02-28 22:22:21,338:INFO:              psutil: 5.9.8
2024-02-28 22:22:21,338:INFO:          markupsafe: 2.1.5
2024-02-28 22:22:21,338:INFO:             pickle5: Not installed
2024-02-28 22:22:21,338:INFO:         cloudpickle: 3.0.0
2024-02-28 22:22:21,338:INFO:         deprecation: 2.1.0
2024-02-28 22:22:21,338:INFO:              xxhash: 3.4.1
2024-02-28 22:22:21,338:INFO:           wurlitzer: Not installed
2024-02-28 22:22:21,338:INFO:PyCaret optional dependencies:
2024-02-28 22:22:21,338:INFO:                shap: 0.44.1
2024-02-28 22:22:21,338:INFO:           interpret: 0.5.1
2024-02-28 22:22:21,338:INFO:                umap: 0.5.5
2024-02-28 22:22:21,339:INFO:     ydata_profiling: 4.6.5
2024-02-28 22:22:21,339:INFO:  explainerdashboard: 0.4.5
2024-02-28 22:22:21,339:INFO:             autoviz: Not installed
2024-02-28 22:22:21,339:INFO:           fairlearn: 0.7.0
2024-02-28 22:22:21,339:INFO:          deepchecks: Not installed
2024-02-28 22:22:21,339:INFO:             xgboost: 2.0.3
2024-02-28 22:22:21,339:INFO:            catboost: 1.2.3
2024-02-28 22:22:21,339:INFO:              kmodes: 0.12.2
2024-02-28 22:22:21,339:INFO:             mlxtend: 0.23.1
2024-02-28 22:22:21,339:INFO:       statsforecast: 1.5.0
2024-02-28 22:22:21,339:INFO:        tune_sklearn: 0.5.0
2024-02-28 22:22:21,339:INFO:                 ray: 2.9.3
2024-02-28 22:22:21,339:INFO:            hyperopt: 0.2.7
2024-02-28 22:22:21,339:INFO:              optuna: 3.5.0
2024-02-28 22:22:21,339:INFO:               skopt: 0.9.0
2024-02-28 22:22:21,339:INFO:              mlflow: 2.10.2
2024-02-28 22:22:21,339:INFO:              gradio: 4.19.2
2024-02-28 22:22:21,339:INFO:             fastapi: 0.110.0
2024-02-28 22:22:21,339:INFO:             uvicorn: 0.27.1
2024-02-28 22:22:21,339:INFO:              m2cgen: 0.10.0
2024-02-28 22:22:21,339:INFO:           evidently: 0.4.16
2024-02-28 22:22:21,339:INFO:               fugue: 0.8.6
2024-02-28 22:22:21,339:INFO:           streamlit: Not installed
2024-02-28 22:22:21,339:INFO:             prophet: Not installed
2024-02-28 22:22:21,339:INFO:None
2024-02-28 22:22:21,339:INFO:Set up data.
2024-02-28 22:22:21,342:INFO:Set up folding strategy.
2024-02-28 22:22:21,342:INFO:Set up train/test split.
2024-02-28 22:22:21,345:INFO:Set up index.
2024-02-28 22:22:21,345:INFO:Assigning column types.
2024-02-28 22:22:21,347:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-02-28 22:22:21,418:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:22:21,422:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:22:21,492:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:22:21,492:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:22:21,492:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-02-28 22:22:21,569:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:22:21,569:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:22:21,646:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:22:21,646:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:22:21,646:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-02-28 22:22:21,715:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:22:21,722:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:22:21,793:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:22:21,793:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:22:21,793:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-02-28 22:22:21,869:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:22:21,869:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:22:21,946:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:22:21,946:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:22:21,946:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-02-28 22:22:22,022:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:22:22,022:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:22:22,092:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:22:22,099:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:22:22,099:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-02-28 22:22:22,169:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:22:22,169:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:22:22,246:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:22:22,253:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:22:22,253:INFO:Preparing preprocessing pipeline...
2024-02-28 22:22:22,253:INFO:Set up simple imputation.
2024-02-28 22:22:22,261:INFO:Finished creating preprocessing pipeline.
2024-02-28 22:22:22,269:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['cylinders', 'displacement',
                                             'horsepower', 'weight',
                                             'acceleration'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2024-02-28 22:22:22,269:INFO:Creating final display dataframe.
2024-02-28 22:22:22,299:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target               mpg
2                   Target type        Regression
3           Original data shape          (392, 6)
4        Transformed data shape          (392, 6)
5   Transformed train set shape          (274, 6)
6    Transformed test set shape          (118, 6)
7              Numeric features                 5
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              c79a
2024-02-28 22:22:22,385:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:22:22,385:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:22:22,461:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:22:22,461:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:22:22,461:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\internal\metrics.py:51: FutureWarning: The `needs_threshold` and `needs_proba` parameter are deprecated in version 1.4 and will be removed in 1.6. You can either let `response_method` be `None` or set it to `predict` to preserve the same behaviour.
  warnings.warn(

2024-02-28 22:22:22,461:INFO:setup() successfully completed in 1.13s...............
2024-02-28 22:22:32,086:INFO:Initializing compare_models()
2024-02-28 22:22:32,086:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571861F0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000160571861F0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-02-28 22:22:32,086:INFO:Checking exceptions
2024-02-28 22:22:32,086:INFO:Preparing display monitor
2024-02-28 22:22:32,104:INFO:Initializing Linear Regression
2024-02-28 22:22:32,104:INFO:Total runtime is 0.0 minutes
2024-02-28 22:22:32,106:INFO:SubProcess create_model() called ==================================
2024-02-28 22:22:32,107:INFO:Initializing create_model()
2024-02-28 22:22:32,107:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571861F0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000160237EC160>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:22:32,107:INFO:Checking exceptions
2024-02-28 22:22:32,107:INFO:Importing libraries
2024-02-28 22:22:32,107:INFO:Copying training dataset
2024-02-28 22:22:32,109:INFO:Defining folds
2024-02-28 22:22:32,109:INFO:Declaring metric variables
2024-02-28 22:22:32,111:INFO:Importing untrained model
2024-02-28 22:22:32,113:INFO:Linear Regression Imported successfully
2024-02-28 22:22:32,118:INFO:Starting cross validation
2024-02-28 22:22:32,119:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-28 22:22:34,969:INFO:Calculating mean and std
2024-02-28 22:22:34,969:INFO:Creating metrics dataframe
2024-02-28 22:22:34,973:INFO:Uploading results into container
2024-02-28 22:22:34,974:INFO:Uploading model into container now
2024-02-28 22:22:34,974:INFO:_master_model_container: 21
2024-02-28 22:22:34,974:INFO:_display_container: 2
2024-02-28 22:22:34,975:INFO:LinearRegression(n_jobs=-1)
2024-02-28 22:22:34,975:INFO:create_model() successfully completed......................................
2024-02-28 22:22:35,284:INFO:SubProcess create_model() end ==================================
2024-02-28 22:22:35,284:INFO:Creating metrics dataframe
2024-02-28 22:22:35,292:INFO:Initializing Lasso Regression
2024-02-28 22:22:35,292:INFO:Total runtime is 0.0531349778175354 minutes
2024-02-28 22:22:35,297:INFO:SubProcess create_model() called ==================================
2024-02-28 22:22:35,297:INFO:Initializing create_model()
2024-02-28 22:22:35,297:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571861F0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000160237EC160>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:22:35,297:INFO:Checking exceptions
2024-02-28 22:22:35,297:INFO:Importing libraries
2024-02-28 22:22:35,297:INFO:Copying training dataset
2024-02-28 22:22:35,300:INFO:Defining folds
2024-02-28 22:22:35,300:INFO:Declaring metric variables
2024-02-28 22:22:35,302:INFO:Importing untrained model
2024-02-28 22:22:35,305:INFO:Lasso Regression Imported successfully
2024-02-28 22:22:35,308:INFO:Starting cross validation
2024-02-28 22:22:35,310:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-28 22:22:37,216:INFO:Calculating mean and std
2024-02-28 22:22:37,216:INFO:Creating metrics dataframe
2024-02-28 22:22:37,221:INFO:Uploading results into container
2024-02-28 22:22:37,222:INFO:Uploading model into container now
2024-02-28 22:22:37,222:INFO:_master_model_container: 22
2024-02-28 22:22:37,222:INFO:_display_container: 2
2024-02-28 22:22:37,222:INFO:Lasso(random_state=123)
2024-02-28 22:22:37,222:INFO:create_model() successfully completed......................................
2024-02-28 22:22:37,538:INFO:SubProcess create_model() end ==================================
2024-02-28 22:22:37,538:INFO:Creating metrics dataframe
2024-02-28 22:22:37,538:INFO:Initializing Ridge Regression
2024-02-28 22:22:37,538:INFO:Total runtime is 0.09056812524795532 minutes
2024-02-28 22:22:37,547:INFO:SubProcess create_model() called ==================================
2024-02-28 22:22:37,548:INFO:Initializing create_model()
2024-02-28 22:22:37,548:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571861F0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000160237EC160>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:22:37,548:INFO:Checking exceptions
2024-02-28 22:22:37,548:INFO:Importing libraries
2024-02-28 22:22:37,548:INFO:Copying training dataset
2024-02-28 22:22:37,548:INFO:Defining folds
2024-02-28 22:22:37,548:INFO:Declaring metric variables
2024-02-28 22:22:37,553:INFO:Importing untrained model
2024-02-28 22:22:37,555:INFO:Ridge Regression Imported successfully
2024-02-28 22:22:37,555:INFO:Starting cross validation
2024-02-28 22:22:37,561:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-28 22:22:37,615:INFO:Calculating mean and std
2024-02-28 22:22:37,615:INFO:Creating metrics dataframe
2024-02-28 22:22:37,615:INFO:Uploading results into container
2024-02-28 22:22:37,615:INFO:Uploading model into container now
2024-02-28 22:22:37,615:INFO:_master_model_container: 23
2024-02-28 22:22:37,615:INFO:_display_container: 2
2024-02-28 22:22:37,615:INFO:Ridge(random_state=123)
2024-02-28 22:22:37,615:INFO:create_model() successfully completed......................................
2024-02-28 22:22:37,915:INFO:SubProcess create_model() end ==================================
2024-02-28 22:22:37,915:INFO:Creating metrics dataframe
2024-02-28 22:22:37,923:INFO:Initializing Elastic Net
2024-02-28 22:22:37,923:INFO:Total runtime is 0.09697641134262085 minutes
2024-02-28 22:22:37,930:INFO:SubProcess create_model() called ==================================
2024-02-28 22:22:37,930:INFO:Initializing create_model()
2024-02-28 22:22:37,930:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571861F0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000160237EC160>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:22:37,930:INFO:Checking exceptions
2024-02-28 22:22:37,930:INFO:Importing libraries
2024-02-28 22:22:37,930:INFO:Copying training dataset
2024-02-28 22:22:37,930:INFO:Defining folds
2024-02-28 22:22:37,930:INFO:Declaring metric variables
2024-02-28 22:22:37,936:INFO:Importing untrained model
2024-02-28 22:22:37,938:INFO:Elastic Net Imported successfully
2024-02-28 22:22:37,941:INFO:Starting cross validation
2024-02-28 22:22:37,941:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-28 22:22:37,992:INFO:Calculating mean and std
2024-02-28 22:22:37,992:INFO:Creating metrics dataframe
2024-02-28 22:22:37,992:INFO:Uploading results into container
2024-02-28 22:22:37,992:INFO:Uploading model into container now
2024-02-28 22:22:37,992:INFO:_master_model_container: 24
2024-02-28 22:22:37,992:INFO:_display_container: 2
2024-02-28 22:22:37,992:INFO:ElasticNet(random_state=123)
2024-02-28 22:22:37,992:INFO:create_model() successfully completed......................................
2024-02-28 22:22:38,284:INFO:SubProcess create_model() end ==================================
2024-02-28 22:22:38,284:INFO:Creating metrics dataframe
2024-02-28 22:22:38,284:INFO:Initializing Least Angle Regression
2024-02-28 22:22:38,284:INFO:Total runtime is 0.10300236543019613 minutes
2024-02-28 22:22:38,292:INFO:SubProcess create_model() called ==================================
2024-02-28 22:22:38,292:INFO:Initializing create_model()
2024-02-28 22:22:38,292:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571861F0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000160237EC160>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:22:38,292:INFO:Checking exceptions
2024-02-28 22:22:38,292:INFO:Importing libraries
2024-02-28 22:22:38,292:INFO:Copying training dataset
2024-02-28 22:22:38,292:INFO:Defining folds
2024-02-28 22:22:38,292:INFO:Declaring metric variables
2024-02-28 22:22:38,299:INFO:Importing untrained model
2024-02-28 22:22:38,301:INFO:Least Angle Regression Imported successfully
2024-02-28 22:22:38,301:INFO:Starting cross validation
2024-02-28 22:22:38,307:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-28 22:22:38,361:INFO:Calculating mean and std
2024-02-28 22:22:38,361:INFO:Creating metrics dataframe
2024-02-28 22:22:38,361:INFO:Uploading results into container
2024-02-28 22:22:38,361:INFO:Uploading model into container now
2024-02-28 22:22:38,361:INFO:_master_model_container: 25
2024-02-28 22:22:38,361:INFO:_display_container: 2
2024-02-28 22:22:38,361:INFO:Lars(random_state=123)
2024-02-28 22:22:38,361:INFO:create_model() successfully completed......................................
2024-02-28 22:22:38,661:INFO:SubProcess create_model() end ==================================
2024-02-28 22:22:38,661:INFO:Creating metrics dataframe
2024-02-28 22:22:38,669:INFO:Initializing Lasso Least Angle Regression
2024-02-28 22:22:38,669:INFO:Total runtime is 0.10941327810287475 minutes
2024-02-28 22:22:38,669:INFO:SubProcess create_model() called ==================================
2024-02-28 22:22:38,669:INFO:Initializing create_model()
2024-02-28 22:22:38,669:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571861F0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000160237EC160>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:22:38,669:INFO:Checking exceptions
2024-02-28 22:22:38,669:INFO:Importing libraries
2024-02-28 22:22:38,669:INFO:Copying training dataset
2024-02-28 22:22:38,669:INFO:Defining folds
2024-02-28 22:22:38,669:INFO:Declaring metric variables
2024-02-28 22:22:38,678:INFO:Importing untrained model
2024-02-28 22:22:38,679:INFO:Lasso Least Angle Regression Imported successfully
2024-02-28 22:22:38,686:INFO:Starting cross validation
2024-02-28 22:22:38,687:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-28 22:22:38,746:INFO:Calculating mean and std
2024-02-28 22:22:38,746:INFO:Creating metrics dataframe
2024-02-28 22:22:38,746:INFO:Uploading results into container
2024-02-28 22:22:38,746:INFO:Uploading model into container now
2024-02-28 22:22:38,746:INFO:_master_model_container: 26
2024-02-28 22:22:38,746:INFO:_display_container: 2
2024-02-28 22:22:38,746:INFO:LassoLars(random_state=123)
2024-02-28 22:22:38,746:INFO:create_model() successfully completed......................................
2024-02-28 22:22:39,046:INFO:SubProcess create_model() end ==================================
2024-02-28 22:22:39,046:INFO:Creating metrics dataframe
2024-02-28 22:22:39,053:INFO:Initializing Orthogonal Matching Pursuit
2024-02-28 22:22:39,053:INFO:Total runtime is 0.11582234700520833 minutes
2024-02-28 22:22:39,053:INFO:SubProcess create_model() called ==================================
2024-02-28 22:22:39,053:INFO:Initializing create_model()
2024-02-28 22:22:39,053:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571861F0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000160237EC160>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:22:39,053:INFO:Checking exceptions
2024-02-28 22:22:39,053:INFO:Importing libraries
2024-02-28 22:22:39,053:INFO:Copying training dataset
2024-02-28 22:22:39,053:INFO:Defining folds
2024-02-28 22:22:39,053:INFO:Declaring metric variables
2024-02-28 22:22:39,063:INFO:Importing untrained model
2024-02-28 22:22:39,065:INFO:Orthogonal Matching Pursuit Imported successfully
2024-02-28 22:22:39,069:INFO:Starting cross validation
2024-02-28 22:22:39,070:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-28 22:22:39,115:INFO:Calculating mean and std
2024-02-28 22:22:39,115:INFO:Creating metrics dataframe
2024-02-28 22:22:39,115:INFO:Uploading results into container
2024-02-28 22:22:39,115:INFO:Uploading model into container now
2024-02-28 22:22:39,115:INFO:_master_model_container: 27
2024-02-28 22:22:39,115:INFO:_display_container: 2
2024-02-28 22:22:39,115:INFO:OrthogonalMatchingPursuit()
2024-02-28 22:22:39,115:INFO:create_model() successfully completed......................................
2024-02-28 22:22:39,400:INFO:SubProcess create_model() end ==================================
2024-02-28 22:22:39,400:INFO:Creating metrics dataframe
2024-02-28 22:22:39,407:INFO:Initializing Bayesian Ridge
2024-02-28 22:22:39,407:INFO:Total runtime is 0.12172233263651529 minutes
2024-02-28 22:22:39,407:INFO:SubProcess create_model() called ==================================
2024-02-28 22:22:39,407:INFO:Initializing create_model()
2024-02-28 22:22:39,407:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571861F0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000160237EC160>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:22:39,407:INFO:Checking exceptions
2024-02-28 22:22:39,407:INFO:Importing libraries
2024-02-28 22:22:39,407:INFO:Copying training dataset
2024-02-28 22:22:39,417:INFO:Defining folds
2024-02-28 22:22:39,417:INFO:Declaring metric variables
2024-02-28 22:22:39,417:INFO:Importing untrained model
2024-02-28 22:22:39,422:INFO:Bayesian Ridge Imported successfully
2024-02-28 22:22:39,423:INFO:Starting cross validation
2024-02-28 22:22:39,423:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-28 22:22:39,484:INFO:Calculating mean and std
2024-02-28 22:22:39,484:INFO:Creating metrics dataframe
2024-02-28 22:22:39,484:INFO:Uploading results into container
2024-02-28 22:22:39,484:INFO:Uploading model into container now
2024-02-28 22:22:39,484:INFO:_master_model_container: 28
2024-02-28 22:22:39,484:INFO:_display_container: 2
2024-02-28 22:22:39,484:INFO:BayesianRidge()
2024-02-28 22:22:39,484:INFO:create_model() successfully completed......................................
2024-02-28 22:22:39,792:INFO:SubProcess create_model() end ==================================
2024-02-28 22:22:39,792:INFO:Creating metrics dataframe
2024-02-28 22:22:39,800:INFO:Initializing Passive Aggressive Regressor
2024-02-28 22:22:39,800:INFO:Total runtime is 0.12825870513916016 minutes
2024-02-28 22:22:39,800:INFO:SubProcess create_model() called ==================================
2024-02-28 22:22:39,800:INFO:Initializing create_model()
2024-02-28 22:22:39,800:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571861F0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000160237EC160>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:22:39,800:INFO:Checking exceptions
2024-02-28 22:22:39,800:INFO:Importing libraries
2024-02-28 22:22:39,800:INFO:Copying training dataset
2024-02-28 22:22:39,800:INFO:Defining folds
2024-02-28 22:22:39,800:INFO:Declaring metric variables
2024-02-28 22:22:39,807:INFO:Importing untrained model
2024-02-28 22:22:39,811:INFO:Passive Aggressive Regressor Imported successfully
2024-02-28 22:22:39,816:INFO:Starting cross validation
2024-02-28 22:22:39,816:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-28 22:22:39,861:INFO:Calculating mean and std
2024-02-28 22:22:39,861:INFO:Creating metrics dataframe
2024-02-28 22:22:39,861:INFO:Uploading results into container
2024-02-28 22:22:39,861:INFO:Uploading model into container now
2024-02-28 22:22:39,861:INFO:_master_model_container: 29
2024-02-28 22:22:39,861:INFO:_display_container: 2
2024-02-28 22:22:39,861:INFO:PassiveAggressiveRegressor(random_state=123)
2024-02-28 22:22:39,861:INFO:create_model() successfully completed......................................
2024-02-28 22:22:40,148:INFO:SubProcess create_model() end ==================================
2024-02-28 22:22:40,148:INFO:Creating metrics dataframe
2024-02-28 22:22:40,154:INFO:Initializing Huber Regressor
2024-02-28 22:22:40,154:INFO:Total runtime is 0.13415911595026653 minutes
2024-02-28 22:22:40,161:INFO:SubProcess create_model() called ==================================
2024-02-28 22:22:40,161:INFO:Initializing create_model()
2024-02-28 22:22:40,161:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571861F0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000160237EC160>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:22:40,161:INFO:Checking exceptions
2024-02-28 22:22:40,161:INFO:Importing libraries
2024-02-28 22:22:40,161:INFO:Copying training dataset
2024-02-28 22:22:40,161:INFO:Defining folds
2024-02-28 22:22:40,161:INFO:Declaring metric variables
2024-02-28 22:22:40,167:INFO:Importing untrained model
2024-02-28 22:22:40,169:INFO:Huber Regressor Imported successfully
2024-02-28 22:22:40,169:INFO:Starting cross validation
2024-02-28 22:22:40,169:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-28 22:22:40,213:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-02-28 22:22:40,215:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-02-28 22:22:40,223:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-02-28 22:22:40,223:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-02-28 22:22:40,223:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-02-28 22:22:40,231:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-02-28 22:22:40,246:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-02-28 22:22:40,246:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-02-28 22:22:40,261:INFO:Calculating mean and std
2024-02-28 22:22:40,261:INFO:Creating metrics dataframe
2024-02-28 22:22:40,261:INFO:Uploading results into container
2024-02-28 22:22:40,261:INFO:Uploading model into container now
2024-02-28 22:22:40,261:INFO:_master_model_container: 30
2024-02-28 22:22:40,261:INFO:_display_container: 2
2024-02-28 22:22:40,261:INFO:HuberRegressor()
2024-02-28 22:22:40,261:INFO:create_model() successfully completed......................................
2024-02-28 22:22:40,563:INFO:SubProcess create_model() end ==================================
2024-02-28 22:22:40,563:INFO:Creating metrics dataframe
2024-02-28 22:22:40,572:INFO:Initializing K Neighbors Regressor
2024-02-28 22:22:40,572:INFO:Total runtime is 0.14113728602727255 minutes
2024-02-28 22:22:40,575:INFO:SubProcess create_model() called ==================================
2024-02-28 22:22:40,575:INFO:Initializing create_model()
2024-02-28 22:22:40,575:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571861F0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000160237EC160>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:22:40,575:INFO:Checking exceptions
2024-02-28 22:22:40,575:INFO:Importing libraries
2024-02-28 22:22:40,575:INFO:Copying training dataset
2024-02-28 22:22:40,578:INFO:Defining folds
2024-02-28 22:22:40,578:INFO:Declaring metric variables
2024-02-28 22:22:40,579:INFO:Importing untrained model
2024-02-28 22:22:40,579:INFO:K Neighbors Regressor Imported successfully
2024-02-28 22:22:40,587:INFO:Starting cross validation
2024-02-28 22:22:40,588:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-28 22:22:40,661:INFO:Calculating mean and std
2024-02-28 22:22:40,661:INFO:Creating metrics dataframe
2024-02-28 22:22:40,661:INFO:Uploading results into container
2024-02-28 22:22:40,661:INFO:Uploading model into container now
2024-02-28 22:22:40,661:INFO:_master_model_container: 31
2024-02-28 22:22:40,661:INFO:_display_container: 2
2024-02-28 22:22:40,661:INFO:KNeighborsRegressor(n_jobs=-1)
2024-02-28 22:22:40,661:INFO:create_model() successfully completed......................................
2024-02-28 22:22:40,961:INFO:SubProcess create_model() end ==================================
2024-02-28 22:22:40,961:INFO:Creating metrics dataframe
2024-02-28 22:22:40,969:INFO:Initializing Decision Tree Regressor
2024-02-28 22:22:40,969:INFO:Total runtime is 0.14774604241053263 minutes
2024-02-28 22:22:40,969:INFO:SubProcess create_model() called ==================================
2024-02-28 22:22:40,969:INFO:Initializing create_model()
2024-02-28 22:22:40,969:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571861F0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000160237EC160>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:22:40,969:INFO:Checking exceptions
2024-02-28 22:22:40,969:INFO:Importing libraries
2024-02-28 22:22:40,969:INFO:Copying training dataset
2024-02-28 22:22:40,976:INFO:Defining folds
2024-02-28 22:22:40,977:INFO:Declaring metric variables
2024-02-28 22:22:40,980:INFO:Importing untrained model
2024-02-28 22:22:40,981:INFO:Decision Tree Regressor Imported successfully
2024-02-28 22:22:40,987:INFO:Starting cross validation
2024-02-28 22:22:40,987:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-28 22:22:41,046:INFO:Calculating mean and std
2024-02-28 22:22:41,046:INFO:Creating metrics dataframe
2024-02-28 22:22:41,046:INFO:Uploading results into container
2024-02-28 22:22:41,046:INFO:Uploading model into container now
2024-02-28 22:22:41,046:INFO:_master_model_container: 32
2024-02-28 22:22:41,046:INFO:_display_container: 2
2024-02-28 22:22:41,046:INFO:DecisionTreeRegressor(random_state=123)
2024-02-28 22:22:41,046:INFO:create_model() successfully completed......................................
2024-02-28 22:22:41,346:INFO:SubProcess create_model() end ==================================
2024-02-28 22:22:41,346:INFO:Creating metrics dataframe
2024-02-28 22:22:41,354:INFO:Initializing Random Forest Regressor
2024-02-28 22:22:41,354:INFO:Total runtime is 0.15416661500930787 minutes
2024-02-28 22:22:41,354:INFO:SubProcess create_model() called ==================================
2024-02-28 22:22:41,354:INFO:Initializing create_model()
2024-02-28 22:22:41,354:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571861F0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000160237EC160>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:22:41,354:INFO:Checking exceptions
2024-02-28 22:22:41,354:INFO:Importing libraries
2024-02-28 22:22:41,354:INFO:Copying training dataset
2024-02-28 22:22:41,361:INFO:Defining folds
2024-02-28 22:22:41,361:INFO:Declaring metric variables
2024-02-28 22:22:41,363:INFO:Importing untrained model
2024-02-28 22:22:41,365:INFO:Random Forest Regressor Imported successfully
2024-02-28 22:22:41,370:INFO:Starting cross validation
2024-02-28 22:22:41,370:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-28 22:22:41,423:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:22:41,423:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:22:41,423:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:22:41,430:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:22:41,438:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:22:41,453:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:22:41,453:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:22:41,461:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:22:41,469:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:22:41,493:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:22:41,500:INFO:Calculating mean and std
2024-02-28 22:22:41,500:INFO:Creating metrics dataframe
2024-02-28 22:22:41,500:INFO:Uploading results into container
2024-02-28 22:22:41,500:INFO:Uploading model into container now
2024-02-28 22:22:41,500:INFO:_master_model_container: 33
2024-02-28 22:22:41,500:INFO:_display_container: 2
2024-02-28 22:22:41,500:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-02-28 22:22:41,500:INFO:create_model() successfully completed......................................
2024-02-28 22:22:41,800:INFO:SubProcess create_model() end ==================================
2024-02-28 22:22:41,800:INFO:Creating metrics dataframe
2024-02-28 22:22:41,810:INFO:Initializing Extra Trees Regressor
2024-02-28 22:22:41,810:INFO:Total runtime is 0.16176200310389202 minutes
2024-02-28 22:22:41,816:INFO:SubProcess create_model() called ==================================
2024-02-28 22:22:41,816:INFO:Initializing create_model()
2024-02-28 22:22:41,816:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571861F0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000160237EC160>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:22:41,816:INFO:Checking exceptions
2024-02-28 22:22:41,816:INFO:Importing libraries
2024-02-28 22:22:41,816:INFO:Copying training dataset
2024-02-28 22:22:41,818:INFO:Defining folds
2024-02-28 22:22:41,818:INFO:Declaring metric variables
2024-02-28 22:22:41,818:INFO:Importing untrained model
2024-02-28 22:22:41,824:INFO:Extra Trees Regressor Imported successfully
2024-02-28 22:22:41,826:INFO:Starting cross validation
2024-02-28 22:22:41,826:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-28 22:22:41,884:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:22:41,892:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:22:41,892:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:22:41,899:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:22:41,907:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:22:41,916:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:22:41,917:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:22:41,930:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:22:41,930:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:22:41,946:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:22:41,954:INFO:Calculating mean and std
2024-02-28 22:22:41,954:INFO:Creating metrics dataframe
2024-02-28 22:22:41,956:INFO:Uploading results into container
2024-02-28 22:22:41,957:INFO:Uploading model into container now
2024-02-28 22:22:41,957:INFO:_master_model_container: 34
2024-02-28 22:22:41,957:INFO:_display_container: 2
2024-02-28 22:22:41,957:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-02-28 22:22:41,957:INFO:create_model() successfully completed......................................
2024-02-28 22:22:42,254:INFO:SubProcess create_model() end ==================================
2024-02-28 22:22:42,254:INFO:Creating metrics dataframe
2024-02-28 22:22:42,264:INFO:Initializing AdaBoost Regressor
2024-02-28 22:22:42,265:INFO:Total runtime is 0.16933503150939944 minutes
2024-02-28 22:22:42,267:INFO:SubProcess create_model() called ==================================
2024-02-28 22:22:42,268:INFO:Initializing create_model()
2024-02-28 22:22:42,268:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571861F0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000160237EC160>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:22:42,268:INFO:Checking exceptions
2024-02-28 22:22:42,268:INFO:Importing libraries
2024-02-28 22:22:42,268:INFO:Copying training dataset
2024-02-28 22:22:42,270:INFO:Defining folds
2024-02-28 22:22:42,270:INFO:Declaring metric variables
2024-02-28 22:22:42,272:INFO:Importing untrained model
2024-02-28 22:22:42,274:INFO:AdaBoost Regressor Imported successfully
2024-02-28 22:22:42,279:INFO:Starting cross validation
2024-02-28 22:22:42,280:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-28 22:22:42,392:INFO:Calculating mean and std
2024-02-28 22:22:42,392:INFO:Creating metrics dataframe
2024-02-28 22:22:42,392:INFO:Uploading results into container
2024-02-28 22:22:42,392:INFO:Uploading model into container now
2024-02-28 22:22:42,392:INFO:_master_model_container: 35
2024-02-28 22:22:42,392:INFO:_display_container: 2
2024-02-28 22:22:42,392:INFO:AdaBoostRegressor(random_state=123)
2024-02-28 22:22:42,392:INFO:create_model() successfully completed......................................
2024-02-28 22:22:42,690:INFO:SubProcess create_model() end ==================================
2024-02-28 22:22:42,690:INFO:Creating metrics dataframe
2024-02-28 22:22:42,699:INFO:Initializing Gradient Boosting Regressor
2024-02-28 22:22:42,699:INFO:Total runtime is 0.17658758958180748 minutes
2024-02-28 22:22:42,702:INFO:SubProcess create_model() called ==================================
2024-02-28 22:22:42,703:INFO:Initializing create_model()
2024-02-28 22:22:42,703:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571861F0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000160237EC160>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:22:42,703:INFO:Checking exceptions
2024-02-28 22:22:42,703:INFO:Importing libraries
2024-02-28 22:22:42,703:INFO:Copying training dataset
2024-02-28 22:22:42,703:INFO:Defining folds
2024-02-28 22:22:42,703:INFO:Declaring metric variables
2024-02-28 22:22:42,708:INFO:Importing untrained model
2024-02-28 22:22:42,710:INFO:Gradient Boosting Regressor Imported successfully
2024-02-28 22:22:42,715:INFO:Starting cross validation
2024-02-28 22:22:42,716:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-28 22:22:42,838:INFO:Calculating mean and std
2024-02-28 22:22:42,838:INFO:Creating metrics dataframe
2024-02-28 22:22:42,838:INFO:Uploading results into container
2024-02-28 22:22:42,838:INFO:Uploading model into container now
2024-02-28 22:22:42,838:INFO:_master_model_container: 36
2024-02-28 22:22:42,838:INFO:_display_container: 2
2024-02-28 22:22:42,838:INFO:GradientBoostingRegressor(random_state=123)
2024-02-28 22:22:42,838:INFO:create_model() successfully completed......................................
2024-02-28 22:22:43,123:INFO:SubProcess create_model() end ==================================
2024-02-28 22:22:43,123:INFO:Creating metrics dataframe
2024-02-28 22:22:43,139:INFO:Initializing Extreme Gradient Boosting
2024-02-28 22:22:43,139:INFO:Total runtime is 0.18391137123107912 minutes
2024-02-28 22:22:43,140:INFO:SubProcess create_model() called ==================================
2024-02-28 22:22:43,140:INFO:Initializing create_model()
2024-02-28 22:22:43,140:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571861F0>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000160237EC160>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:22:43,140:INFO:Checking exceptions
2024-02-28 22:22:43,140:INFO:Importing libraries
2024-02-28 22:22:43,140:INFO:Copying training dataset
2024-02-28 22:22:43,140:INFO:Defining folds
2024-02-28 22:22:43,140:INFO:Declaring metric variables
2024-02-28 22:22:43,148:INFO:Importing untrained model
2024-02-28 22:22:43,148:INFO:Extreme Gradient Boosting Imported successfully
2024-02-28 22:22:43,155:INFO:Starting cross validation
2024-02-28 22:22:43,155:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-28 22:22:43,353:INFO:Calculating mean and std
2024-02-28 22:22:43,354:INFO:Creating metrics dataframe
2024-02-28 22:22:43,354:INFO:Uploading results into container
2024-02-28 22:22:43,354:INFO:Uploading model into container now
2024-02-28 22:22:43,354:INFO:_master_model_container: 37
2024-02-28 22:22:43,354:INFO:_display_container: 2
2024-02-28 22:22:43,354:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=123, ...)
2024-02-28 22:22:43,358:INFO:create_model() successfully completed......................................
2024-02-28 22:22:43,654:INFO:SubProcess create_model() end ==================================
2024-02-28 22:22:43,654:INFO:Creating metrics dataframe
2024-02-28 22:22:43,662:INFO:Initializing Light Gradient Boosting Machine
2024-02-28 22:22:43,662:INFO:Total runtime is 0.19263468980789186 minutes
2024-02-28 22:22:43,665:INFO:SubProcess create_model() called ==================================
2024-02-28 22:22:43,665:INFO:Initializing create_model()
2024-02-28 22:22:43,665:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571861F0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000160237EC160>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:22:43,665:INFO:Checking exceptions
2024-02-28 22:22:43,665:INFO:Importing libraries
2024-02-28 22:22:43,665:INFO:Copying training dataset
2024-02-28 22:22:43,670:INFO:Defining folds
2024-02-28 22:22:43,670:INFO:Declaring metric variables
2024-02-28 22:22:43,673:INFO:Importing untrained model
2024-02-28 22:22:43,677:INFO:Light Gradient Boosting Machine Imported successfully
2024-02-28 22:22:43,681:INFO:Starting cross validation
2024-02-28 22:22:43,684:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-28 22:22:43,969:INFO:Calculating mean and std
2024-02-28 22:22:43,970:INFO:Creating metrics dataframe
2024-02-28 22:22:43,972:INFO:Uploading results into container
2024-02-28 22:22:43,973:INFO:Uploading model into container now
2024-02-28 22:22:43,973:INFO:_master_model_container: 38
2024-02-28 22:22:43,973:INFO:_display_container: 2
2024-02-28 22:22:43,974:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2024-02-28 22:22:43,974:INFO:create_model() successfully completed......................................
2024-02-28 22:22:44,287:INFO:SubProcess create_model() end ==================================
2024-02-28 22:22:44,288:INFO:Creating metrics dataframe
2024-02-28 22:22:44,292:INFO:Initializing CatBoost Regressor
2024-02-28 22:22:44,292:INFO:Total runtime is 0.20313316186269126 minutes
2024-02-28 22:22:44,300:INFO:SubProcess create_model() called ==================================
2024-02-28 22:22:44,300:INFO:Initializing create_model()
2024-02-28 22:22:44,300:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571861F0>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000160237EC160>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:22:44,300:INFO:Checking exceptions
2024-02-28 22:22:44,300:INFO:Importing libraries
2024-02-28 22:22:44,300:INFO:Copying training dataset
2024-02-28 22:22:44,300:INFO:Defining folds
2024-02-28 22:22:44,300:INFO:Declaring metric variables
2024-02-28 22:22:44,305:INFO:Importing untrained model
2024-02-28 22:22:44,308:INFO:CatBoost Regressor Imported successfully
2024-02-28 22:22:44,308:INFO:Starting cross validation
2024-02-28 22:22:44,308:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-28 22:22:46,169:INFO:Calculating mean and std
2024-02-28 22:22:46,169:INFO:Creating metrics dataframe
2024-02-28 22:22:46,172:INFO:Uploading results into container
2024-02-28 22:22:46,172:INFO:Uploading model into container now
2024-02-28 22:22:46,172:INFO:_master_model_container: 39
2024-02-28 22:22:46,173:INFO:_display_container: 2
2024-02-28 22:22:46,173:INFO:<catboost.core.CatBoostRegressor object at 0x000001601C9BE910>
2024-02-28 22:22:46,173:INFO:create_model() successfully completed......................................
2024-02-28 22:22:46,466:INFO:SubProcess create_model() end ==================================
2024-02-28 22:22:46,466:INFO:Creating metrics dataframe
2024-02-28 22:22:46,476:INFO:Initializing Dummy Regressor
2024-02-28 22:22:46,476:INFO:Total runtime is 0.23952666918436688 minutes
2024-02-28 22:22:46,476:INFO:SubProcess create_model() called ==================================
2024-02-28 22:22:46,476:INFO:Initializing create_model()
2024-02-28 22:22:46,476:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571861F0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000160237EC160>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:22:46,476:INFO:Checking exceptions
2024-02-28 22:22:46,476:INFO:Importing libraries
2024-02-28 22:22:46,476:INFO:Copying training dataset
2024-02-28 22:22:46,476:INFO:Defining folds
2024-02-28 22:22:46,476:INFO:Declaring metric variables
2024-02-28 22:22:46,484:INFO:Importing untrained model
2024-02-28 22:22:46,486:INFO:Dummy Regressor Imported successfully
2024-02-28 22:22:46,493:INFO:Starting cross validation
2024-02-28 22:22:46,494:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-28 22:22:46,546:INFO:Calculating mean and std
2024-02-28 22:22:46,546:INFO:Creating metrics dataframe
2024-02-28 22:22:46,548:INFO:Uploading results into container
2024-02-28 22:22:46,548:INFO:Uploading model into container now
2024-02-28 22:22:46,549:INFO:_master_model_container: 40
2024-02-28 22:22:46,549:INFO:_display_container: 2
2024-02-28 22:22:46,549:INFO:DummyRegressor()
2024-02-28 22:22:46,549:INFO:create_model() successfully completed......................................
2024-02-28 22:22:46,840:INFO:SubProcess create_model() end ==================================
2024-02-28 22:22:46,840:INFO:Creating metrics dataframe
2024-02-28 22:22:46,860:INFO:Initializing create_model()
2024-02-28 22:22:46,860:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571861F0>, estimator=<catboost.core.CatBoostRegressor object at 0x000001601C9BE910>, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:22:46,860:INFO:Checking exceptions
2024-02-28 22:22:46,861:INFO:Importing libraries
2024-02-28 22:22:46,862:INFO:Copying training dataset
2024-02-28 22:22:46,864:INFO:Defining folds
2024-02-28 22:22:46,864:INFO:Declaring metric variables
2024-02-28 22:22:46,864:INFO:Importing untrained model
2024-02-28 22:22:46,864:INFO:Declaring custom model
2024-02-28 22:22:46,864:INFO:CatBoost Regressor Imported successfully
2024-02-28 22:22:46,865:INFO:Cross validation set to False
2024-02-28 22:22:46,865:INFO:Fitting Model
2024-02-28 22:22:47,593:INFO:<catboost.core.CatBoostRegressor object at 0x000001601CC2F400>
2024-02-28 22:22:47,593:INFO:create_model() successfully completed......................................
2024-02-28 22:22:47,909:INFO:_master_model_container: 40
2024-02-28 22:22:47,909:INFO:_display_container: 2
2024-02-28 22:22:47,909:INFO:<catboost.core.CatBoostRegressor object at 0x000001601CC2F400>
2024-02-28 22:22:47,909:INFO:compare_models() successfully completed......................................
2024-02-28 22:23:03,325:INFO:Initializing evaluate_model()
2024-02-28 22:23:03,325:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571F1E50>, estimator=<catboost.core.CatBoostRegressor object at 0x000001601CC2F400>, fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-02-28 22:23:03,334:INFO:Initializing plot_model()
2024-02-28 22:23:03,334:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=<catboost.core.CatBoostRegressor object at 0x000001601CC2F400>, feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571F1E50>, system=True)
2024-02-28 22:23:03,334:INFO:Checking exceptions
2024-02-28 22:23:03,335:INFO:Preloading libraries
2024-02-28 22:23:03,337:INFO:Copying training dataset
2024-02-28 22:23:03,337:INFO:Plot type: pipeline
2024-02-28 22:23:03,385:INFO:Visual Rendered Successfully
2024-02-28 22:23:03,682:INFO:plot_model() successfully completed......................................
2024-02-28 22:23:42,778:INFO:PyCaret RegressionExperiment
2024-02-28 22:23:42,778:INFO:Logging name: reg-default-name
2024-02-28 22:23:42,778:INFO:ML Usecase: MLUsecase.REGRESSION
2024-02-28 22:23:42,778:INFO:version 3.3.0
2024-02-28 22:23:42,778:INFO:Initializing setup()
2024-02-28 22:23:42,778:INFO:self.USI: 5aed
2024-02-28 22:23:42,778:INFO:self._variable_keys: {'logging_param', '_ml_usecase', 'target_param', 'X_train', 'idx', 'data', 'y', 'exp_name_log', 'X_test', 'transform_target_param', 'log_plots_param', 'memory', 'html_param', '_available_plots', 'gpu_n_jobs_param', 'y_train', 'seed', 'USI', 'pipeline', 'exp_id', 'y_test', 'gpu_param', 'fold_shuffle_param', 'fold_generator', 'fold_groups_param', 'X', 'n_jobs_param'}
2024-02-28 22:23:42,778:INFO:Checking environment
2024-02-28 22:23:42,778:INFO:python_version: 3.9.18
2024-02-28 22:23:42,778:INFO:python_build: ('main', 'Dec 23 2023 16:29:04')
2024-02-28 22:23:42,778:INFO:machine: AMD64
2024-02-28 22:23:42,778:INFO:platform: Windows-10-10.0.22621-SP0
2024-02-28 22:23:42,778:INFO:Memory: svmem(total=34228445184, available=16499523584, percent=51.8, used=17728921600, free=16499523584)
2024-02-28 22:23:42,778:INFO:Physical Core: 8
2024-02-28 22:23:42,778:INFO:Logical Core: 16
2024-02-28 22:23:42,778:INFO:Checking libraries
2024-02-28 22:23:42,778:INFO:System:
2024-02-28 22:23:42,778:INFO:    python: 3.9.18 | packaged by conda-forge | (main, Dec 23 2023, 16:29:04) [MSC v.1929 64 bit (AMD64)]
2024-02-28 22:23:42,778:INFO:executable: c:\Users\Administrator\anaconda3\envs\EXAM_ML\python.exe
2024-02-28 22:23:42,778:INFO:   machine: Windows-10-10.0.22621-SP0
2024-02-28 22:23:42,778:INFO:PyCaret required dependencies:
2024-02-28 22:23:42,778:INFO:                 pip: 24.0
2024-02-28 22:23:42,778:INFO:          setuptools: 69.1.1
2024-02-28 22:23:42,778:INFO:             pycaret: 3.3.0
2024-02-28 22:23:42,778:INFO:             IPython: 8.12.0
2024-02-28 22:23:42,778:INFO:          ipywidgets: 8.1.2
2024-02-28 22:23:42,778:INFO:                tqdm: 4.66.2
2024-02-28 22:23:42,778:INFO:               numpy: 1.25.2
2024-02-28 22:23:42,778:INFO:              pandas: 1.5.3
2024-02-28 22:23:42,778:INFO:              jinja2: 3.1.3
2024-02-28 22:23:42,778:INFO:               scipy: 1.11.4
2024-02-28 22:23:42,778:INFO:              joblib: 1.3.2
2024-02-28 22:23:42,778:INFO:             sklearn: 1.4.1.post1
2024-02-28 22:23:42,778:INFO:                pyod: 1.1.3
2024-02-28 22:23:42,778:INFO:            imblearn: 0.12.0
2024-02-28 22:23:42,778:INFO:   category_encoders: 2.6.3
2024-02-28 22:23:42,778:INFO:            lightgbm: 4.3.0
2024-02-28 22:23:42,778:INFO:               numba: 0.58.1
2024-02-28 22:23:42,778:INFO:            requests: 2.31.0
2024-02-28 22:23:42,778:INFO:          matplotlib: 3.7.5
2024-02-28 22:23:42,778:INFO:          scikitplot: 0.3.7
2024-02-28 22:23:42,778:INFO:         yellowbrick: 1.5
2024-02-28 22:23:42,778:INFO:              plotly: 5.19.0
2024-02-28 22:23:42,778:INFO:    plotly-resampler: Not installed
2024-02-28 22:23:42,778:INFO:             kaleido: 0.2.1
2024-02-28 22:23:42,778:INFO:           schemdraw: 0.15
2024-02-28 22:23:42,778:INFO:         statsmodels: 0.14.1
2024-02-28 22:23:42,778:INFO:              sktime: 0.27.0
2024-02-28 22:23:42,778:INFO:               tbats: 1.1.3
2024-02-28 22:23:42,778:INFO:            pmdarima: 2.0.4
2024-02-28 22:23:42,778:INFO:              psutil: 5.9.8
2024-02-28 22:23:42,778:INFO:          markupsafe: 2.1.5
2024-02-28 22:23:42,778:INFO:             pickle5: Not installed
2024-02-28 22:23:42,778:INFO:         cloudpickle: 3.0.0
2024-02-28 22:23:42,778:INFO:         deprecation: 2.1.0
2024-02-28 22:23:42,778:INFO:              xxhash: 3.4.1
2024-02-28 22:23:42,778:INFO:           wurlitzer: Not installed
2024-02-28 22:23:42,778:INFO:PyCaret optional dependencies:
2024-02-28 22:23:42,778:INFO:                shap: 0.44.1
2024-02-28 22:23:42,778:INFO:           interpret: 0.5.1
2024-02-28 22:23:42,778:INFO:                umap: 0.5.5
2024-02-28 22:23:42,778:INFO:     ydata_profiling: 4.6.5
2024-02-28 22:23:42,778:INFO:  explainerdashboard: 0.4.5
2024-02-28 22:23:42,778:INFO:             autoviz: Not installed
2024-02-28 22:23:42,778:INFO:           fairlearn: 0.7.0
2024-02-28 22:23:42,778:INFO:          deepchecks: Not installed
2024-02-28 22:23:42,778:INFO:             xgboost: 2.0.3
2024-02-28 22:23:42,778:INFO:            catboost: 1.2.3
2024-02-28 22:23:42,778:INFO:              kmodes: 0.12.2
2024-02-28 22:23:42,778:INFO:             mlxtend: 0.23.1
2024-02-28 22:23:42,778:INFO:       statsforecast: 1.5.0
2024-02-28 22:23:42,778:INFO:        tune_sklearn: 0.5.0
2024-02-28 22:23:42,778:INFO:                 ray: 2.9.3
2024-02-28 22:23:42,778:INFO:            hyperopt: 0.2.7
2024-02-28 22:23:42,778:INFO:              optuna: 3.5.0
2024-02-28 22:23:42,778:INFO:               skopt: 0.9.0
2024-02-28 22:23:42,778:INFO:              mlflow: 2.10.2
2024-02-28 22:23:42,778:INFO:              gradio: 4.19.2
2024-02-28 22:23:42,778:INFO:             fastapi: 0.110.0
2024-02-28 22:23:42,778:INFO:             uvicorn: 0.27.1
2024-02-28 22:23:42,778:INFO:              m2cgen: 0.10.0
2024-02-28 22:23:42,778:INFO:           evidently: 0.4.16
2024-02-28 22:23:42,778:INFO:               fugue: 0.8.6
2024-02-28 22:23:42,778:INFO:           streamlit: Not installed
2024-02-28 22:23:42,778:INFO:             prophet: Not installed
2024-02-28 22:23:42,778:INFO:None
2024-02-28 22:23:42,778:INFO:Set up data.
2024-02-28 22:23:42,794:INFO:Set up folding strategy.
2024-02-28 22:23:42,794:INFO:Set up train/test split.
2024-02-28 22:23:42,799:INFO:Set up index.
2024-02-28 22:23:42,799:INFO:Assigning column types.
2024-02-28 22:23:42,802:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-02-28 22:23:42,870:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:23:42,870:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:23:42,956:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:23:42,956:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:23:42,956:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-02-28 22:23:43,031:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:23:43,031:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:23:43,100:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:23:43,100:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:23:43,100:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-02-28 22:23:43,177:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:23:43,177:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:23:43,254:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:23:43,254:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:23:43,254:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-02-28 22:23:43,332:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:23:43,340:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:23:43,401:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:23:43,401:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:23:43,416:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-02-28 22:23:43,486:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:23:43,486:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:23:43,555:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:23:43,555:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:23:43,555:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-02-28 22:23:43,631:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:23:43,631:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:23:43,709:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:23:43,709:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:23:43,709:INFO:Preparing preprocessing pipeline...
2024-02-28 22:23:43,709:INFO:Set up simple imputation.
2024-02-28 22:23:43,709:INFO:Set up feature normalization.
2024-02-28 22:23:43,732:INFO:Finished creating preprocessing pipeline.
2024-02-28 22:23:43,732:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['cylinders', 'displacement',
                                             'horsepower', 'weight',
                                             'acceleration'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2024-02-28 22:23:43,732:INFO:Creating final display dataframe.
2024-02-28 22:23:43,786:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target               mpg
2                   Target type        Regression
3           Original data shape          (392, 6)
4        Transformed data shape          (392, 6)
5   Transformed train set shape          (274, 6)
6    Transformed test set shape          (118, 6)
7              Numeric features                 5
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                    Normalize              True
13             Normalize method            zscore
14               Fold Generator             KFold
15                  Fold Number                10
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  reg-default-name
20                          USI              5aed
2024-02-28 22:23:43,865:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:23:43,870:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:23:43,939:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:23:43,939:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:23:43,939:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\internal\metrics.py:51: FutureWarning: The `needs_threshold` and `needs_proba` parameter are deprecated in version 1.4 and will be removed in 1.6. You can either let `response_method` be `None` or set it to `predict` to preserve the same behaviour.
  warnings.warn(

2024-02-28 22:23:43,939:INFO:setup() successfully completed in 1.16s...............
2024-02-28 22:23:51,009:INFO:PyCaret RegressionExperiment
2024-02-28 22:23:51,009:INFO:Logging name: reg-default-name
2024-02-28 22:23:51,009:INFO:ML Usecase: MLUsecase.REGRESSION
2024-02-28 22:23:51,009:INFO:version 3.3.0
2024-02-28 22:23:51,009:INFO:Initializing setup()
2024-02-28 22:23:51,009:INFO:self.USI: d0ae
2024-02-28 22:23:51,009:INFO:self._variable_keys: {'logging_param', '_ml_usecase', 'target_param', 'X_train', 'idx', 'data', 'y', 'exp_name_log', 'X_test', 'transform_target_param', 'log_plots_param', 'memory', 'html_param', '_available_plots', 'gpu_n_jobs_param', 'y_train', 'seed', 'USI', 'pipeline', 'exp_id', 'y_test', 'gpu_param', 'fold_shuffle_param', 'fold_generator', 'fold_groups_param', 'X', 'n_jobs_param'}
2024-02-28 22:23:51,009:INFO:Checking environment
2024-02-28 22:23:51,009:INFO:python_version: 3.9.18
2024-02-28 22:23:51,009:INFO:python_build: ('main', 'Dec 23 2023 16:29:04')
2024-02-28 22:23:51,009:INFO:machine: AMD64
2024-02-28 22:23:51,009:INFO:platform: Windows-10-10.0.22621-SP0
2024-02-28 22:23:51,009:INFO:Memory: svmem(total=34228445184, available=16537616384, percent=51.7, used=17690828800, free=16537616384)
2024-02-28 22:23:51,009:INFO:Physical Core: 8
2024-02-28 22:23:51,009:INFO:Logical Core: 16
2024-02-28 22:23:51,009:INFO:Checking libraries
2024-02-28 22:23:51,009:INFO:System:
2024-02-28 22:23:51,009:INFO:    python: 3.9.18 | packaged by conda-forge | (main, Dec 23 2023, 16:29:04) [MSC v.1929 64 bit (AMD64)]
2024-02-28 22:23:51,009:INFO:executable: c:\Users\Administrator\anaconda3\envs\EXAM_ML\python.exe
2024-02-28 22:23:51,009:INFO:   machine: Windows-10-10.0.22621-SP0
2024-02-28 22:23:51,009:INFO:PyCaret required dependencies:
2024-02-28 22:23:51,009:INFO:                 pip: 24.0
2024-02-28 22:23:51,009:INFO:          setuptools: 69.1.1
2024-02-28 22:23:51,009:INFO:             pycaret: 3.3.0
2024-02-28 22:23:51,009:INFO:             IPython: 8.12.0
2024-02-28 22:23:51,009:INFO:          ipywidgets: 8.1.2
2024-02-28 22:23:51,009:INFO:                tqdm: 4.66.2
2024-02-28 22:23:51,009:INFO:               numpy: 1.25.2
2024-02-28 22:23:51,009:INFO:              pandas: 1.5.3
2024-02-28 22:23:51,009:INFO:              jinja2: 3.1.3
2024-02-28 22:23:51,009:INFO:               scipy: 1.11.4
2024-02-28 22:23:51,009:INFO:              joblib: 1.3.2
2024-02-28 22:23:51,009:INFO:             sklearn: 1.4.1.post1
2024-02-28 22:23:51,009:INFO:                pyod: 1.1.3
2024-02-28 22:23:51,009:INFO:            imblearn: 0.12.0
2024-02-28 22:23:51,009:INFO:   category_encoders: 2.6.3
2024-02-28 22:23:51,009:INFO:            lightgbm: 4.3.0
2024-02-28 22:23:51,009:INFO:               numba: 0.58.1
2024-02-28 22:23:51,009:INFO:            requests: 2.31.0
2024-02-28 22:23:51,009:INFO:          matplotlib: 3.7.5
2024-02-28 22:23:51,009:INFO:          scikitplot: 0.3.7
2024-02-28 22:23:51,009:INFO:         yellowbrick: 1.5
2024-02-28 22:23:51,009:INFO:              plotly: 5.19.0
2024-02-28 22:23:51,009:INFO:    plotly-resampler: Not installed
2024-02-28 22:23:51,009:INFO:             kaleido: 0.2.1
2024-02-28 22:23:51,009:INFO:           schemdraw: 0.15
2024-02-28 22:23:51,009:INFO:         statsmodels: 0.14.1
2024-02-28 22:23:51,009:INFO:              sktime: 0.27.0
2024-02-28 22:23:51,009:INFO:               tbats: 1.1.3
2024-02-28 22:23:51,009:INFO:            pmdarima: 2.0.4
2024-02-28 22:23:51,009:INFO:              psutil: 5.9.8
2024-02-28 22:23:51,009:INFO:          markupsafe: 2.1.5
2024-02-28 22:23:51,009:INFO:             pickle5: Not installed
2024-02-28 22:23:51,009:INFO:         cloudpickle: 3.0.0
2024-02-28 22:23:51,009:INFO:         deprecation: 2.1.0
2024-02-28 22:23:51,016:INFO:              xxhash: 3.4.1
2024-02-28 22:23:51,016:INFO:           wurlitzer: Not installed
2024-02-28 22:23:51,016:INFO:PyCaret optional dependencies:
2024-02-28 22:23:51,016:INFO:                shap: 0.44.1
2024-02-28 22:23:51,016:INFO:           interpret: 0.5.1
2024-02-28 22:23:51,016:INFO:                umap: 0.5.5
2024-02-28 22:23:51,016:INFO:     ydata_profiling: 4.6.5
2024-02-28 22:23:51,016:INFO:  explainerdashboard: 0.4.5
2024-02-28 22:23:51,016:INFO:             autoviz: Not installed
2024-02-28 22:23:51,016:INFO:           fairlearn: 0.7.0
2024-02-28 22:23:51,016:INFO:          deepchecks: Not installed
2024-02-28 22:23:51,016:INFO:             xgboost: 2.0.3
2024-02-28 22:23:51,016:INFO:            catboost: 1.2.3
2024-02-28 22:23:51,016:INFO:              kmodes: 0.12.2
2024-02-28 22:23:51,016:INFO:             mlxtend: 0.23.1
2024-02-28 22:23:51,016:INFO:       statsforecast: 1.5.0
2024-02-28 22:23:51,016:INFO:        tune_sklearn: 0.5.0
2024-02-28 22:23:51,016:INFO:                 ray: 2.9.3
2024-02-28 22:23:51,016:INFO:            hyperopt: 0.2.7
2024-02-28 22:23:51,016:INFO:              optuna: 3.5.0
2024-02-28 22:23:51,016:INFO:               skopt: 0.9.0
2024-02-28 22:23:51,016:INFO:              mlflow: 2.10.2
2024-02-28 22:23:51,016:INFO:              gradio: 4.19.2
2024-02-28 22:23:51,016:INFO:             fastapi: 0.110.0
2024-02-28 22:23:51,016:INFO:             uvicorn: 0.27.1
2024-02-28 22:23:51,016:INFO:              m2cgen: 0.10.0
2024-02-28 22:23:51,017:INFO:           evidently: 0.4.16
2024-02-28 22:23:51,017:INFO:               fugue: 0.8.6
2024-02-28 22:23:51,017:INFO:           streamlit: Not installed
2024-02-28 22:23:51,017:INFO:             prophet: Not installed
2024-02-28 22:23:51,017:INFO:None
2024-02-28 22:23:51,017:INFO:Set up data.
2024-02-28 22:23:51,019:INFO:Set up folding strategy.
2024-02-28 22:23:51,019:INFO:Set up train/test split.
2024-02-28 22:23:51,022:INFO:Set up index.
2024-02-28 22:23:51,022:INFO:Assigning column types.
2024-02-28 22:23:51,025:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-02-28 22:23:51,101:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:23:51,108:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:23:51,178:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:23:51,178:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:23:51,185:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-02-28 22:23:51,256:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:23:51,256:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:23:51,332:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:23:51,332:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:23:51,332:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-02-28 22:23:51,408:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:23:51,408:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:23:51,478:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:23:51,485:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:23:51,485:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-02-28 22:23:51,557:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:23:51,557:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:23:51,632:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:23:51,632:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:23:51,632:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-02-28 22:23:51,701:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:23:51,709:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:23:51,780:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:23:51,785:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:23:51,785:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-02-28 22:23:51,855:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:23:51,862:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:23:51,932:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:23:51,939:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:23:51,939:INFO:Preparing preprocessing pipeline...
2024-02-28 22:23:51,939:INFO:Set up simple imputation.
2024-02-28 22:23:51,939:INFO:Set up feature normalization.
2024-02-28 22:23:51,955:INFO:Finished creating preprocessing pipeline.
2024-02-28 22:23:51,955:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['cylinders', 'displacement',
                                             'horsepower', 'weight',
                                             'acceleration'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2024-02-28 22:23:51,955:INFO:Creating final display dataframe.
2024-02-28 22:23:52,001:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target               mpg
2                   Target type        Regression
3           Original data shape          (392, 6)
4        Transformed data shape          (392, 6)
5   Transformed train set shape          (274, 6)
6    Transformed test set shape          (118, 6)
7              Numeric features                 5
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                    Normalize              True
13             Normalize method            zscore
14               Fold Generator             KFold
15                  Fold Number                10
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  reg-default-name
20                          USI              d0ae
2024-02-28 22:23:52,085:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:23:52,087:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:23:52,155:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:23:52,162:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:23:52,162:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\internal\metrics.py:51: FutureWarning: The `needs_threshold` and `needs_proba` parameter are deprecated in version 1.4 and will be removed in 1.6. You can either let `response_method` be `None` or set it to `predict` to preserve the same behaviour.
  warnings.warn(

2024-02-28 22:23:52,162:INFO:setup() successfully completed in 1.15s...............
2024-02-28 22:23:56,124:INFO:Initializing compare_models()
2024-02-28 22:23:56,124:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571861F0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000160571861F0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-02-28 22:23:56,124:INFO:Checking exceptions
2024-02-28 22:23:56,124:INFO:Preparing display monitor
2024-02-28 22:23:56,141:INFO:Initializing Linear Regression
2024-02-28 22:23:56,142:INFO:Total runtime is 1.5632311503092447e-05 minutes
2024-02-28 22:23:56,142:INFO:SubProcess create_model() called ==================================
2024-02-28 22:23:56,142:INFO:Initializing create_model()
2024-02-28 22:23:56,142:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571861F0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001601C9D5AC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:23:56,142:INFO:Checking exceptions
2024-02-28 22:23:56,142:INFO:Importing libraries
2024-02-28 22:23:56,142:INFO:Copying training dataset
2024-02-28 22:23:56,147:INFO:Defining folds
2024-02-28 22:23:56,148:INFO:Declaring metric variables
2024-02-28 22:23:56,150:INFO:Importing untrained model
2024-02-28 22:23:56,152:INFO:Linear Regression Imported successfully
2024-02-28 22:23:56,156:INFO:Starting cross validation
2024-02-28 22:23:56,156:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-28 22:23:56,230:INFO:Calculating mean and std
2024-02-28 22:23:56,230:INFO:Creating metrics dataframe
2024-02-28 22:23:56,233:INFO:Uploading results into container
2024-02-28 22:23:56,233:INFO:Uploading model into container now
2024-02-28 22:23:56,233:INFO:_master_model_container: 41
2024-02-28 22:23:56,233:INFO:_display_container: 2
2024-02-28 22:23:56,233:INFO:LinearRegression(n_jobs=-1)
2024-02-28 22:23:56,233:INFO:create_model() successfully completed......................................
2024-02-28 22:23:56,541:INFO:SubProcess create_model() end ==================================
2024-02-28 22:23:56,542:INFO:Creating metrics dataframe
2024-02-28 22:23:56,548:INFO:Initializing Lasso Regression
2024-02-28 22:23:56,548:INFO:Total runtime is 0.006778268019358317 minutes
2024-02-28 22:23:56,549:INFO:SubProcess create_model() called ==================================
2024-02-28 22:23:56,549:INFO:Initializing create_model()
2024-02-28 22:23:56,549:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571861F0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001601C9D5AC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:23:56,549:INFO:Checking exceptions
2024-02-28 22:23:56,549:INFO:Importing libraries
2024-02-28 22:23:56,549:INFO:Copying training dataset
2024-02-28 22:23:56,549:INFO:Defining folds
2024-02-28 22:23:56,549:INFO:Declaring metric variables
2024-02-28 22:23:56,555:INFO:Importing untrained model
2024-02-28 22:23:56,557:INFO:Lasso Regression Imported successfully
2024-02-28 22:23:56,562:INFO:Starting cross validation
2024-02-28 22:23:56,562:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-28 22:23:56,632:INFO:Calculating mean and std
2024-02-28 22:23:56,632:INFO:Creating metrics dataframe
2024-02-28 22:23:56,634:INFO:Uploading results into container
2024-02-28 22:23:56,634:INFO:Uploading model into container now
2024-02-28 22:23:56,634:INFO:_master_model_container: 42
2024-02-28 22:23:56,635:INFO:_display_container: 2
2024-02-28 22:23:56,635:INFO:Lasso(random_state=123)
2024-02-28 22:23:56,635:INFO:create_model() successfully completed......................................
2024-02-28 22:23:56,924:INFO:SubProcess create_model() end ==================================
2024-02-28 22:23:56,924:INFO:Creating metrics dataframe
2024-02-28 22:23:56,932:INFO:Initializing Ridge Regression
2024-02-28 22:23:56,932:INFO:Total runtime is 0.01317977507909139 minutes
2024-02-28 22:23:56,939:INFO:SubProcess create_model() called ==================================
2024-02-28 22:23:56,939:INFO:Initializing create_model()
2024-02-28 22:23:56,939:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571861F0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001601C9D5AC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:23:56,939:INFO:Checking exceptions
2024-02-28 22:23:56,939:INFO:Importing libraries
2024-02-28 22:23:56,939:INFO:Copying training dataset
2024-02-28 22:23:56,939:INFO:Defining folds
2024-02-28 22:23:56,939:INFO:Declaring metric variables
2024-02-28 22:23:56,939:INFO:Importing untrained model
2024-02-28 22:23:56,947:INFO:Ridge Regression Imported successfully
2024-02-28 22:23:56,950:INFO:Starting cross validation
2024-02-28 22:23:56,951:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-28 22:23:57,017:INFO:Calculating mean and std
2024-02-28 22:23:57,017:INFO:Creating metrics dataframe
2024-02-28 22:23:57,017:INFO:Uploading results into container
2024-02-28 22:23:57,017:INFO:Uploading model into container now
2024-02-28 22:23:57,017:INFO:_master_model_container: 43
2024-02-28 22:23:57,017:INFO:_display_container: 2
2024-02-28 22:23:57,017:INFO:Ridge(random_state=123)
2024-02-28 22:23:57,017:INFO:create_model() successfully completed......................................
2024-02-28 22:23:57,316:INFO:SubProcess create_model() end ==================================
2024-02-28 22:23:57,316:INFO:Creating metrics dataframe
2024-02-28 22:23:57,324:INFO:Initializing Elastic Net
2024-02-28 22:23:57,324:INFO:Total runtime is 0.019718217849731445 minutes
2024-02-28 22:23:57,324:INFO:SubProcess create_model() called ==================================
2024-02-28 22:23:57,324:INFO:Initializing create_model()
2024-02-28 22:23:57,324:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571861F0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001601C9D5AC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:23:57,324:INFO:Checking exceptions
2024-02-28 22:23:57,324:INFO:Importing libraries
2024-02-28 22:23:57,324:INFO:Copying training dataset
2024-02-28 22:23:57,324:INFO:Defining folds
2024-02-28 22:23:57,324:INFO:Declaring metric variables
2024-02-28 22:23:57,332:INFO:Importing untrained model
2024-02-28 22:23:57,334:INFO:Elastic Net Imported successfully
2024-02-28 22:23:57,340:INFO:Starting cross validation
2024-02-28 22:23:57,341:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-28 22:23:57,401:INFO:Calculating mean and std
2024-02-28 22:23:57,401:INFO:Creating metrics dataframe
2024-02-28 22:23:57,403:INFO:Uploading results into container
2024-02-28 22:23:57,403:INFO:Uploading model into container now
2024-02-28 22:23:57,403:INFO:_master_model_container: 44
2024-02-28 22:23:57,403:INFO:_display_container: 2
2024-02-28 22:23:57,403:INFO:ElasticNet(random_state=123)
2024-02-28 22:23:57,403:INFO:create_model() successfully completed......................................
2024-02-28 22:23:57,701:INFO:SubProcess create_model() end ==================================
2024-02-28 22:23:57,701:INFO:Creating metrics dataframe
2024-02-28 22:23:57,708:INFO:Initializing Least Angle Regression
2024-02-28 22:23:57,708:INFO:Total runtime is 0.026121723651885986 minutes
2024-02-28 22:23:57,710:INFO:SubProcess create_model() called ==================================
2024-02-28 22:23:57,710:INFO:Initializing create_model()
2024-02-28 22:23:57,710:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571861F0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001601C9D5AC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:23:57,710:INFO:Checking exceptions
2024-02-28 22:23:57,710:INFO:Importing libraries
2024-02-28 22:23:57,710:INFO:Copying training dataset
2024-02-28 22:23:57,710:INFO:Defining folds
2024-02-28 22:23:57,710:INFO:Declaring metric variables
2024-02-28 22:23:57,716:INFO:Importing untrained model
2024-02-28 22:23:57,718:INFO:Least Angle Regression Imported successfully
2024-02-28 22:23:57,724:INFO:Starting cross validation
2024-02-28 22:23:57,724:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-28 22:23:57,786:INFO:Calculating mean and std
2024-02-28 22:23:57,786:INFO:Creating metrics dataframe
2024-02-28 22:23:57,786:INFO:Uploading results into container
2024-02-28 22:23:57,786:INFO:Uploading model into container now
2024-02-28 22:23:57,786:INFO:_master_model_container: 45
2024-02-28 22:23:57,786:INFO:_display_container: 2
2024-02-28 22:23:57,786:INFO:Lars(random_state=123)
2024-02-28 22:23:57,786:INFO:create_model() successfully completed......................................
2024-02-28 22:23:58,070:INFO:SubProcess create_model() end ==================================
2024-02-28 22:23:58,070:INFO:Creating metrics dataframe
2024-02-28 22:23:58,078:INFO:Initializing Lasso Least Angle Regression
2024-02-28 22:23:58,078:INFO:Total runtime is 0.032284243901570635 minutes
2024-02-28 22:23:58,086:INFO:SubProcess create_model() called ==================================
2024-02-28 22:23:58,086:INFO:Initializing create_model()
2024-02-28 22:23:58,086:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571861F0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001601C9D5AC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:23:58,086:INFO:Checking exceptions
2024-02-28 22:23:58,086:INFO:Importing libraries
2024-02-28 22:23:58,086:INFO:Copying training dataset
2024-02-28 22:23:58,086:INFO:Defining folds
2024-02-28 22:23:58,086:INFO:Declaring metric variables
2024-02-28 22:23:58,086:INFO:Importing untrained model
2024-02-28 22:23:58,094:INFO:Lasso Least Angle Regression Imported successfully
2024-02-28 22:23:58,095:INFO:Starting cross validation
2024-02-28 22:23:58,095:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-28 22:23:58,155:INFO:Calculating mean and std
2024-02-28 22:23:58,155:INFO:Creating metrics dataframe
2024-02-28 22:23:58,155:INFO:Uploading results into container
2024-02-28 22:23:58,155:INFO:Uploading model into container now
2024-02-28 22:23:58,155:INFO:_master_model_container: 46
2024-02-28 22:23:58,155:INFO:_display_container: 2
2024-02-28 22:23:58,155:INFO:LassoLars(random_state=123)
2024-02-28 22:23:58,155:INFO:create_model() successfully completed......................................
2024-02-28 22:23:58,441:INFO:SubProcess create_model() end ==================================
2024-02-28 22:23:58,441:INFO:Creating metrics dataframe
2024-02-28 22:23:58,447:INFO:Initializing Orthogonal Matching Pursuit
2024-02-28 22:23:58,447:INFO:Total runtime is 0.03843735059102376 minutes
2024-02-28 22:23:58,455:INFO:SubProcess create_model() called ==================================
2024-02-28 22:23:58,455:INFO:Initializing create_model()
2024-02-28 22:23:58,455:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571861F0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001601C9D5AC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:23:58,455:INFO:Checking exceptions
2024-02-28 22:23:58,455:INFO:Importing libraries
2024-02-28 22:23:58,455:INFO:Copying training dataset
2024-02-28 22:23:58,455:INFO:Defining folds
2024-02-28 22:23:58,455:INFO:Declaring metric variables
2024-02-28 22:23:58,455:INFO:Importing untrained model
2024-02-28 22:23:58,463:INFO:Orthogonal Matching Pursuit Imported successfully
2024-02-28 22:23:58,465:INFO:Starting cross validation
2024-02-28 22:23:58,465:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-28 22:23:58,532:INFO:Calculating mean and std
2024-02-28 22:23:58,532:INFO:Creating metrics dataframe
2024-02-28 22:23:58,532:INFO:Uploading results into container
2024-02-28 22:23:58,532:INFO:Uploading model into container now
2024-02-28 22:23:58,532:INFO:_master_model_container: 47
2024-02-28 22:23:58,532:INFO:_display_container: 2
2024-02-28 22:23:58,532:INFO:OrthogonalMatchingPursuit()
2024-02-28 22:23:58,532:INFO:create_model() successfully completed......................................
2024-02-28 22:23:58,832:INFO:SubProcess create_model() end ==================================
2024-02-28 22:23:58,832:INFO:Creating metrics dataframe
2024-02-28 22:23:58,840:INFO:Initializing Bayesian Ridge
2024-02-28 22:23:58,840:INFO:Total runtime is 0.04497589270273844 minutes
2024-02-28 22:23:58,840:INFO:SubProcess create_model() called ==================================
2024-02-28 22:23:58,840:INFO:Initializing create_model()
2024-02-28 22:23:58,840:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571861F0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001601C9D5AC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:23:58,840:INFO:Checking exceptions
2024-02-28 22:23:58,840:INFO:Importing libraries
2024-02-28 22:23:58,840:INFO:Copying training dataset
2024-02-28 22:23:58,847:INFO:Defining folds
2024-02-28 22:23:58,847:INFO:Declaring metric variables
2024-02-28 22:23:58,852:INFO:Importing untrained model
2024-02-28 22:23:58,854:INFO:Bayesian Ridge Imported successfully
2024-02-28 22:23:58,859:INFO:Starting cross validation
2024-02-28 22:23:58,859:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-28 22:23:58,924:INFO:Calculating mean and std
2024-02-28 22:23:58,924:INFO:Creating metrics dataframe
2024-02-28 22:23:58,924:INFO:Uploading results into container
2024-02-28 22:23:58,924:INFO:Uploading model into container now
2024-02-28 22:23:58,924:INFO:_master_model_container: 48
2024-02-28 22:23:58,924:INFO:_display_container: 2
2024-02-28 22:23:58,924:INFO:BayesianRidge()
2024-02-28 22:23:58,924:INFO:create_model() successfully completed......................................
2024-02-28 22:23:59,239:INFO:SubProcess create_model() end ==================================
2024-02-28 22:23:59,239:INFO:Creating metrics dataframe
2024-02-28 22:23:59,247:INFO:Initializing Passive Aggressive Regressor
2024-02-28 22:23:59,247:INFO:Total runtime is 0.05176873604456583 minutes
2024-02-28 22:23:59,247:INFO:SubProcess create_model() called ==================================
2024-02-28 22:23:59,247:INFO:Initializing create_model()
2024-02-28 22:23:59,247:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571861F0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001601C9D5AC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:23:59,247:INFO:Checking exceptions
2024-02-28 22:23:59,247:INFO:Importing libraries
2024-02-28 22:23:59,247:INFO:Copying training dataset
2024-02-28 22:23:59,255:INFO:Defining folds
2024-02-28 22:23:59,255:INFO:Declaring metric variables
2024-02-28 22:23:59,258:INFO:Importing untrained model
2024-02-28 22:23:59,260:INFO:Passive Aggressive Regressor Imported successfully
2024-02-28 22:23:59,265:INFO:Starting cross validation
2024-02-28 22:23:59,265:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-28 22:23:59,339:INFO:Calculating mean and std
2024-02-28 22:23:59,339:INFO:Creating metrics dataframe
2024-02-28 22:23:59,339:INFO:Uploading results into container
2024-02-28 22:23:59,339:INFO:Uploading model into container now
2024-02-28 22:23:59,339:INFO:_master_model_container: 49
2024-02-28 22:23:59,339:INFO:_display_container: 2
2024-02-28 22:23:59,339:INFO:PassiveAggressiveRegressor(random_state=123)
2024-02-28 22:23:59,339:INFO:create_model() successfully completed......................................
2024-02-28 22:23:59,647:INFO:SubProcess create_model() end ==================================
2024-02-28 22:23:59,647:INFO:Creating metrics dataframe
2024-02-28 22:23:59,655:INFO:Initializing Huber Regressor
2024-02-28 22:23:59,655:INFO:Total runtime is 0.05856258869171142 minutes
2024-02-28 22:23:59,655:INFO:SubProcess create_model() called ==================================
2024-02-28 22:23:59,655:INFO:Initializing create_model()
2024-02-28 22:23:59,655:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571861F0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001601C9D5AC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:23:59,655:INFO:Checking exceptions
2024-02-28 22:23:59,655:INFO:Importing libraries
2024-02-28 22:23:59,655:INFO:Copying training dataset
2024-02-28 22:23:59,663:INFO:Defining folds
2024-02-28 22:23:59,663:INFO:Declaring metric variables
2024-02-28 22:23:59,666:INFO:Importing untrained model
2024-02-28 22:23:59,668:INFO:Huber Regressor Imported successfully
2024-02-28 22:23:59,672:INFO:Starting cross validation
2024-02-28 22:23:59,672:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-28 22:23:59,747:INFO:Calculating mean and std
2024-02-28 22:23:59,747:INFO:Creating metrics dataframe
2024-02-28 22:23:59,747:INFO:Uploading results into container
2024-02-28 22:23:59,747:INFO:Uploading model into container now
2024-02-28 22:23:59,747:INFO:_master_model_container: 50
2024-02-28 22:23:59,747:INFO:_display_container: 2
2024-02-28 22:23:59,747:INFO:HuberRegressor()
2024-02-28 22:23:59,747:INFO:create_model() successfully completed......................................
2024-02-28 22:24:00,055:INFO:SubProcess create_model() end ==================================
2024-02-28 22:24:00,055:INFO:Creating metrics dataframe
2024-02-28 22:24:00,063:INFO:Initializing K Neighbors Regressor
2024-02-28 22:24:00,063:INFO:Total runtime is 0.0653586188952128 minutes
2024-02-28 22:24:00,070:INFO:SubProcess create_model() called ==================================
2024-02-28 22:24:00,070:INFO:Initializing create_model()
2024-02-28 22:24:00,070:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571861F0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001601C9D5AC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:24:00,070:INFO:Checking exceptions
2024-02-28 22:24:00,070:INFO:Importing libraries
2024-02-28 22:24:00,070:INFO:Copying training dataset
2024-02-28 22:24:00,070:INFO:Defining folds
2024-02-28 22:24:00,070:INFO:Declaring metric variables
2024-02-28 22:24:00,070:INFO:Importing untrained model
2024-02-28 22:24:00,077:INFO:K Neighbors Regressor Imported successfully
2024-02-28 22:24:00,079:INFO:Starting cross validation
2024-02-28 22:24:00,079:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-28 22:24:00,140:INFO:Calculating mean and std
2024-02-28 22:24:00,140:INFO:Creating metrics dataframe
2024-02-28 22:24:00,140:INFO:Uploading results into container
2024-02-28 22:24:00,140:INFO:Uploading model into container now
2024-02-28 22:24:00,140:INFO:_master_model_container: 51
2024-02-28 22:24:00,140:INFO:_display_container: 2
2024-02-28 22:24:00,140:INFO:KNeighborsRegressor(n_jobs=-1)
2024-02-28 22:24:00,140:INFO:create_model() successfully completed......................................
2024-02-28 22:24:00,447:INFO:SubProcess create_model() end ==================================
2024-02-28 22:24:00,447:INFO:Creating metrics dataframe
2024-02-28 22:24:00,455:INFO:Initializing Decision Tree Regressor
2024-02-28 22:24:00,455:INFO:Total runtime is 0.07189767758051553 minutes
2024-02-28 22:24:00,455:INFO:SubProcess create_model() called ==================================
2024-02-28 22:24:00,455:INFO:Initializing create_model()
2024-02-28 22:24:00,455:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571861F0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001601C9D5AC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:24:00,455:INFO:Checking exceptions
2024-02-28 22:24:00,455:INFO:Importing libraries
2024-02-28 22:24:00,455:INFO:Copying training dataset
2024-02-28 22:24:00,462:INFO:Defining folds
2024-02-28 22:24:00,462:INFO:Declaring metric variables
2024-02-28 22:24:00,466:INFO:Importing untrained model
2024-02-28 22:24:00,467:INFO:Decision Tree Regressor Imported successfully
2024-02-28 22:24:00,472:INFO:Starting cross validation
2024-02-28 22:24:00,472:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-28 22:24:00,524:INFO:Calculating mean and std
2024-02-28 22:24:00,524:INFO:Creating metrics dataframe
2024-02-28 22:24:00,524:INFO:Uploading results into container
2024-02-28 22:24:00,524:INFO:Uploading model into container now
2024-02-28 22:24:00,524:INFO:_master_model_container: 52
2024-02-28 22:24:00,524:INFO:_display_container: 2
2024-02-28 22:24:00,524:INFO:DecisionTreeRegressor(random_state=123)
2024-02-28 22:24:00,524:INFO:create_model() successfully completed......................................
2024-02-28 22:24:00,832:INFO:SubProcess create_model() end ==================================
2024-02-28 22:24:00,832:INFO:Creating metrics dataframe
2024-02-28 22:24:00,840:INFO:Initializing Random Forest Regressor
2024-02-28 22:24:00,840:INFO:Total runtime is 0.0783095359802246 minutes
2024-02-28 22:24:00,847:INFO:SubProcess create_model() called ==================================
2024-02-28 22:24:00,847:INFO:Initializing create_model()
2024-02-28 22:24:00,847:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571861F0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001601C9D5AC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:24:00,847:INFO:Checking exceptions
2024-02-28 22:24:00,847:INFO:Importing libraries
2024-02-28 22:24:00,848:INFO:Copying training dataset
2024-02-28 22:24:00,849:INFO:Defining folds
2024-02-28 22:24:00,849:INFO:Declaring metric variables
2024-02-28 22:24:00,853:INFO:Importing untrained model
2024-02-28 22:24:00,855:INFO:Random Forest Regressor Imported successfully
2024-02-28 22:24:00,855:INFO:Starting cross validation
2024-02-28 22:24:00,855:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-28 22:24:00,909:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:24:00,909:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:24:00,909:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:24:00,932:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:24:00,939:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:24:00,939:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:24:00,939:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:24:00,947:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:24:00,962:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:24:00,978:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:24:00,986:INFO:Calculating mean and std
2024-02-28 22:24:00,986:INFO:Creating metrics dataframe
2024-02-28 22:24:00,986:INFO:Uploading results into container
2024-02-28 22:24:00,986:INFO:Uploading model into container now
2024-02-28 22:24:00,986:INFO:_master_model_container: 53
2024-02-28 22:24:00,986:INFO:_display_container: 2
2024-02-28 22:24:00,986:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-02-28 22:24:00,986:INFO:create_model() successfully completed......................................
2024-02-28 22:24:01,286:INFO:SubProcess create_model() end ==================================
2024-02-28 22:24:01,286:INFO:Creating metrics dataframe
2024-02-28 22:24:01,295:INFO:Initializing Extra Trees Regressor
2024-02-28 22:24:01,296:INFO:Total runtime is 0.08591694831848143 minutes
2024-02-28 22:24:01,298:INFO:SubProcess create_model() called ==================================
2024-02-28 22:24:01,298:INFO:Initializing create_model()
2024-02-28 22:24:01,298:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571861F0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001601C9D5AC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:24:01,298:INFO:Checking exceptions
2024-02-28 22:24:01,298:INFO:Importing libraries
2024-02-28 22:24:01,298:INFO:Copying training dataset
2024-02-28 22:24:01,302:INFO:Defining folds
2024-02-28 22:24:01,302:INFO:Declaring metric variables
2024-02-28 22:24:01,303:INFO:Importing untrained model
2024-02-28 22:24:01,303:INFO:Extra Trees Regressor Imported successfully
2024-02-28 22:24:01,312:INFO:Starting cross validation
2024-02-28 22:24:01,312:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-28 22:24:01,370:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:24:01,370:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:24:01,370:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:24:01,380:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:24:01,401:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:24:01,408:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:24:01,424:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:24:01,432:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:24:01,439:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:24:01,447:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:24:01,455:INFO:Calculating mean and std
2024-02-28 22:24:01,455:INFO:Creating metrics dataframe
2024-02-28 22:24:01,455:INFO:Uploading results into container
2024-02-28 22:24:01,455:INFO:Uploading model into container now
2024-02-28 22:24:01,455:INFO:_master_model_container: 54
2024-02-28 22:24:01,455:INFO:_display_container: 2
2024-02-28 22:24:01,455:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-02-28 22:24:01,455:INFO:create_model() successfully completed......................................
2024-02-28 22:24:01,763:INFO:SubProcess create_model() end ==================================
2024-02-28 22:24:01,763:INFO:Creating metrics dataframe
2024-02-28 22:24:01,770:INFO:Initializing AdaBoost Regressor
2024-02-28 22:24:01,770:INFO:Total runtime is 0.09382128318150837 minutes
2024-02-28 22:24:01,778:INFO:SubProcess create_model() called ==================================
2024-02-28 22:24:01,778:INFO:Initializing create_model()
2024-02-28 22:24:01,778:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571861F0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001601C9D5AC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:24:01,778:INFO:Checking exceptions
2024-02-28 22:24:01,778:INFO:Importing libraries
2024-02-28 22:24:01,778:INFO:Copying training dataset
2024-02-28 22:24:01,778:INFO:Defining folds
2024-02-28 22:24:01,778:INFO:Declaring metric variables
2024-02-28 22:24:01,778:INFO:Importing untrained model
2024-02-28 22:24:01,787:INFO:AdaBoost Regressor Imported successfully
2024-02-28 22:24:01,788:INFO:Starting cross validation
2024-02-28 22:24:01,788:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-28 22:24:01,909:INFO:Calculating mean and std
2024-02-28 22:24:01,909:INFO:Creating metrics dataframe
2024-02-28 22:24:01,909:INFO:Uploading results into container
2024-02-28 22:24:01,909:INFO:Uploading model into container now
2024-02-28 22:24:01,909:INFO:_master_model_container: 55
2024-02-28 22:24:01,909:INFO:_display_container: 2
2024-02-28 22:24:01,909:INFO:AdaBoostRegressor(random_state=123)
2024-02-28 22:24:01,909:INFO:create_model() successfully completed......................................
2024-02-28 22:24:02,219:INFO:SubProcess create_model() end ==================================
2024-02-28 22:24:02,219:INFO:Creating metrics dataframe
2024-02-28 22:24:02,225:INFO:Initializing Gradient Boosting Regressor
2024-02-28 22:24:02,225:INFO:Total runtime is 0.10140437682469684 minutes
2024-02-28 22:24:02,232:INFO:SubProcess create_model() called ==================================
2024-02-28 22:24:02,233:INFO:Initializing create_model()
2024-02-28 22:24:02,233:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571861F0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001601C9D5AC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:24:02,233:INFO:Checking exceptions
2024-02-28 22:24:02,233:INFO:Importing libraries
2024-02-28 22:24:02,233:INFO:Copying training dataset
2024-02-28 22:24:02,234:INFO:Defining folds
2024-02-28 22:24:02,234:INFO:Declaring metric variables
2024-02-28 22:24:02,234:INFO:Importing untrained model
2024-02-28 22:24:02,241:INFO:Gradient Boosting Regressor Imported successfully
2024-02-28 22:24:02,242:INFO:Starting cross validation
2024-02-28 22:24:02,242:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-28 22:24:02,363:INFO:Calculating mean and std
2024-02-28 22:24:02,363:INFO:Creating metrics dataframe
2024-02-28 22:24:02,363:INFO:Uploading results into container
2024-02-28 22:24:02,363:INFO:Uploading model into container now
2024-02-28 22:24:02,363:INFO:_master_model_container: 56
2024-02-28 22:24:02,363:INFO:_display_container: 2
2024-02-28 22:24:02,363:INFO:GradientBoostingRegressor(random_state=123)
2024-02-28 22:24:02,363:INFO:create_model() successfully completed......................................
2024-02-28 22:24:02,678:INFO:SubProcess create_model() end ==================================
2024-02-28 22:24:02,678:INFO:Creating metrics dataframe
2024-02-28 22:24:02,687:INFO:Initializing Extreme Gradient Boosting
2024-02-28 22:24:02,687:INFO:Total runtime is 0.10909942388534544 minutes
2024-02-28 22:24:02,690:INFO:SubProcess create_model() called ==================================
2024-02-28 22:24:02,690:INFO:Initializing create_model()
2024-02-28 22:24:02,690:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571861F0>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001601C9D5AC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:24:02,690:INFO:Checking exceptions
2024-02-28 22:24:02,690:INFO:Importing libraries
2024-02-28 22:24:02,690:INFO:Copying training dataset
2024-02-28 22:24:02,693:INFO:Defining folds
2024-02-28 22:24:02,693:INFO:Declaring metric variables
2024-02-28 22:24:02,696:INFO:Importing untrained model
2024-02-28 22:24:02,696:INFO:Extreme Gradient Boosting Imported successfully
2024-02-28 22:24:02,703:INFO:Starting cross validation
2024-02-28 22:24:02,704:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-28 22:24:02,832:INFO:Calculating mean and std
2024-02-28 22:24:02,833:INFO:Creating metrics dataframe
2024-02-28 22:24:02,833:INFO:Uploading results into container
2024-02-28 22:24:02,833:INFO:Uploading model into container now
2024-02-28 22:24:02,833:INFO:_master_model_container: 57
2024-02-28 22:24:02,833:INFO:_display_container: 2
2024-02-28 22:24:02,833:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=123, ...)
2024-02-28 22:24:02,833:INFO:create_model() successfully completed......................................
2024-02-28 22:24:03,140:INFO:SubProcess create_model() end ==================================
2024-02-28 22:24:03,140:INFO:Creating metrics dataframe
2024-02-28 22:24:03,156:INFO:Initializing Light Gradient Boosting Machine
2024-02-28 22:24:03,156:INFO:Total runtime is 0.11690924962361651 minutes
2024-02-28 22:24:03,158:INFO:SubProcess create_model() called ==================================
2024-02-28 22:24:03,158:INFO:Initializing create_model()
2024-02-28 22:24:03,158:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571861F0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001601C9D5AC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:24:03,158:INFO:Checking exceptions
2024-02-28 22:24:03,158:INFO:Importing libraries
2024-02-28 22:24:03,158:INFO:Copying training dataset
2024-02-28 22:24:03,161:INFO:Defining folds
2024-02-28 22:24:03,161:INFO:Declaring metric variables
2024-02-28 22:24:03,163:INFO:Importing untrained model
2024-02-28 22:24:03,165:INFO:Light Gradient Boosting Machine Imported successfully
2024-02-28 22:24:03,171:INFO:Starting cross validation
2024-02-28 22:24:03,171:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-28 22:24:03,512:INFO:Calculating mean and std
2024-02-28 22:24:03,512:INFO:Creating metrics dataframe
2024-02-28 22:24:03,516:INFO:Uploading results into container
2024-02-28 22:24:03,516:INFO:Uploading model into container now
2024-02-28 22:24:03,517:INFO:_master_model_container: 58
2024-02-28 22:24:03,517:INFO:_display_container: 2
2024-02-28 22:24:03,517:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2024-02-28 22:24:03,517:INFO:create_model() successfully completed......................................
2024-02-28 22:24:03,834:INFO:SubProcess create_model() end ==================================
2024-02-28 22:24:03,834:INFO:Creating metrics dataframe
2024-02-28 22:24:03,850:INFO:Initializing CatBoost Regressor
2024-02-28 22:24:03,850:INFO:Total runtime is 0.12847923040390014 minutes
2024-02-28 22:24:03,850:INFO:SubProcess create_model() called ==================================
2024-02-28 22:24:03,850:INFO:Initializing create_model()
2024-02-28 22:24:03,850:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571861F0>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001601C9D5AC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:24:03,850:INFO:Checking exceptions
2024-02-28 22:24:03,850:INFO:Importing libraries
2024-02-28 22:24:03,850:INFO:Copying training dataset
2024-02-28 22:24:03,850:INFO:Defining folds
2024-02-28 22:24:03,850:INFO:Declaring metric variables
2024-02-28 22:24:03,858:INFO:Importing untrained model
2024-02-28 22:24:03,860:INFO:CatBoost Regressor Imported successfully
2024-02-28 22:24:03,864:INFO:Starting cross validation
2024-02-28 22:24:03,864:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-28 22:24:05,989:INFO:Calculating mean and std
2024-02-28 22:24:05,989:INFO:Creating metrics dataframe
2024-02-28 22:24:05,991:INFO:Uploading results into container
2024-02-28 22:24:05,992:INFO:Uploading model into container now
2024-02-28 22:24:05,992:INFO:_master_model_container: 59
2024-02-28 22:24:05,992:INFO:_display_container: 2
2024-02-28 22:24:05,992:INFO:<catboost.core.CatBoostRegressor object at 0x000001602212EAC0>
2024-02-28 22:24:05,992:INFO:create_model() successfully completed......................................
2024-02-28 22:24:06,309:INFO:SubProcess create_model() end ==================================
2024-02-28 22:24:06,309:INFO:Creating metrics dataframe
2024-02-28 22:24:06,318:INFO:Initializing Dummy Regressor
2024-02-28 22:24:06,318:INFO:Total runtime is 0.16961792707443235 minutes
2024-02-28 22:24:06,320:INFO:SubProcess create_model() called ==================================
2024-02-28 22:24:06,321:INFO:Initializing create_model()
2024-02-28 22:24:06,321:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571861F0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001601C9D5AC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:24:06,321:INFO:Checking exceptions
2024-02-28 22:24:06,321:INFO:Importing libraries
2024-02-28 22:24:06,321:INFO:Copying training dataset
2024-02-28 22:24:06,323:INFO:Defining folds
2024-02-28 22:24:06,323:INFO:Declaring metric variables
2024-02-28 22:24:06,324:INFO:Importing untrained model
2024-02-28 22:24:06,324:INFO:Dummy Regressor Imported successfully
2024-02-28 22:24:06,332:INFO:Starting cross validation
2024-02-28 22:24:06,333:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-28 22:24:06,386:INFO:Calculating mean and std
2024-02-28 22:24:06,386:INFO:Creating metrics dataframe
2024-02-28 22:24:06,387:INFO:Uploading results into container
2024-02-28 22:24:06,387:INFO:Uploading model into container now
2024-02-28 22:24:06,387:INFO:_master_model_container: 60
2024-02-28 22:24:06,387:INFO:_display_container: 2
2024-02-28 22:24:06,387:INFO:DummyRegressor()
2024-02-28 22:24:06,387:INFO:create_model() successfully completed......................................
2024-02-28 22:24:06,686:INFO:SubProcess create_model() end ==================================
2024-02-28 22:24:06,686:INFO:Creating metrics dataframe
2024-02-28 22:24:06,703:INFO:Initializing create_model()
2024-02-28 22:24:06,703:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571861F0>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:24:06,703:INFO:Checking exceptions
2024-02-28 22:24:06,704:INFO:Importing libraries
2024-02-28 22:24:06,704:INFO:Copying training dataset
2024-02-28 22:24:06,705:INFO:Defining folds
2024-02-28 22:24:06,705:INFO:Declaring metric variables
2024-02-28 22:24:06,705:INFO:Importing untrained model
2024-02-28 22:24:06,705:INFO:Declaring custom model
2024-02-28 22:24:06,705:INFO:Random Forest Regressor Imported successfully
2024-02-28 22:24:06,705:INFO:Cross validation set to False
2024-02-28 22:24:06,705:INFO:Fitting Model
2024-02-28 22:24:06,718:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-02-28 22:24:06,718:INFO:create_model() successfully completed......................................
2024-02-28 22:24:07,059:INFO:_master_model_container: 60
2024-02-28 22:24:07,059:INFO:_display_container: 2
2024-02-28 22:24:07,059:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-02-28 22:24:07,059:INFO:compare_models() successfully completed......................................
2024-02-28 22:25:33,134:INFO:Initializing create_model()
2024-02-28 22:25:33,134:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571F1E50>, estimator=catboost, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:25:33,134:INFO:Checking exceptions
2024-02-28 22:25:33,144:INFO:Importing libraries
2024-02-28 22:25:33,144:INFO:Copying training dataset
2024-02-28 22:25:33,146:INFO:Defining folds
2024-02-28 22:25:33,147:INFO:Declaring metric variables
2024-02-28 22:25:33,148:INFO:Importing untrained model
2024-02-28 22:25:33,149:INFO:CatBoost Regressor Imported successfully
2024-02-28 22:25:33,156:INFO:Starting cross validation
2024-02-28 22:25:33,157:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:26:28,394:INFO:PyCaret RegressionExperiment
2024-02-28 22:26:28,394:INFO:Logging name: reg-default-name
2024-02-28 22:26:28,394:INFO:ML Usecase: MLUsecase.REGRESSION
2024-02-28 22:26:28,394:INFO:version 3.3.0
2024-02-28 22:26:28,394:INFO:Initializing setup()
2024-02-28 22:26:28,394:INFO:self.USI: a893
2024-02-28 22:26:28,394:INFO:self._variable_keys: {'logging_param', '_ml_usecase', 'target_param', 'X_train', 'idx', 'data', 'y', 'exp_name_log', 'X_test', 'transform_target_param', 'log_plots_param', 'memory', 'html_param', '_available_plots', 'gpu_n_jobs_param', 'y_train', 'seed', 'USI', 'pipeline', 'exp_id', 'y_test', 'gpu_param', 'fold_shuffle_param', 'fold_generator', 'fold_groups_param', 'X', 'n_jobs_param'}
2024-02-28 22:26:28,394:INFO:Checking environment
2024-02-28 22:26:28,394:INFO:python_version: 3.9.18
2024-02-28 22:26:28,394:INFO:python_build: ('main', 'Dec 23 2023 16:29:04')
2024-02-28 22:26:28,394:INFO:machine: AMD64
2024-02-28 22:26:28,394:INFO:platform: Windows-10-10.0.22621-SP0
2024-02-28 22:26:28,397:INFO:Memory: svmem(total=34228445184, available=19096240128, percent=44.2, used=15132205056, free=19096240128)
2024-02-28 22:26:28,397:INFO:Physical Core: 8
2024-02-28 22:26:28,397:INFO:Logical Core: 16
2024-02-28 22:26:28,397:INFO:Checking libraries
2024-02-28 22:26:28,397:INFO:System:
2024-02-28 22:26:28,397:INFO:    python: 3.9.18 | packaged by conda-forge | (main, Dec 23 2023, 16:29:04) [MSC v.1929 64 bit (AMD64)]
2024-02-28 22:26:28,397:INFO:executable: c:\Users\Administrator\anaconda3\envs\EXAM_ML\python.exe
2024-02-28 22:26:28,397:INFO:   machine: Windows-10-10.0.22621-SP0
2024-02-28 22:26:28,397:INFO:PyCaret required dependencies:
2024-02-28 22:26:28,397:INFO:                 pip: 24.0
2024-02-28 22:26:28,397:INFO:          setuptools: 69.1.1
2024-02-28 22:26:28,397:INFO:             pycaret: 3.3.0
2024-02-28 22:26:28,397:INFO:             IPython: 8.12.0
2024-02-28 22:26:28,397:INFO:          ipywidgets: 8.1.2
2024-02-28 22:26:28,397:INFO:                tqdm: 4.66.2
2024-02-28 22:26:28,397:INFO:               numpy: 1.25.2
2024-02-28 22:26:28,397:INFO:              pandas: 1.5.3
2024-02-28 22:26:28,397:INFO:              jinja2: 3.1.3
2024-02-28 22:26:28,397:INFO:               scipy: 1.11.4
2024-02-28 22:26:28,397:INFO:              joblib: 1.3.2
2024-02-28 22:26:28,397:INFO:             sklearn: 1.4.1.post1
2024-02-28 22:26:28,398:INFO:                pyod: 1.1.3
2024-02-28 22:26:28,398:INFO:            imblearn: 0.12.0
2024-02-28 22:26:28,398:INFO:   category_encoders: 2.6.3
2024-02-28 22:26:28,398:INFO:            lightgbm: 4.3.0
2024-02-28 22:26:28,398:INFO:               numba: 0.58.1
2024-02-28 22:26:28,398:INFO:            requests: 2.31.0
2024-02-28 22:26:28,398:INFO:          matplotlib: 3.7.5
2024-02-28 22:26:28,398:INFO:          scikitplot: 0.3.7
2024-02-28 22:26:28,398:INFO:         yellowbrick: 1.5
2024-02-28 22:26:28,398:INFO:              plotly: 5.19.0
2024-02-28 22:26:28,398:INFO:    plotly-resampler: Not installed
2024-02-28 22:26:28,398:INFO:             kaleido: 0.2.1
2024-02-28 22:26:28,398:INFO:           schemdraw: 0.15
2024-02-28 22:26:28,398:INFO:         statsmodels: 0.14.1
2024-02-28 22:26:28,398:INFO:              sktime: 0.27.0
2024-02-28 22:26:28,398:INFO:               tbats: 1.1.3
2024-02-28 22:26:28,398:INFO:            pmdarima: 2.0.4
2024-02-28 22:26:28,398:INFO:              psutil: 5.9.8
2024-02-28 22:26:28,398:INFO:          markupsafe: 2.1.5
2024-02-28 22:26:28,398:INFO:             pickle5: Not installed
2024-02-28 22:26:28,398:INFO:         cloudpickle: 3.0.0
2024-02-28 22:26:28,398:INFO:         deprecation: 2.1.0
2024-02-28 22:26:28,398:INFO:              xxhash: 3.4.1
2024-02-28 22:26:28,398:INFO:           wurlitzer: Not installed
2024-02-28 22:26:28,398:INFO:PyCaret optional dependencies:
2024-02-28 22:26:28,398:INFO:                shap: 0.44.1
2024-02-28 22:26:28,398:INFO:           interpret: 0.5.1
2024-02-28 22:26:28,398:INFO:                umap: 0.5.5
2024-02-28 22:26:28,398:INFO:     ydata_profiling: 4.6.5
2024-02-28 22:26:28,398:INFO:  explainerdashboard: 0.4.5
2024-02-28 22:26:28,398:INFO:             autoviz: Not installed
2024-02-28 22:26:28,398:INFO:           fairlearn: 0.7.0
2024-02-28 22:26:28,399:INFO:          deepchecks: Not installed
2024-02-28 22:26:28,399:INFO:             xgboost: 2.0.3
2024-02-28 22:26:28,399:INFO:            catboost: 1.2.3
2024-02-28 22:26:28,399:INFO:              kmodes: 0.12.2
2024-02-28 22:26:28,399:INFO:             mlxtend: 0.23.1
2024-02-28 22:26:28,399:INFO:       statsforecast: 1.5.0
2024-02-28 22:26:28,399:INFO:        tune_sklearn: 0.5.0
2024-02-28 22:26:28,399:INFO:                 ray: 2.9.3
2024-02-28 22:26:28,399:INFO:            hyperopt: 0.2.7
2024-02-28 22:26:28,399:INFO:              optuna: 3.5.0
2024-02-28 22:26:28,399:INFO:               skopt: 0.9.0
2024-02-28 22:26:28,399:INFO:              mlflow: 2.10.2
2024-02-28 22:26:28,399:INFO:              gradio: 4.19.2
2024-02-28 22:26:28,399:INFO:             fastapi: 0.110.0
2024-02-28 22:26:28,399:INFO:             uvicorn: 0.27.1
2024-02-28 22:26:28,399:INFO:              m2cgen: 0.10.0
2024-02-28 22:26:28,399:INFO:           evidently: 0.4.16
2024-02-28 22:26:28,399:INFO:               fugue: 0.8.6
2024-02-28 22:26:28,399:INFO:           streamlit: Not installed
2024-02-28 22:26:28,399:INFO:             prophet: Not installed
2024-02-28 22:26:28,399:INFO:None
2024-02-28 22:26:28,399:INFO:Set up GPU usage.
2024-02-28 22:26:28,399:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:26:28,399:WARNING:cuML is outdated or not found. Required version is >=23.08.
                Please visit https://rapids.ai/install for installation instructions.
2024-02-28 22:26:28,399:INFO:Set up data.
2024-02-28 22:26:28,403:INFO:Set up folding strategy.
2024-02-28 22:26:28,403:INFO:Set up train/test split.
2024-02-28 22:26:28,406:INFO:Set up index.
2024-02-28 22:26:28,406:INFO:Assigning column types.
2024-02-28 22:26:28,408:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-02-28 22:26:28,408:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:26:28,408:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:26:28,412:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:26:28,412:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:26:28,452:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:26:28,488:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:26:28,488:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:26:28,488:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:26:28,596:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:26:28,596:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:26:28,596:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:26:28,604:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:26:28,605:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:26:28,649:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:26:28,680:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:26:28,680:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:26:28,680:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:26:28,772:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:26:28,772:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-02-28 22:26:28,772:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:26:28,772:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:26:28,772:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:26:28,772:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:26:28,819:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:26:28,842:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:26:28,842:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:26:28,842:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:26:28,935:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:26:28,936:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:26:28,936:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:26:28,936:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:26:28,942:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:26:28,988:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:26:29,026:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:26:29,026:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:26:29,026:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:26:29,103:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:26:29,103:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-02-28 22:26:29,103:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:26:29,103:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:26:29,103:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:26:29,111:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:26:29,149:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:26:29,180:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:26:29,180:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:26:29,180:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:26:29,261:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:26:29,262:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:26:29,262:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:26:29,265:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:26:29,265:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:26:29,303:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:26:29,334:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:26:29,334:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:26:29,334:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:26:29,419:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:26:29,419:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-02-28 22:26:29,419:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:26:29,419:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:26:29,419:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:26:29,426:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:26:29,480:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:26:29,511:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:26:29,518:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:26:29,519:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:26:29,596:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:26:29,596:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:26:29,596:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:26:29,603:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:26:29,603:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:26:29,642:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:26:29,672:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:26:29,672:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:26:29,672:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:26:29,757:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:26:29,757:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-02-28 22:26:29,757:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:26:29,757:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:26:29,765:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:26:29,765:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:26:29,811:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:26:29,842:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:26:29,842:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:26:29,842:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:26:29,934:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:26:29,934:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:26:29,934:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:26:29,934:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:26:29,942:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:26:29,981:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:26:30,011:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:26:30,011:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:26:30,011:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:26:30,090:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:26:30,090:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-02-28 22:26:30,090:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:26:30,090:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:26:30,096:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:26:30,103:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:26:30,142:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:26:30,172:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:26:30,172:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:26:30,172:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:26:30,254:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:26:30,254:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:26:30,254:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:26:30,258:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:26:30,261:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:26:30,296:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:26:30,326:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:26:30,326:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:26:30,326:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:26:30,403:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:26:30,403:INFO:Preparing preprocessing pipeline...
2024-02-28 22:26:30,403:INFO:Set up simple imputation.
2024-02-28 22:26:30,403:INFO:Set up feature normalization.
2024-02-28 22:26:30,419:INFO:Finished creating preprocessing pipeline.
2024-02-28 22:26:30,419:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\ADMINI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['cylinders', 'displacement',
                                             'horsepower', 'weight',
                                             'acceleration'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2024-02-28 22:26:30,419:INFO:Creating final display dataframe.
2024-02-28 22:26:30,472:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target               mpg
2                   Target type        Regression
3           Original data shape          (392, 6)
4        Transformed data shape          (392, 6)
5   Transformed train set shape          (274, 6)
6    Transformed test set shape          (118, 6)
7              Numeric features                 5
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                    Normalize              True
13             Normalize method            zscore
14               Fold Generator             KFold
15                  Fold Number                10
16                     CPU Jobs                -1
17                      Use GPU              True
18               Log Experiment             False
19              Experiment Name  reg-default-name
20                          USI              a893
2024-02-28 22:26:30,477:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:26:30,478:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:26:30,480:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:26:30,480:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:26:30,526:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:26:30,549:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:26:30,549:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:26:30,549:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:26:30,621:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:26:30,621:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:26:30,621:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:26:30,636:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:26:30,636:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:26:30,665:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:26:30,705:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:26:30,705:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-28 22:26:30,705:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-28 22:26:30,786:INFO:Soft dependency imported: catboost: 1.2.3
2024-02-28 22:26:30,788:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\internal\metrics.py:51: FutureWarning: The `needs_threshold` and `needs_proba` parameter are deprecated in version 1.4 and will be removed in 1.6. You can either let `response_method` be `None` or set it to `predict` to preserve the same behaviour.
  warnings.warn(

2024-02-28 22:26:30,788:INFO:setup() successfully completed in 2.4s...............
2024-02-28 22:26:35,740:INFO:Initializing compare_models()
2024-02-28 22:26:35,740:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571861F0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000160571861F0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-02-28 22:26:35,740:INFO:Checking exceptions
2024-02-28 22:26:35,740:INFO:Preparing display monitor
2024-02-28 22:26:35,759:INFO:Initializing Linear Regression
2024-02-28 22:26:35,759:INFO:Total runtime is 2.400080362955729e-06 minutes
2024-02-28 22:26:35,759:INFO:SubProcess create_model() called ==================================
2024-02-28 22:26:35,759:INFO:Initializing create_model()
2024-02-28 22:26:35,759:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571861F0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016025D52A60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:26:35,759:INFO:Checking exceptions
2024-02-28 22:26:35,759:INFO:Importing libraries
2024-02-28 22:26:35,759:INFO:Copying training dataset
2024-02-28 22:26:35,759:INFO:Defining folds
2024-02-28 22:26:35,759:INFO:Declaring metric variables
2024-02-28 22:26:35,766:INFO:Importing untrained model
2024-02-28 22:26:35,769:INFO:Linear Regression Imported successfully
2024-02-28 22:26:35,773:INFO:Starting cross validation
2024-02-28 22:26:35,773:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:26:35,906:INFO:Calculating mean and std
2024-02-28 22:26:35,907:INFO:Creating metrics dataframe
2024-02-28 22:26:35,908:INFO:Uploading results into container
2024-02-28 22:26:35,908:INFO:Uploading model into container now
2024-02-28 22:26:35,908:INFO:_master_model_container: 61
2024-02-28 22:26:35,908:INFO:_display_container: 2
2024-02-28 22:26:35,908:INFO:LinearRegression(n_jobs=-1)
2024-02-28 22:26:35,908:INFO:create_model() successfully completed......................................
2024-02-28 22:26:36,450:INFO:SubProcess create_model() end ==================================
2024-02-28 22:26:36,450:INFO:Creating metrics dataframe
2024-02-28 22:26:36,457:INFO:Initializing Lasso Regression
2024-02-28 22:26:36,458:INFO:Total runtime is 0.011637115478515625 minutes
2024-02-28 22:26:36,458:INFO:SubProcess create_model() called ==================================
2024-02-28 22:26:36,458:INFO:Initializing create_model()
2024-02-28 22:26:36,458:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571861F0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016025D52A60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:26:36,458:INFO:Checking exceptions
2024-02-28 22:26:36,458:INFO:Importing libraries
2024-02-28 22:26:36,458:INFO:Copying training dataset
2024-02-28 22:26:36,458:INFO:Defining folds
2024-02-28 22:26:36,458:INFO:Declaring metric variables
2024-02-28 22:26:36,465:INFO:Importing untrained model
2024-02-28 22:26:36,466:INFO:Lasso Regression Imported successfully
2024-02-28 22:26:36,473:INFO:Starting cross validation
2024-02-28 22:26:36,473:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:26:36,596:INFO:Calculating mean and std
2024-02-28 22:26:36,596:INFO:Creating metrics dataframe
2024-02-28 22:26:36,596:INFO:Uploading results into container
2024-02-28 22:26:36,596:INFO:Uploading model into container now
2024-02-28 22:26:36,596:INFO:_master_model_container: 62
2024-02-28 22:26:36,596:INFO:_display_container: 2
2024-02-28 22:26:36,596:INFO:Lasso(random_state=123)
2024-02-28 22:26:36,596:INFO:create_model() successfully completed......................................
2024-02-28 22:26:36,758:INFO:SubProcess create_model() end ==================================
2024-02-28 22:26:36,758:INFO:Creating metrics dataframe
2024-02-28 22:26:36,765:INFO:Initializing Ridge Regression
2024-02-28 22:26:36,765:INFO:Total runtime is 0.01675832668940226 minutes
2024-02-28 22:26:36,765:INFO:SubProcess create_model() called ==================================
2024-02-28 22:26:36,765:INFO:Initializing create_model()
2024-02-28 22:26:36,765:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571861F0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016025D52A60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:26:36,765:INFO:Checking exceptions
2024-02-28 22:26:36,765:INFO:Importing libraries
2024-02-28 22:26:36,765:INFO:Copying training dataset
2024-02-28 22:26:36,765:INFO:Defining folds
2024-02-28 22:26:36,765:INFO:Declaring metric variables
2024-02-28 22:26:36,772:INFO:Importing untrained model
2024-02-28 22:26:36,774:INFO:Ridge Regression Imported successfully
2024-02-28 22:26:36,775:INFO:Starting cross validation
2024-02-28 22:26:36,780:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:26:36,896:INFO:Calculating mean and std
2024-02-28 22:26:36,896:INFO:Creating metrics dataframe
2024-02-28 22:26:36,904:INFO:Uploading results into container
2024-02-28 22:26:36,904:INFO:Uploading model into container now
2024-02-28 22:26:36,904:INFO:_master_model_container: 63
2024-02-28 22:26:36,904:INFO:_display_container: 2
2024-02-28 22:26:36,904:INFO:Ridge(random_state=123)
2024-02-28 22:26:36,904:INFO:create_model() successfully completed......................................
2024-02-28 22:26:37,058:INFO:SubProcess create_model() end ==================================
2024-02-28 22:26:37,058:INFO:Creating metrics dataframe
2024-02-28 22:26:37,067:INFO:Initializing Elastic Net
2024-02-28 22:26:37,067:INFO:Total runtime is 0.021797509988149007 minutes
2024-02-28 22:26:37,073:INFO:SubProcess create_model() called ==================================
2024-02-28 22:26:37,073:INFO:Initializing create_model()
2024-02-28 22:26:37,073:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571861F0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016025D52A60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:26:37,073:INFO:Checking exceptions
2024-02-28 22:26:37,073:INFO:Importing libraries
2024-02-28 22:26:37,073:INFO:Copying training dataset
2024-02-28 22:26:37,077:INFO:Defining folds
2024-02-28 22:26:37,077:INFO:Declaring metric variables
2024-02-28 22:26:37,081:INFO:Importing untrained model
2024-02-28 22:26:37,084:INFO:Elastic Net Imported successfully
2024-02-28 22:26:37,091:INFO:Starting cross validation
2024-02-28 22:26:37,092:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:26:37,213:INFO:Calculating mean and std
2024-02-28 22:26:37,213:INFO:Creating metrics dataframe
2024-02-28 22:26:37,213:INFO:Uploading results into container
2024-02-28 22:26:37,213:INFO:Uploading model into container now
2024-02-28 22:26:37,213:INFO:_master_model_container: 64
2024-02-28 22:26:37,213:INFO:_display_container: 2
2024-02-28 22:26:37,213:INFO:ElasticNet(random_state=123)
2024-02-28 22:26:37,213:INFO:create_model() successfully completed......................................
2024-02-28 22:26:37,361:INFO:SubProcess create_model() end ==================================
2024-02-28 22:26:37,361:INFO:Creating metrics dataframe
2024-02-28 22:26:37,376:INFO:Initializing Least Angle Regression
2024-02-28 22:26:37,376:INFO:Total runtime is 0.026947808265686036 minutes
2024-02-28 22:26:37,381:INFO:SubProcess create_model() called ==================================
2024-02-28 22:26:37,382:INFO:Initializing create_model()
2024-02-28 22:26:37,382:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571861F0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016025D52A60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:26:37,382:INFO:Checking exceptions
2024-02-28 22:26:37,382:INFO:Importing libraries
2024-02-28 22:26:37,382:INFO:Copying training dataset
2024-02-28 22:26:37,385:INFO:Defining folds
2024-02-28 22:26:37,385:INFO:Declaring metric variables
2024-02-28 22:26:37,386:INFO:Importing untrained model
2024-02-28 22:26:37,390:INFO:Least Angle Regression Imported successfully
2024-02-28 22:26:37,392:INFO:Starting cross validation
2024-02-28 22:26:37,396:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:26:37,519:INFO:Calculating mean and std
2024-02-28 22:26:37,519:INFO:Creating metrics dataframe
2024-02-28 22:26:37,519:INFO:Uploading results into container
2024-02-28 22:26:37,519:INFO:Uploading model into container now
2024-02-28 22:26:37,519:INFO:_master_model_container: 65
2024-02-28 22:26:37,519:INFO:_display_container: 2
2024-02-28 22:26:37,519:INFO:Lars(random_state=123)
2024-02-28 22:26:37,519:INFO:create_model() successfully completed......................................
2024-02-28 22:26:37,660:INFO:SubProcess create_model() end ==================================
2024-02-28 22:26:37,660:INFO:Creating metrics dataframe
2024-02-28 22:26:37,677:INFO:Initializing Lasso Least Angle Regression
2024-02-28 22:26:37,677:INFO:Total runtime is 0.031957916418711346 minutes
2024-02-28 22:26:37,682:INFO:SubProcess create_model() called ==================================
2024-02-28 22:26:37,682:INFO:Initializing create_model()
2024-02-28 22:26:37,682:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571861F0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016025D52A60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:26:37,682:INFO:Checking exceptions
2024-02-28 22:26:37,682:INFO:Importing libraries
2024-02-28 22:26:37,682:INFO:Copying training dataset
2024-02-28 22:26:37,683:INFO:Defining folds
2024-02-28 22:26:37,683:INFO:Declaring metric variables
2024-02-28 22:26:37,683:INFO:Importing untrained model
2024-02-28 22:26:37,690:INFO:Lasso Least Angle Regression Imported successfully
2024-02-28 22:26:37,692:INFO:Starting cross validation
2024-02-28 22:26:37,696:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:26:37,813:INFO:Calculating mean and std
2024-02-28 22:26:37,813:INFO:Creating metrics dataframe
2024-02-28 22:26:37,813:INFO:Uploading results into container
2024-02-28 22:26:37,813:INFO:Uploading model into container now
2024-02-28 22:26:37,813:INFO:_master_model_container: 66
2024-02-28 22:26:37,813:INFO:_display_container: 2
2024-02-28 22:26:37,813:INFO:LassoLars(random_state=123)
2024-02-28 22:26:37,813:INFO:create_model() successfully completed......................................
2024-02-28 22:26:37,976:INFO:SubProcess create_model() end ==================================
2024-02-28 22:26:37,976:INFO:Creating metrics dataframe
2024-02-28 22:26:37,976:INFO:Initializing Orthogonal Matching Pursuit
2024-02-28 22:26:37,976:INFO:Total runtime is 0.03693735599517822 minutes
2024-02-28 22:26:37,986:INFO:SubProcess create_model() called ==================================
2024-02-28 22:26:37,986:INFO:Initializing create_model()
2024-02-28 22:26:37,986:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571861F0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016025D52A60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:26:37,986:INFO:Checking exceptions
2024-02-28 22:26:37,986:INFO:Importing libraries
2024-02-28 22:26:37,986:INFO:Copying training dataset
2024-02-28 22:26:37,989:INFO:Defining folds
2024-02-28 22:26:37,990:INFO:Declaring metric variables
2024-02-28 22:26:37,991:INFO:Importing untrained model
2024-02-28 22:26:37,991:INFO:Orthogonal Matching Pursuit Imported successfully
2024-02-28 22:26:37,998:INFO:Starting cross validation
2024-02-28 22:26:38,000:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:26:38,105:INFO:Calculating mean and std
2024-02-28 22:26:38,121:INFO:Creating metrics dataframe
2024-02-28 22:26:38,122:INFO:Uploading results into container
2024-02-28 22:26:38,123:INFO:Uploading model into container now
2024-02-28 22:26:38,123:INFO:_master_model_container: 67
2024-02-28 22:26:38,123:INFO:_display_container: 2
2024-02-28 22:26:38,123:INFO:OrthogonalMatchingPursuit()
2024-02-28 22:26:38,123:INFO:create_model() successfully completed......................................
2024-02-28 22:26:38,266:INFO:SubProcess create_model() end ==================================
2024-02-28 22:26:38,266:INFO:Creating metrics dataframe
2024-02-28 22:26:38,266:INFO:Initializing Bayesian Ridge
2024-02-28 22:26:38,266:INFO:Total runtime is 0.04177381992340088 minutes
2024-02-28 22:26:38,281:INFO:SubProcess create_model() called ==================================
2024-02-28 22:26:38,281:INFO:Initializing create_model()
2024-02-28 22:26:38,281:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571861F0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016025D52A60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:26:38,282:INFO:Checking exceptions
2024-02-28 22:26:38,282:INFO:Importing libraries
2024-02-28 22:26:38,282:INFO:Copying training dataset
2024-02-28 22:26:38,283:INFO:Defining folds
2024-02-28 22:26:38,283:INFO:Declaring metric variables
2024-02-28 22:26:38,283:INFO:Importing untrained model
2024-02-28 22:26:38,289:INFO:Bayesian Ridge Imported successfully
2024-02-28 22:26:38,292:INFO:Starting cross validation
2024-02-28 22:26:38,292:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:26:38,434:INFO:Calculating mean and std
2024-02-28 22:26:38,434:INFO:Creating metrics dataframe
2024-02-28 22:26:38,434:INFO:Uploading results into container
2024-02-28 22:26:38,442:INFO:Uploading model into container now
2024-02-28 22:26:38,442:INFO:_master_model_container: 68
2024-02-28 22:26:38,442:INFO:_display_container: 2
2024-02-28 22:26:38,442:INFO:BayesianRidge()
2024-02-28 22:26:38,442:INFO:create_model() successfully completed......................................
2024-02-28 22:26:38,588:INFO:SubProcess create_model() end ==================================
2024-02-28 22:26:38,588:INFO:Creating metrics dataframe
2024-02-28 22:26:38,598:INFO:Initializing Passive Aggressive Regressor
2024-02-28 22:26:38,598:INFO:Total runtime is 0.04731694459915161 minutes
2024-02-28 22:26:38,601:INFO:SubProcess create_model() called ==================================
2024-02-28 22:26:38,601:INFO:Initializing create_model()
2024-02-28 22:26:38,601:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571861F0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016025D52A60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:26:38,601:INFO:Checking exceptions
2024-02-28 22:26:38,601:INFO:Importing libraries
2024-02-28 22:26:38,601:INFO:Copying training dataset
2024-02-28 22:26:38,605:INFO:Defining folds
2024-02-28 22:26:38,605:INFO:Declaring metric variables
2024-02-28 22:26:38,606:INFO:Importing untrained model
2024-02-28 22:26:38,606:INFO:Passive Aggressive Regressor Imported successfully
2024-02-28 22:26:38,614:INFO:Starting cross validation
2024-02-28 22:26:38,615:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:26:38,742:INFO:Calculating mean and std
2024-02-28 22:26:38,742:INFO:Creating metrics dataframe
2024-02-28 22:26:38,747:INFO:Uploading results into container
2024-02-28 22:26:38,748:INFO:Uploading model into container now
2024-02-28 22:26:38,748:INFO:_master_model_container: 69
2024-02-28 22:26:38,748:INFO:_display_container: 2
2024-02-28 22:26:38,748:INFO:PassiveAggressiveRegressor(random_state=123)
2024-02-28 22:26:38,748:INFO:create_model() successfully completed......................................
2024-02-28 22:26:38,896:INFO:SubProcess create_model() end ==================================
2024-02-28 22:26:38,896:INFO:Creating metrics dataframe
2024-02-28 22:26:38,904:INFO:Initializing Huber Regressor
2024-02-28 22:26:38,904:INFO:Total runtime is 0.052406875292460124 minutes
2024-02-28 22:26:38,904:INFO:SubProcess create_model() called ==================================
2024-02-28 22:26:38,904:INFO:Initializing create_model()
2024-02-28 22:26:38,904:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571861F0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016025D52A60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:26:38,904:INFO:Checking exceptions
2024-02-28 22:26:38,904:INFO:Importing libraries
2024-02-28 22:26:38,904:INFO:Copying training dataset
2024-02-28 22:26:38,904:INFO:Defining folds
2024-02-28 22:26:38,904:INFO:Declaring metric variables
2024-02-28 22:26:38,912:INFO:Importing untrained model
2024-02-28 22:26:38,914:INFO:Huber Regressor Imported successfully
2024-02-28 22:26:38,919:INFO:Starting cross validation
2024-02-28 22:26:38,919:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:26:39,073:INFO:Calculating mean and std
2024-02-28 22:26:39,073:INFO:Creating metrics dataframe
2024-02-28 22:26:39,081:INFO:Uploading results into container
2024-02-28 22:26:39,081:INFO:Uploading model into container now
2024-02-28 22:26:39,081:INFO:_master_model_container: 70
2024-02-28 22:26:39,081:INFO:_display_container: 2
2024-02-28 22:26:39,081:INFO:HuberRegressor()
2024-02-28 22:26:39,081:INFO:create_model() successfully completed......................................
2024-02-28 22:26:39,227:INFO:SubProcess create_model() end ==================================
2024-02-28 22:26:39,227:INFO:Creating metrics dataframe
2024-02-28 22:26:39,235:INFO:Initializing K Neighbors Regressor
2024-02-28 22:26:39,235:INFO:Total runtime is 0.057921755313873294 minutes
2024-02-28 22:26:39,235:INFO:SubProcess create_model() called ==================================
2024-02-28 22:26:39,235:INFO:Initializing create_model()
2024-02-28 22:26:39,235:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571861F0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016025D52A60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:26:39,235:INFO:Checking exceptions
2024-02-28 22:26:39,235:INFO:Importing libraries
2024-02-28 22:26:39,235:INFO:Copying training dataset
2024-02-28 22:26:39,242:INFO:Defining folds
2024-02-28 22:26:39,242:INFO:Declaring metric variables
2024-02-28 22:26:39,244:INFO:Importing untrained model
2024-02-28 22:26:39,249:INFO:K Neighbors Regressor Imported successfully
2024-02-28 22:26:39,257:INFO:Starting cross validation
2024-02-28 22:26:39,258:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:26:39,383:INFO:Calculating mean and std
2024-02-28 22:26:39,383:INFO:Creating metrics dataframe
2024-02-28 22:26:39,398:INFO:Uploading results into container
2024-02-28 22:26:39,399:INFO:Uploading model into container now
2024-02-28 22:26:39,399:INFO:_master_model_container: 71
2024-02-28 22:26:39,399:INFO:_display_container: 2
2024-02-28 22:26:39,399:INFO:KNeighborsRegressor(n_jobs=-1)
2024-02-28 22:26:39,399:INFO:create_model() successfully completed......................................
2024-02-28 22:26:39,545:INFO:SubProcess create_model() end ==================================
2024-02-28 22:26:39,545:INFO:Creating metrics dataframe
2024-02-28 22:26:39,551:INFO:Initializing Decision Tree Regressor
2024-02-28 22:26:39,551:INFO:Total runtime is 0.06319348812103272 minutes
2024-02-28 22:26:39,551:INFO:SubProcess create_model() called ==================================
2024-02-28 22:26:39,551:INFO:Initializing create_model()
2024-02-28 22:26:39,551:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571861F0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016025D52A60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:26:39,551:INFO:Checking exceptions
2024-02-28 22:26:39,551:INFO:Importing libraries
2024-02-28 22:26:39,551:INFO:Copying training dataset
2024-02-28 22:26:39,551:INFO:Defining folds
2024-02-28 22:26:39,551:INFO:Declaring metric variables
2024-02-28 22:26:39,563:INFO:Importing untrained model
2024-02-28 22:26:39,565:INFO:Decision Tree Regressor Imported successfully
2024-02-28 22:26:39,566:INFO:Starting cross validation
2024-02-28 22:26:39,566:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:26:39,690:INFO:Calculating mean and std
2024-02-28 22:26:39,690:INFO:Creating metrics dataframe
2024-02-28 22:26:39,690:INFO:Uploading results into container
2024-02-28 22:26:39,690:INFO:Uploading model into container now
2024-02-28 22:26:39,690:INFO:_master_model_container: 72
2024-02-28 22:26:39,690:INFO:_display_container: 2
2024-02-28 22:26:39,690:INFO:DecisionTreeRegressor(random_state=123)
2024-02-28 22:26:39,690:INFO:create_model() successfully completed......................................
2024-02-28 22:26:39,838:INFO:SubProcess create_model() end ==================================
2024-02-28 22:26:39,838:INFO:Creating metrics dataframe
2024-02-28 22:26:39,859:INFO:Initializing Random Forest Regressor
2024-02-28 22:26:39,859:INFO:Total runtime is 0.06832088629404703 minutes
2024-02-28 22:26:39,860:INFO:SubProcess create_model() called ==================================
2024-02-28 22:26:39,861:INFO:Initializing create_model()
2024-02-28 22:26:39,861:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571861F0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016025D52A60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:26:39,861:INFO:Checking exceptions
2024-02-28 22:26:39,861:INFO:Importing libraries
2024-02-28 22:26:39,861:INFO:Copying training dataset
2024-02-28 22:26:39,864:INFO:Defining folds
2024-02-28 22:26:39,864:INFO:Declaring metric variables
2024-02-28 22:26:39,866:INFO:Importing untrained model
2024-02-28 22:26:39,869:INFO:Random Forest Regressor Imported successfully
2024-02-28 22:26:39,874:INFO:Starting cross validation
2024-02-28 22:26:39,875:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:26:39,890:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:26:39,905:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:26:39,921:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:26:39,935:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:26:39,950:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:26:39,967:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:26:39,982:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:26:39,998:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:26:40,029:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:26:40,045:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:26:40,045:INFO:Calculating mean and std
2024-02-28 22:26:40,045:INFO:Creating metrics dataframe
2024-02-28 22:26:40,050:INFO:Uploading results into container
2024-02-28 22:26:40,050:INFO:Uploading model into container now
2024-02-28 22:26:40,050:INFO:_master_model_container: 73
2024-02-28 22:26:40,050:INFO:_display_container: 2
2024-02-28 22:26:40,050:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-02-28 22:26:40,050:INFO:create_model() successfully completed......................................
2024-02-28 22:26:40,196:INFO:SubProcess create_model() end ==================================
2024-02-28 22:26:40,196:INFO:Creating metrics dataframe
2024-02-28 22:26:40,204:INFO:Initializing Extra Trees Regressor
2024-02-28 22:26:40,204:INFO:Total runtime is 0.07408535877863566 minutes
2024-02-28 22:26:40,208:INFO:SubProcess create_model() called ==================================
2024-02-28 22:26:40,208:INFO:Initializing create_model()
2024-02-28 22:26:40,208:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571861F0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016025D52A60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:26:40,208:INFO:Checking exceptions
2024-02-28 22:26:40,208:INFO:Importing libraries
2024-02-28 22:26:40,208:INFO:Copying training dataset
2024-02-28 22:26:40,208:INFO:Defining folds
2024-02-28 22:26:40,211:INFO:Declaring metric variables
2024-02-28 22:26:40,213:INFO:Importing untrained model
2024-02-28 22:26:40,213:INFO:Extra Trees Regressor Imported successfully
2024-02-28 22:26:40,220:INFO:Starting cross validation
2024-02-28 22:26:40,221:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:26:40,238:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:26:40,255:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:26:40,274:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:26:40,280:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:26:40,296:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:26:40,327:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:26:40,342:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:26:40,358:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:26:40,374:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:26:40,382:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:26:40,398:INFO:Calculating mean and std
2024-02-28 22:26:40,398:INFO:Creating metrics dataframe
2024-02-28 22:26:40,402:INFO:Uploading results into container
2024-02-28 22:26:40,403:INFO:Uploading model into container now
2024-02-28 22:26:40,403:INFO:_master_model_container: 74
2024-02-28 22:26:40,403:INFO:_display_container: 2
2024-02-28 22:26:40,403:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-02-28 22:26:40,403:INFO:create_model() successfully completed......................................
2024-02-28 22:26:40,545:INFO:SubProcess create_model() end ==================================
2024-02-28 22:26:40,545:INFO:Creating metrics dataframe
2024-02-28 22:26:40,545:INFO:Initializing AdaBoost Regressor
2024-02-28 22:26:40,545:INFO:Total runtime is 0.07975362141927084 minutes
2024-02-28 22:26:40,560:INFO:SubProcess create_model() called ==================================
2024-02-28 22:26:40,560:INFO:Initializing create_model()
2024-02-28 22:26:40,560:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571861F0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016025D52A60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:26:40,560:INFO:Checking exceptions
2024-02-28 22:26:40,560:INFO:Importing libraries
2024-02-28 22:26:40,560:INFO:Copying training dataset
2024-02-28 22:26:40,560:INFO:Defining folds
2024-02-28 22:26:40,560:INFO:Declaring metric variables
2024-02-28 22:26:40,567:INFO:Importing untrained model
2024-02-28 22:26:40,570:INFO:AdaBoost Regressor Imported successfully
2024-02-28 22:26:40,575:INFO:Starting cross validation
2024-02-28 22:26:40,575:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:26:41,097:INFO:Calculating mean and std
2024-02-28 22:26:41,097:INFO:Creating metrics dataframe
2024-02-28 22:26:41,097:INFO:Uploading results into container
2024-02-28 22:26:41,097:INFO:Uploading model into container now
2024-02-28 22:26:41,097:INFO:_master_model_container: 75
2024-02-28 22:26:41,097:INFO:_display_container: 2
2024-02-28 22:26:41,097:INFO:AdaBoostRegressor(random_state=123)
2024-02-28 22:26:41,097:INFO:create_model() successfully completed......................................
2024-02-28 22:26:41,236:INFO:SubProcess create_model() end ==================================
2024-02-28 22:26:41,236:INFO:Creating metrics dataframe
2024-02-28 22:26:41,259:INFO:Initializing Gradient Boosting Regressor
2024-02-28 22:26:41,259:INFO:Total runtime is 0.09166446924209595 minutes
2024-02-28 22:26:41,259:INFO:SubProcess create_model() called ==================================
2024-02-28 22:26:41,259:INFO:Initializing create_model()
2024-02-28 22:26:41,259:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571861F0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016025D52A60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:26:41,259:INFO:Checking exceptions
2024-02-28 22:26:41,259:INFO:Importing libraries
2024-02-28 22:26:41,259:INFO:Copying training dataset
2024-02-28 22:26:41,259:INFO:Defining folds
2024-02-28 22:26:41,265:INFO:Declaring metric variables
2024-02-28 22:26:41,267:INFO:Importing untrained model
2024-02-28 22:26:41,269:INFO:Gradient Boosting Regressor Imported successfully
2024-02-28 22:26:41,274:INFO:Starting cross validation
2024-02-28 22:26:41,275:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:26:41,822:INFO:Calculating mean and std
2024-02-28 22:26:41,822:INFO:Creating metrics dataframe
2024-02-28 22:26:41,822:INFO:Uploading results into container
2024-02-28 22:26:41,822:INFO:Uploading model into container now
2024-02-28 22:26:41,822:INFO:_master_model_container: 76
2024-02-28 22:26:41,822:INFO:_display_container: 2
2024-02-28 22:26:41,822:INFO:GradientBoostingRegressor(random_state=123)
2024-02-28 22:26:41,822:INFO:create_model() successfully completed......................................
2024-02-28 22:26:41,967:INFO:SubProcess create_model() end ==================================
2024-02-28 22:26:41,967:INFO:Creating metrics dataframe
2024-02-28 22:26:41,983:INFO:Initializing Extreme Gradient Boosting
2024-02-28 22:26:41,983:INFO:Total runtime is 0.10372122526168824 minutes
2024-02-28 22:26:41,988:INFO:SubProcess create_model() called ==================================
2024-02-28 22:26:41,989:INFO:Initializing create_model()
2024-02-28 22:26:41,989:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571861F0>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016025D52A60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:26:41,989:INFO:Checking exceptions
2024-02-28 22:26:41,989:INFO:Importing libraries
2024-02-28 22:26:41,989:INFO:Copying training dataset
2024-02-28 22:26:41,991:INFO:Defining folds
2024-02-28 22:26:41,991:INFO:Declaring metric variables
2024-02-28 22:26:41,991:INFO:Importing untrained model
2024-02-28 22:26:41,997:INFO:Extreme Gradient Boosting Imported successfully
2024-02-28 22:26:42,000:INFO:Starting cross validation
2024-02-28 22:26:42,000:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:26:44,596:INFO:Calculating mean and std
2024-02-28 22:26:44,603:INFO:Creating metrics dataframe
2024-02-28 22:26:44,606:INFO:Uploading results into container
2024-02-28 22:26:44,606:INFO:Uploading model into container now
2024-02-28 22:26:44,606:INFO:_master_model_container: 77
2024-02-28 22:26:44,606:INFO:_display_container: 2
2024-02-28 22:26:44,607:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='gpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=123, ...)
2024-02-28 22:26:44,607:INFO:create_model() successfully completed......................................
2024-02-28 22:26:44,775:INFO:SubProcess create_model() end ==================================
2024-02-28 22:26:44,775:INFO:Creating metrics dataframe
2024-02-28 22:26:44,781:INFO:Initializing Light Gradient Boosting Machine
2024-02-28 22:26:44,781:INFO:Total runtime is 0.15035796165466309 minutes
2024-02-28 22:26:44,788:INFO:SubProcess create_model() called ==================================
2024-02-28 22:26:44,788:INFO:Initializing create_model()
2024-02-28 22:26:44,788:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571861F0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016025D52A60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:26:44,788:INFO:Checking exceptions
2024-02-28 22:26:44,788:INFO:Importing libraries
2024-02-28 22:26:44,788:INFO:Copying training dataset
2024-02-28 22:26:44,788:INFO:Defining folds
2024-02-28 22:26:44,788:INFO:Declaring metric variables
2024-02-28 22:26:44,795:INFO:Importing untrained model
2024-02-28 22:26:44,797:INFO:Light Gradient Boosting Machine Imported successfully
2024-02-28 22:26:44,798:INFO:Starting cross validation
2024-02-28 22:26:44,798:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:26:44,812:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-02-28 22:26:44,812:INFO:[LightGBM] [Info] Total Bins 221
2024-02-28 22:26:44,812:INFO:[LightGBM] [Info] Number of data points in the train set: 246, number of used features: 5
2024-02-28 22:26:44,871:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-02-28 22:26:44,871:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-02-28 22:26:44,874:INFO:[LightGBM] [Info] GPU programs have been built
2024-02-28 22:26:44,880:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-02-28 22:26:44,881:INFO:[LightGBM] [Info] 5 dense feature groups (0.00 MB) transferred to GPU in 0.000393 secs. 0 sparse feature groups
2024-02-28 22:26:44,881:INFO:[LightGBM] [Info] Start training from score 23.452033
2024-02-28 22:26:44,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:44,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:44,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:44,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:44,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:44,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:44,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:44,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:44,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:44,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:44,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:44,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:44,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:44,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:44,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:44,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:44,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:44,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:44,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:44,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:44,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:44,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:44,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:44,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:44,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:44,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:44,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:44,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:44,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:44,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:44,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:44,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:44,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:44,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:44,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:44,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:44,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:44,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:44,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:44,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:44,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:44,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:44,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:44,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:44,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:44,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:44,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:44,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:44,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:44,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:44,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:44,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:44,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:44,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:44,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:44,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:44,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:44,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:44,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:44,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:44,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:44,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:44,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:44,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:44,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:44,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:44,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:44,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:44,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:44,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:44,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:44,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:44,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:44,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:44,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:44,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:44,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:44,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:44,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:44,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:44,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:44,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:44,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:44,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:44,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:44,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:44,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:44,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:44,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:44,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:44,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:44,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:44,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:44,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:44,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:44,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:44,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:44,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:44,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:44,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,019:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-02-28 22:26:45,019:INFO:[LightGBM] [Info] Total Bins 222
2024-02-28 22:26:45,019:INFO:[LightGBM] [Info] Number of data points in the train set: 246, number of used features: 5
2024-02-28 22:26:45,090:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-02-28 22:26:45,090:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-02-28 22:26:45,090:INFO:[LightGBM] [Info] GPU programs have been built
2024-02-28 22:26:45,090:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-02-28 22:26:45,090:INFO:[LightGBM] [Info] 5 dense feature groups (0.00 MB) transferred to GPU in 0.000350 secs. 0 sparse feature groups
2024-02-28 22:26:45,090:INFO:[LightGBM] [Info] Start training from score 23.622358
2024-02-28 22:26:45,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,243:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-02-28 22:26:45,243:INFO:[LightGBM] [Info] Total Bins 217
2024-02-28 22:26:45,243:INFO:[LightGBM] [Info] Number of data points in the train set: 246, number of used features: 5
2024-02-28 22:26:45,298:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-02-28 22:26:45,298:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-02-28 22:26:45,313:INFO:[LightGBM] [Info] GPU programs have been built
2024-02-28 22:26:45,313:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-02-28 22:26:45,313:INFO:[LightGBM] [Info] 5 dense feature groups (0.00 MB) transferred to GPU in 0.000416 secs. 0 sparse feature groups
2024-02-28 22:26:45,313:INFO:[LightGBM] [Info] Start training from score 23.693902
2024-02-28 22:26:45,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,466:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-02-28 22:26:45,466:INFO:[LightGBM] [Info] Total Bins 219
2024-02-28 22:26:45,466:INFO:[LightGBM] [Info] Number of data points in the train set: 246, number of used features: 5
2024-02-28 22:26:45,521:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-02-28 22:26:45,521:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-02-28 22:26:45,536:INFO:[LightGBM] [Info] GPU programs have been built
2024-02-28 22:26:45,536:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-02-28 22:26:45,536:INFO:[LightGBM] [Info] 5 dense feature groups (0.00 MB) transferred to GPU in 0.000347 secs. 0 sparse feature groups
2024-02-28 22:26:45,536:INFO:[LightGBM] [Info] Start training from score 23.815041
2024-02-28 22:26:45,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,690:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-02-28 22:26:45,690:INFO:[LightGBM] [Info] Total Bins 221
2024-02-28 22:26:45,690:INFO:[LightGBM] [Info] Number of data points in the train set: 247, number of used features: 5
2024-02-28 22:26:45,760:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-02-28 22:26:45,760:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-02-28 22:26:45,760:INFO:[LightGBM] [Info] GPU programs have been built
2024-02-28 22:26:45,760:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-02-28 22:26:45,760:INFO:[LightGBM] [Info] 5 dense feature groups (0.00 MB) transferred to GPU in 0.000384 secs. 0 sparse feature groups
2024-02-28 22:26:45,760:INFO:[LightGBM] [Info] Start training from score 23.681781
2024-02-28 22:26:45,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:45,938:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-02-28 22:26:45,938:INFO:[LightGBM] [Info] Total Bins 222
2024-02-28 22:26:45,938:INFO:[LightGBM] [Info] Number of data points in the train set: 247, number of used features: 5
2024-02-28 22:26:45,996:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-02-28 22:26:45,996:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-02-28 22:26:45,996:INFO:[LightGBM] [Info] GPU programs have been built
2024-02-28 22:26:46,004:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-02-28 22:26:46,004:INFO:[LightGBM] [Info] 5 dense feature groups (0.00 MB) transferred to GPU in 0.000396 secs. 0 sparse feature groups
2024-02-28 22:26:46,004:INFO:[LightGBM] [Info] Start training from score 23.918623
2024-02-28 22:26:46,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,140:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-02-28 22:26:46,140:INFO:[LightGBM] [Info] Total Bins 217
2024-02-28 22:26:46,140:INFO:[LightGBM] [Info] Number of data points in the train set: 247, number of used features: 5
2024-02-28 22:26:46,196:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-02-28 22:26:46,196:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-02-28 22:26:46,204:INFO:[LightGBM] [Info] GPU programs have been built
2024-02-28 22:26:46,204:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-02-28 22:26:46,204:INFO:[LightGBM] [Info] 5 dense feature groups (0.00 MB) transferred to GPU in 0.000374 secs. 0 sparse feature groups
2024-02-28 22:26:46,204:INFO:[LightGBM] [Info] Start training from score 23.956275
2024-02-28 22:26:46,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,357:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-02-28 22:26:46,357:INFO:[LightGBM] [Info] Total Bins 219
2024-02-28 22:26:46,357:INFO:[LightGBM] [Info] Number of data points in the train set: 247, number of used features: 5
2024-02-28 22:26:46,411:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-02-28 22:26:46,411:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-02-28 22:26:46,419:INFO:[LightGBM] [Info] GPU programs have been built
2024-02-28 22:26:46,419:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-02-28 22:26:46,419:INFO:[LightGBM] [Info] 5 dense feature groups (0.00 MB) transferred to GPU in 0.000371 secs. 0 sparse feature groups
2024-02-28 22:26:46,419:INFO:[LightGBM] [Info] Start training from score 23.765182
2024-02-28 22:26:46,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,572:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-02-28 22:26:46,572:INFO:[LightGBM] [Info] Total Bins 215
2024-02-28 22:26:46,572:INFO:[LightGBM] [Info] Number of data points in the train set: 247, number of used features: 5
2024-02-28 22:26:46,628:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-02-28 22:26:46,628:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-02-28 22:26:46,634:INFO:[LightGBM] [Info] GPU programs have been built
2024-02-28 22:26:46,635:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-02-28 22:26:46,635:INFO:[LightGBM] [Info] 5 dense feature groups (0.00 MB) transferred to GPU in 0.000354 secs. 0 sparse feature groups
2024-02-28 22:26:46,636:INFO:[LightGBM] [Info] Start training from score 23.770040
2024-02-28 22:26:46,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,788:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-02-28 22:26:46,788:INFO:[LightGBM] [Info] Total Bins 222
2024-02-28 22:26:46,788:INFO:[LightGBM] [Info] Number of data points in the train set: 247, number of used features: 5
2024-02-28 22:26:46,842:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-02-28 22:26:46,842:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-02-28 22:26:46,850:INFO:[LightGBM] [Info] GPU programs have been built
2024-02-28 22:26:46,850:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-02-28 22:26:46,850:INFO:[LightGBM] [Info] 5 dense feature groups (0.00 MB) transferred to GPU in 0.000367 secs. 0 sparse feature groups
2024-02-28 22:26:46,850:INFO:[LightGBM] [Info] Start training from score 23.837652
2024-02-28 22:26:46,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:26:46,994:INFO:Calculating mean and std
2024-02-28 22:26:46,995:INFO:Creating metrics dataframe
2024-02-28 22:26:46,998:INFO:Uploading results into container
2024-02-28 22:26:46,999:INFO:Uploading model into container now
2024-02-28 22:26:46,999:INFO:_master_model_container: 78
2024-02-28 22:26:46,999:INFO:_display_container: 2
2024-02-28 22:26:46,999:INFO:LGBMRegressor(device='gpu', n_jobs=-1, random_state=123)
2024-02-28 22:26:46,999:INFO:create_model() successfully completed......................................
2024-02-28 22:26:47,173:INFO:SubProcess create_model() end ==================================
2024-02-28 22:26:47,173:INFO:Creating metrics dataframe
2024-02-28 22:26:47,180:INFO:Initializing CatBoost Regressor
2024-02-28 22:26:47,180:INFO:Total runtime is 0.19035011529922485 minutes
2024-02-28 22:26:47,180:INFO:SubProcess create_model() called ==================================
2024-02-28 22:26:47,180:INFO:Initializing create_model()
2024-02-28 22:26:47,180:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571861F0>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016025D52A60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:26:47,180:INFO:Checking exceptions
2024-02-28 22:26:47,180:INFO:Importing libraries
2024-02-28 22:26:47,180:INFO:Copying training dataset
2024-02-28 22:26:47,188:INFO:Defining folds
2024-02-28 22:26:47,188:INFO:Declaring metric variables
2024-02-28 22:26:47,191:INFO:Importing untrained model
2024-02-28 22:26:47,194:INFO:CatBoost Regressor Imported successfully
2024-02-28 22:26:47,198:INFO:Starting cross validation
2024-02-28 22:26:47,198:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:28:01,907:INFO:Calculating mean and std
2024-02-28 22:28:01,907:INFO:Creating metrics dataframe
2024-02-28 22:28:01,907:INFO:Uploading results into container
2024-02-28 22:28:01,912:INFO:Uploading model into container now
2024-02-28 22:28:01,912:INFO:_master_model_container: 79
2024-02-28 22:28:01,912:INFO:_display_container: 2
2024-02-28 22:28:01,912:INFO:<catboost.core.CatBoostRegressor object at 0x00000160670ED2E0>
2024-02-28 22:28:01,912:INFO:create_model() successfully completed......................................
2024-02-28 22:28:02,077:INFO:SubProcess create_model() end ==================================
2024-02-28 22:28:02,077:INFO:Creating metrics dataframe
2024-02-28 22:28:02,089:INFO:Initializing Dummy Regressor
2024-02-28 22:28:02,089:INFO:Total runtime is 1.4388360261917115 minutes
2024-02-28 22:28:02,092:INFO:SubProcess create_model() called ==================================
2024-02-28 22:28:02,092:INFO:Initializing create_model()
2024-02-28 22:28:02,092:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571861F0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016025D52A60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:28:02,092:INFO:Checking exceptions
2024-02-28 22:28:02,092:INFO:Importing libraries
2024-02-28 22:28:02,092:INFO:Copying training dataset
2024-02-28 22:28:02,094:INFO:Defining folds
2024-02-28 22:28:02,094:INFO:Declaring metric variables
2024-02-28 22:28:02,097:INFO:Importing untrained model
2024-02-28 22:28:02,099:INFO:Dummy Regressor Imported successfully
2024-02-28 22:28:02,103:INFO:Starting cross validation
2024-02-28 22:28:02,104:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:28:02,205:INFO:Calculating mean and std
2024-02-28 22:28:02,205:INFO:Creating metrics dataframe
2024-02-28 22:28:02,213:INFO:Uploading results into container
2024-02-28 22:28:02,213:INFO:Uploading model into container now
2024-02-28 22:28:02,213:INFO:_master_model_container: 80
2024-02-28 22:28:02,213:INFO:_display_container: 2
2024-02-28 22:28:02,213:INFO:DummyRegressor()
2024-02-28 22:28:02,213:INFO:create_model() successfully completed......................................
2024-02-28 22:28:02,359:INFO:SubProcess create_model() end ==================================
2024-02-28 22:28:02,359:INFO:Creating metrics dataframe
2024-02-28 22:28:02,376:INFO:Initializing create_model()
2024-02-28 22:28:02,376:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571861F0>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:28:02,376:INFO:Checking exceptions
2024-02-28 22:28:02,376:INFO:Importing libraries
2024-02-28 22:28:02,376:INFO:Copying training dataset
2024-02-28 22:28:02,382:INFO:Defining folds
2024-02-28 22:28:02,382:INFO:Declaring metric variables
2024-02-28 22:28:02,382:INFO:Importing untrained model
2024-02-28 22:28:02,382:INFO:Declaring custom model
2024-02-28 22:28:02,382:INFO:Random Forest Regressor Imported successfully
2024-02-28 22:28:02,383:INFO:Cross validation set to False
2024-02-28 22:28:02,383:INFO:Fitting Model
2024-02-28 22:28:02,394:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-02-28 22:28:02,394:INFO:create_model() successfully completed......................................
2024-02-28 22:28:02,563:INFO:_master_model_container: 80
2024-02-28 22:28:02,563:INFO:_display_container: 2
2024-02-28 22:28:02,563:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-02-28 22:28:02,563:INFO:compare_models() successfully completed......................................
2024-02-28 22:28:12,454:INFO:Initializing create_model()
2024-02-28 22:28:12,454:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571F1E50>, estimator=rf, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:28:12,454:INFO:Checking exceptions
2024-02-28 22:28:12,466:INFO:Importing libraries
2024-02-28 22:28:12,466:INFO:Copying training dataset
2024-02-28 22:28:12,468:INFO:Defining folds
2024-02-28 22:28:12,468:INFO:Declaring metric variables
2024-02-28 22:28:12,470:INFO:Importing untrained model
2024-02-28 22:28:12,473:INFO:Random Forest Regressor Imported successfully
2024-02-28 22:28:12,477:INFO:Starting cross validation
2024-02-28 22:28:12,477:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:28:12,491:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:12,504:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:12,519:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:12,534:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:12,549:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:12,563:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:12,576:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:12,591:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:12,602:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:12,617:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:12,620:INFO:Calculating mean and std
2024-02-28 22:28:12,620:INFO:Creating metrics dataframe
2024-02-28 22:28:12,624:INFO:Finalizing model
2024-02-28 22:28:12,630:INFO:Uploading results into container
2024-02-28 22:28:12,636:INFO:Uploading model into container now
2024-02-28 22:28:12,642:INFO:_master_model_container: 1
2024-02-28 22:28:12,642:INFO:_display_container: 4
2024-02-28 22:28:12,643:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-02-28 22:28:12,643:INFO:create_model() successfully completed......................................
2024-02-28 22:28:27,868:INFO:Initializing create_model()
2024-02-28 22:28:27,871:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571F1E50>, estimator=rf, fold=100, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:28:27,871:INFO:Checking exceptions
2024-02-28 22:28:27,871:INFO:Importing libraries
2024-02-28 22:28:27,871:INFO:Copying training dataset
2024-02-28 22:28:27,884:INFO:Defining folds
2024-02-28 22:28:27,884:INFO:Declaring metric variables
2024-02-28 22:28:27,884:INFO:Importing untrained model
2024-02-28 22:28:27,890:INFO:Random Forest Regressor Imported successfully
2024-02-28 22:28:27,895:INFO:Starting cross validation
2024-02-28 22:28:27,895:INFO:Cross validating with KFold(n_splits=100, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:28:27,910:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:27,927:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:27,943:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:27,957:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:27,972:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:27,987:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:28,001:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:28,018:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:28,045:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:28,059:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:28,074:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:28,084:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:28,100:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:28,117:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:28,117:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:28,136:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:28,152:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:28,167:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:28,182:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:28,191:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:28,206:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:28,222:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:28,222:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:28,237:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:28,253:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:28,275:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:28,275:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:28,291:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:28,307:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:28,321:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:28,331:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:28,347:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:28,364:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:28,374:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:28,374:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:28,400:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:28,415:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:28,421:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:28,436:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:28,455:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:28,467:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:28,467:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:28,493:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:28,506:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:28,513:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:28,528:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:28,544:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:28,552:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:28,567:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:28,582:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:28,590:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:28,607:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:28,621:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:28,629:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:28,644:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:28,652:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:28,667:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:28,683:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:28,691:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:28,706:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:28,721:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:28,736:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:28,744:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:28,759:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:28,774:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:28,783:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:28,798:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:28,813:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:28,822:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:28,836:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:28,852:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:28,860:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:28,875:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:28,890:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:28,898:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:28,913:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:28,928:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:28,936:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:28,952:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:28,967:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:28,990:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:29,006:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:29,021:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:29,029:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:29,044:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:29,059:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:29,067:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:29,082:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:29,098:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:29,106:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:29,121:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:29,136:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:29,146:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:29,159:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:29,175:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:29,182:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:29,198:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:29,206:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:29,221:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:29,236:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:28:29,236:INFO:Calculating mean and std
2024-02-28 22:28:29,236:INFO:Creating metrics dataframe
2024-02-28 22:28:29,244:INFO:Finalizing model
2024-02-28 22:28:29,257:INFO:Uploading results into container
2024-02-28 22:28:29,257:INFO:Uploading model into container now
2024-02-28 22:28:29,283:INFO:_master_model_container: 2
2024-02-28 22:28:29,283:INFO:_display_container: 5
2024-02-28 22:28:29,284:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-02-28 22:28:29,284:INFO:create_model() successfully completed......................................
2024-02-28 22:29:43,022:INFO:Initializing tune_model()
2024-02-28 22:29:43,022:INFO:tune_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571F1E50>)
2024-02-28 22:29:43,022:INFO:Checking exceptions
2024-02-28 22:29:43,035:INFO:Copying training dataset
2024-02-28 22:29:43,037:INFO:Checking base model
2024-02-28 22:29:43,037:INFO:Base model : Random Forest Regressor
2024-02-28 22:29:43,039:INFO:Declaring metric variables
2024-02-28 22:29:43,041:INFO:Defining Hyperparameters
2024-02-28 22:29:43,215:INFO:Tuning with n_jobs=-1
2024-02-28 22:29:43,215:INFO:Initializing RandomizedSearchCV
2024-02-28 22:29:46,779:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:29:46,800:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:29:46,815:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:29:46,821:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:29:46,833:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:29:46,833:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:29:46,846:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:29:46,846:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:29:46,861:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:29:46,869:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:29:46,869:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:29:46,869:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:29:46,869:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:29:46,877:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:29:46,893:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:29:46,930:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:29:46,954:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:29:46,970:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:29:46,985:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:29:47,007:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:29:47,016:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:29:47,023:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:29:47,023:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:29:47,032:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:29:47,033:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:29:47,033:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:29:47,038:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:29:47,046:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:29:47,046:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:29:47,046:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:29:47,046:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:29:47,053:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:29:47,053:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:29:47,076:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:29:47,076:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:29:47,076:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:29:47,076:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:29:47,076:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:29:47,076:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:29:47,107:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:29:47,107:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:29:47,099:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:29:47,122:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:29:47,153:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:29:47,153:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:29:47,161:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:29:47,161:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:29:47,192:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:29:47,192:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:29:47,200:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:29:47,207:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:29:47,222:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:29:47,230:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:29:47,230:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:29:47,230:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:29:47,230:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:29:47,240:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:29:47,253:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:29:47,261:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:29:47,268:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:29:47,292:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:29:47,292:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:29:47,299:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:29:47,307:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:29:47,315:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:29:47,315:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:29:47,341:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:29:47,407:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:29:47,407:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:29:47,423:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:29:47,423:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:29:47,430:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:29:47,430:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:29:47,438:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:29:47,446:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:29:47,446:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:29:47,454:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:29:47,614:INFO:best_params: {'actual_estimator__n_estimators': 290, 'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__min_impurity_decrease': 0.0002, 'actual_estimator__max_features': 'log2', 'actual_estimator__max_depth': 6, 'actual_estimator__criterion': 'squared_error', 'actual_estimator__bootstrap': True}
2024-02-28 22:29:47,614:INFO:Hyperparameter search completed
2024-02-28 22:29:47,614:INFO:SubProcess create_model() called ==================================
2024-02-28 22:29:47,614:INFO:Initializing create_model()
2024-02-28 22:29:47,614:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571F1E50>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001602B91C400>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 290, 'min_samples_split': 2, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.0002, 'max_features': 'log2', 'max_depth': 6, 'criterion': 'squared_error', 'bootstrap': True})
2024-02-28 22:29:47,614:INFO:Checking exceptions
2024-02-28 22:29:47,614:INFO:Importing libraries
2024-02-28 22:29:47,614:INFO:Copying training dataset
2024-02-28 22:29:47,614:INFO:Defining folds
2024-02-28 22:29:47,614:INFO:Declaring metric variables
2024-02-28 22:29:47,621:INFO:Importing untrained model
2024-02-28 22:29:47,621:INFO:Declaring custom model
2024-02-28 22:29:47,624:INFO:Random Forest Regressor Imported successfully
2024-02-28 22:29:47,624:INFO:Starting cross validation
2024-02-28 22:29:47,630:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:29:47,641:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:29:47,656:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:29:47,669:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:29:47,691:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:29:47,707:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:29:47,722:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:29:47,738:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:29:47,745:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:29:47,761:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:29:47,776:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:29:47,776:INFO:Calculating mean and std
2024-02-28 22:29:47,784:INFO:Creating metrics dataframe
2024-02-28 22:29:47,784:INFO:Finalizing model
2024-02-28 22:29:47,799:INFO:Uploading results into container
2024-02-28 22:29:47,800:INFO:Uploading model into container now
2024-02-28 22:29:47,800:INFO:_master_model_container: 3
2024-02-28 22:29:47,800:INFO:_display_container: 6
2024-02-28 22:29:47,800:INFO:RandomForestRegressor(max_depth=6, max_features='log2',
                      min_impurity_decrease=0.0002, min_samples_leaf=2,
                      n_estimators=290, n_jobs=-1, random_state=123)
2024-02-28 22:29:47,800:INFO:create_model() successfully completed......................................
2024-02-28 22:29:47,939:INFO:SubProcess create_model() end ==================================
2024-02-28 22:29:47,939:INFO:choose_better activated
2024-02-28 22:29:47,939:INFO:SubProcess create_model() called ==================================
2024-02-28 22:29:47,939:INFO:Initializing create_model()
2024-02-28 22:29:47,939:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571F1E50>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:29:47,939:INFO:Checking exceptions
2024-02-28 22:29:47,939:INFO:Importing libraries
2024-02-28 22:29:47,939:INFO:Copying training dataset
2024-02-28 22:29:47,939:INFO:Defining folds
2024-02-28 22:29:47,939:INFO:Declaring metric variables
2024-02-28 22:29:47,939:INFO:Importing untrained model
2024-02-28 22:29:47,939:INFO:Declaring custom model
2024-02-28 22:29:47,939:INFO:Random Forest Regressor Imported successfully
2024-02-28 22:29:47,939:INFO:Starting cross validation
2024-02-28 22:29:47,939:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:29:47,961:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:29:47,978:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:29:47,992:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:29:47,999:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:29:48,015:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:29:48,031:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:29:48,040:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:29:48,055:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:29:48,071:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:29:48,071:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:29:48,086:INFO:Calculating mean and std
2024-02-28 22:29:48,086:INFO:Creating metrics dataframe
2024-02-28 22:29:48,086:INFO:Finalizing model
2024-02-28 22:29:48,086:INFO:Uploading results into container
2024-02-28 22:29:48,086:INFO:Uploading model into container now
2024-02-28 22:29:48,086:INFO:_master_model_container: 4
2024-02-28 22:29:48,086:INFO:_display_container: 7
2024-02-28 22:29:48,086:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-02-28 22:29:48,086:INFO:create_model() successfully completed......................................
2024-02-28 22:29:48,233:INFO:SubProcess create_model() end ==================================
2024-02-28 22:29:48,237:INFO:RandomForestRegressor(n_jobs=-1, random_state=123) result for R2 is 0.7694
2024-02-28 22:29:48,237:INFO:RandomForestRegressor(max_depth=6, max_features='log2',
                      min_impurity_decrease=0.0002, min_samples_leaf=2,
                      n_estimators=290, n_jobs=-1, random_state=123) result for R2 is 0.7688
2024-02-28 22:29:48,237:INFO:RandomForestRegressor(n_jobs=-1, random_state=123) is best model
2024-02-28 22:29:48,237:INFO:choose_better completed
2024-02-28 22:29:48,237:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-02-28 22:29:48,237:INFO:_master_model_container: 4
2024-02-28 22:29:48,237:INFO:_display_container: 6
2024-02-28 22:29:48,245:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-02-28 22:29:48,245:INFO:tune_model() successfully completed......................................
2024-02-28 22:31:42,902:INFO:Initializing ensemble_model()
2024-02-28 22:31:42,902:INFO:ensemble_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571F1E50>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=False, optimize=R2, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2024-02-28 22:31:42,902:INFO:Checking exceptions
2024-02-28 22:31:42,913:INFO:Importing libraries
2024-02-28 22:31:42,913:INFO:Copying training dataset
2024-02-28 22:31:42,913:INFO:Checking base model
2024-02-28 22:31:42,913:INFO:Base model : Random Forest Regressor
2024-02-28 22:31:42,917:INFO:Importing untrained ensembler
2024-02-28 22:31:42,918:INFO:Ensemble method set to Bagging
2024-02-28 22:31:42,918:INFO:SubProcess create_model() called ==================================
2024-02-28 22:31:42,918:INFO:Initializing create_model()
2024-02-28 22:31:42,918:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571F1E50>, estimator=BaggingRegressor(estimator=RandomForestRegressor(n_jobs=-1, random_state=123),
                 n_jobs=1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000160650DC190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:31:42,918:INFO:Checking exceptions
2024-02-28 22:31:42,918:INFO:Importing libraries
2024-02-28 22:31:42,918:INFO:Copying training dataset
2024-02-28 22:31:42,920:INFO:Defining folds
2024-02-28 22:31:42,921:INFO:Declaring metric variables
2024-02-28 22:31:42,924:INFO:Importing untrained model
2024-02-28 22:31:42,924:INFO:Declaring custom model
2024-02-28 22:31:42,927:INFO:Random Forest Regressor Imported successfully
2024-02-28 22:31:42,931:INFO:Starting cross validation
2024-02-28 22:31:42,932:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:31:42,986:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\ensemble\_bagging.py:218: RuntimeWarning: invalid value encountered in add
  return sum(

2024-02-28 22:31:42,994:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 680, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:31:42,994:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:31:42,994:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 207, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:31:42,994:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:31:42,994:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 572, in root_mean_squared_error
    mean_squared_error(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 186, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:31:42,994:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 1180, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:31:43,068:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\ensemble\_bagging.py:218: RuntimeWarning: invalid value encountered in add
  return sum(

2024-02-28 22:31:43,076:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 680, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:31:43,077:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:31:43,077:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 207, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:31:43,077:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:31:43,077:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 572, in root_mean_squared_error
    mean_squared_error(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 186, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:31:43,077:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 1180, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:31:43,132:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 680, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:31:43,132:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:31:43,132:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 207, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:31:43,132:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:31:43,132:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 572, in root_mean_squared_error
    mean_squared_error(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 186, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:31:43,132:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 1180, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:31:43,178:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\ensemble\_bagging.py:218: RuntimeWarning: invalid value encountered in add
  return sum(

2024-02-28 22:31:43,185:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 680, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:31:43,186:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:31:43,186:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 207, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:31:43,186:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:31:43,186:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 572, in root_mean_squared_error
    mean_squared_error(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 186, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:31:43,186:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 1180, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:31:43,234:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 680, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:31:43,234:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:31:43,234:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 207, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:31:43,234:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:31:43,234:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 572, in root_mean_squared_error
    mean_squared_error(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 186, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:31:43,234:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 1180, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:31:43,287:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\ensemble\_bagging.py:218: RuntimeWarning: invalid value encountered in add
  return sum(

2024-02-28 22:31:43,291:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 680, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:31:43,292:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:31:43,292:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 207, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:31:43,292:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:31:43,292:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 572, in root_mean_squared_error
    mean_squared_error(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 186, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:31:43,292:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 1180, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:31:43,338:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\ensemble\_bagging.py:218: RuntimeWarning: invalid value encountered in add
  return sum(

2024-02-28 22:31:43,342:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 680, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:31:43,342:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:31:43,342:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 207, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:31:43,342:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:31:43,342:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 572, in root_mean_squared_error
    mean_squared_error(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 186, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:31:43,342:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 1180, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:31:43,392:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\ensemble\_bagging.py:218: RuntimeWarning: invalid value encountered in add
  return sum(

2024-02-28 22:31:43,393:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 680, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:31:43,393:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:31:43,393:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 207, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:31:43,393:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:31:43,393:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 572, in root_mean_squared_error
    mean_squared_error(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 186, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:31:43,393:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 1180, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:31:43,443:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\ensemble\_bagging.py:218: RuntimeWarning: invalid value encountered in add
  return sum(

2024-02-28 22:31:43,449:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 680, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:31:43,449:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:31:43,449:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 207, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:31:43,449:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:31:43,449:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 572, in root_mean_squared_error
    mean_squared_error(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 186, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:31:43,449:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 1180, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:31:43,493:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\ensemble\_bagging.py:218: RuntimeWarning: invalid value encountered in add
  return sum(

2024-02-28 22:31:43,493:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 680, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:31:43,493:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:31:43,493:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 207, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:31:43,493:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:31:43,493:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 572, in root_mean_squared_error
    mean_squared_error(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 186, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:31:43,493:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 1180, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:31:43,509:INFO:Calculating mean and std
2024-02-28 22:31:43,509:INFO:Creating metrics dataframe
2024-02-28 22:31:43,509:INFO:Finalizing model
2024-02-28 22:31:43,555:INFO:Uploading results into container
2024-02-28 22:31:43,555:INFO:Uploading model into container now
2024-02-28 22:31:43,555:INFO:_master_model_container: 5
2024-02-28 22:31:43,555:INFO:_display_container: 7
2024-02-28 22:31:43,555:INFO:BaggingRegressor(estimator=RandomForestRegressor(n_jobs=-1, random_state=123),
                 n_jobs=1, random_state=123)
2024-02-28 22:31:43,555:INFO:create_model() successfully completed......................................
2024-02-28 22:31:43,709:INFO:SubProcess create_model() end ==================================
2024-02-28 22:31:43,717:INFO:_master_model_container: 5
2024-02-28 22:31:43,717:INFO:_display_container: 7
2024-02-28 22:31:43,717:INFO:BaggingRegressor(estimator=RandomForestRegressor(n_jobs=-1, random_state=123),
                 n_jobs=1, random_state=123)
2024-02-28 22:31:43,717:INFO:ensemble_model() successfully completed......................................
2024-02-28 22:31:59,690:INFO:Initializing ensemble_model()
2024-02-28 22:31:59,690:INFO:ensemble_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571F1E50>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=False, optimize=R2, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2024-02-28 22:31:59,690:INFO:Checking exceptions
2024-02-28 22:31:59,704:INFO:Importing libraries
2024-02-28 22:31:59,705:INFO:Copying training dataset
2024-02-28 22:31:59,705:INFO:Checking base model
2024-02-28 22:31:59,705:INFO:Base model : Random Forest Regressor
2024-02-28 22:31:59,709:INFO:Importing untrained ensembler
2024-02-28 22:31:59,709:INFO:Ensemble method set to Bagging
2024-02-28 22:31:59,709:INFO:SubProcess create_model() called ==================================
2024-02-28 22:31:59,710:INFO:Initializing create_model()
2024-02-28 22:31:59,710:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571F1E50>, estimator=BaggingRegressor(estimator=RandomForestRegressor(n_jobs=-1, random_state=123),
                 n_jobs=1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016029EC0B80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:31:59,710:INFO:Checking exceptions
2024-02-28 22:31:59,710:INFO:Importing libraries
2024-02-28 22:31:59,710:INFO:Copying training dataset
2024-02-28 22:31:59,712:INFO:Defining folds
2024-02-28 22:31:59,712:INFO:Declaring metric variables
2024-02-28 22:31:59,715:INFO:Importing untrained model
2024-02-28 22:31:59,715:INFO:Declaring custom model
2024-02-28 22:31:59,719:INFO:Random Forest Regressor Imported successfully
2024-02-28 22:31:59,723:INFO:Starting cross validation
2024-02-28 22:31:59,724:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:31:59,774:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\ensemble\_bagging.py:218: RuntimeWarning: invalid value encountered in add
  return sum(

2024-02-28 22:31:59,779:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 680, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:31:59,779:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:31:59,779:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 207, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:31:59,779:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:31:59,779:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 572, in root_mean_squared_error
    mean_squared_error(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 186, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:31:59,779:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 1180, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:31:59,859:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\ensemble\_bagging.py:218: RuntimeWarning: invalid value encountered in add
  return sum(

2024-02-28 22:31:59,865:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 680, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:31:59,866:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:31:59,866:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 207, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:31:59,866:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:31:59,866:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 572, in root_mean_squared_error
    mean_squared_error(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 186, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:31:59,866:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 1180, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:31:59,921:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 680, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:31:59,921:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:31:59,921:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 207, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:31:59,921:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:31:59,922:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 572, in root_mean_squared_error
    mean_squared_error(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 186, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:31:59,922:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 1180, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:31:59,963:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\ensemble\_bagging.py:218: RuntimeWarning: invalid value encountered in add
  return sum(

2024-02-28 22:31:59,963:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 680, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:31:59,963:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:31:59,963:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 207, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:31:59,963:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:31:59,963:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 572, in root_mean_squared_error
    mean_squared_error(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 186, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:31:59,963:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 1180, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:32:00,025:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 680, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:32:00,025:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:32:00,025:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 207, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:32:00,025:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:32:00,025:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 572, in root_mean_squared_error
    mean_squared_error(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 186, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:32:00,025:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 1180, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:32:00,078:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\ensemble\_bagging.py:218: RuntimeWarning: invalid value encountered in add
  return sum(

2024-02-28 22:32:00,078:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 680, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:32:00,078:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:32:00,078:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 207, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:32:00,078:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:32:00,078:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 572, in root_mean_squared_error
    mean_squared_error(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 186, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:32:00,078:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 1180, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:32:00,125:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\ensemble\_bagging.py:218: RuntimeWarning: invalid value encountered in add
  return sum(

2024-02-28 22:32:00,125:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 680, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:32:00,125:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:32:00,125:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 207, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:32:00,125:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:32:00,125:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 572, in root_mean_squared_error
    mean_squared_error(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 186, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:32:00,125:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 1180, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:32:00,180:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\ensemble\_bagging.py:218: RuntimeWarning: invalid value encountered in add
  return sum(

2024-02-28 22:32:00,180:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 680, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:32:00,180:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:32:00,180:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 207, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:32:00,180:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:32:00,180:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 572, in root_mean_squared_error
    mean_squared_error(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 186, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:32:00,180:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 1180, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:32:00,225:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\ensemble\_bagging.py:218: RuntimeWarning: invalid value encountered in add
  return sum(

2024-02-28 22:32:00,240:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 680, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:32:00,240:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:32:00,240:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 207, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:32:00,240:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:32:00,240:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 572, in root_mean_squared_error
    mean_squared_error(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 186, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:32:00,240:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 1180, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:32:00,289:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\ensemble\_bagging.py:218: RuntimeWarning: invalid value encountered in add
  return sum(

2024-02-28 22:32:00,289:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 680, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:32:00,289:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:32:00,289:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 207, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:32:00,289:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:32:00,289:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 572, in root_mean_squared_error
    mean_squared_error(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 186, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:32:00,289:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 1180, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\daal4py\sklearn\utils\validation.py", line 57, in _assert_all_finite
    _sklearn_assert_all_finite(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-02-28 22:32:00,289:INFO:Calculating mean and std
2024-02-28 22:32:00,289:INFO:Creating metrics dataframe
2024-02-28 22:32:00,305:INFO:Finalizing model
2024-02-28 22:32:00,347:INFO:Uploading results into container
2024-02-28 22:32:00,347:INFO:Uploading model into container now
2024-02-28 22:32:00,347:INFO:_master_model_container: 6
2024-02-28 22:32:00,347:INFO:_display_container: 8
2024-02-28 22:32:00,347:INFO:BaggingRegressor(estimator=RandomForestRegressor(n_jobs=-1, random_state=123),
                 n_jobs=1, random_state=123)
2024-02-28 22:32:00,347:INFO:create_model() successfully completed......................................
2024-02-28 22:32:00,495:INFO:SubProcess create_model() end ==================================
2024-02-28 22:32:00,495:INFO:_master_model_container: 6
2024-02-28 22:32:00,495:INFO:_display_container: 8
2024-02-28 22:32:00,495:INFO:BaggingRegressor(estimator=RandomForestRegressor(n_jobs=-1, random_state=123),
                 n_jobs=1, random_state=123)
2024-02-28 22:32:00,495:INFO:ensemble_model() successfully completed......................................
2024-02-28 22:32:07,709:INFO:Initializing ensemble_model()
2024-02-28 22:32:07,709:INFO:ensemble_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571F1E50>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), method=Boosting, fold=None, n_estimators=10, round=4, choose_better=False, optimize=R2, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2024-02-28 22:32:07,709:INFO:Checking exceptions
2024-02-28 22:32:07,785:INFO:Importing libraries
2024-02-28 22:32:07,785:INFO:Copying training dataset
2024-02-28 22:32:07,785:INFO:Checking base model
2024-02-28 22:32:07,785:INFO:Base model : Random Forest Regressor
2024-02-28 22:32:07,790:INFO:Importing untrained ensembler
2024-02-28 22:32:07,790:INFO:Ensemble method set to Boosting
2024-02-28 22:32:07,790:INFO:SubProcess create_model() called ==================================
2024-02-28 22:32:07,791:INFO:Initializing create_model()
2024-02-28 22:32:07,791:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571F1E50>, estimator=AdaBoostRegressor(estimator=RandomForestRegressor(n_jobs=-1, random_state=123),
                  n_estimators=10, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016029F50C10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:32:07,791:INFO:Checking exceptions
2024-02-28 22:32:07,791:INFO:Importing libraries
2024-02-28 22:32:07,791:INFO:Copying training dataset
2024-02-28 22:32:07,794:INFO:Defining folds
2024-02-28 22:32:07,794:INFO:Declaring metric variables
2024-02-28 22:32:07,796:INFO:Importing untrained model
2024-02-28 22:32:07,796:INFO:Declaring custom model
2024-02-28 22:32:07,799:INFO:Random Forest Regressor Imported successfully
2024-02-28 22:32:07,804:INFO:Starting cross validation
2024-02-28 22:32:07,805:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:32:08,341:INFO:Calculating mean and std
2024-02-28 22:32:08,341:INFO:Creating metrics dataframe
2024-02-28 22:32:08,348:INFO:Finalizing model
2024-02-28 22:32:08,394:INFO:Uploading results into container
2024-02-28 22:32:08,396:INFO:Uploading model into container now
2024-02-28 22:32:08,396:INFO:_master_model_container: 7
2024-02-28 22:32:08,396:INFO:_display_container: 9
2024-02-28 22:32:08,397:INFO:AdaBoostRegressor(estimator=RandomForestRegressor(n_jobs=-1, random_state=123),
                  n_estimators=10, random_state=123)
2024-02-28 22:32:08,397:INFO:create_model() successfully completed......................................
2024-02-28 22:32:08,540:INFO:SubProcess create_model() end ==================================
2024-02-28 22:32:08,548:INFO:_master_model_container: 7
2024-02-28 22:32:08,548:INFO:_display_container: 9
2024-02-28 22:32:08,548:INFO:AdaBoostRegressor(estimator=RandomForestRegressor(n_jobs=-1, random_state=123),
                  n_estimators=10, random_state=123)
2024-02-28 22:32:08,548:INFO:ensemble_model() successfully completed......................................
2024-02-28 22:32:41,025:INFO:Initializing compare_models()
2024-02-28 22:32:41,025:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571F1E50>, include=None, fold=None, round=4, cross_validation=True, sort=MAE, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000160571F1E50>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'MAE', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-02-28 22:32:41,025:INFO:Checking exceptions
2024-02-28 22:32:41,025:INFO:Preparing display monitor
2024-02-28 22:32:41,043:INFO:Initializing Linear Regression
2024-02-28 22:32:41,043:INFO:Total runtime is 0.0 minutes
2024-02-28 22:32:41,045:INFO:SubProcess create_model() called ==================================
2024-02-28 22:32:41,045:INFO:Initializing create_model()
2024-02-28 22:32:41,045:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571F1E50>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000160670ED970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:32:41,045:INFO:Checking exceptions
2024-02-28 22:32:41,045:INFO:Importing libraries
2024-02-28 22:32:41,045:INFO:Copying training dataset
2024-02-28 22:32:41,047:INFO:Defining folds
2024-02-28 22:32:41,048:INFO:Declaring metric variables
2024-02-28 22:32:41,050:INFO:Importing untrained model
2024-02-28 22:32:41,052:INFO:Linear Regression Imported successfully
2024-02-28 22:32:41,056:INFO:Starting cross validation
2024-02-28 22:32:41,057:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:32:41,152:INFO:Calculating mean and std
2024-02-28 22:32:41,153:INFO:Creating metrics dataframe
2024-02-28 22:32:41,154:INFO:Uploading results into container
2024-02-28 22:32:41,155:INFO:Uploading model into container now
2024-02-28 22:32:41,155:INFO:_master_model_container: 8
2024-02-28 22:32:41,155:INFO:_display_container: 10
2024-02-28 22:32:41,155:INFO:LinearRegression(n_jobs=-1)
2024-02-28 22:32:41,155:INFO:create_model() successfully completed......................................
2024-02-28 22:32:41,287:INFO:SubProcess create_model() end ==================================
2024-02-28 22:32:41,294:INFO:Creating metrics dataframe
2024-02-28 22:32:41,299:INFO:Initializing Lasso Regression
2024-02-28 22:32:41,299:INFO:Total runtime is 0.004269099235534668 minutes
2024-02-28 22:32:41,302:INFO:SubProcess create_model() called ==================================
2024-02-28 22:32:41,302:INFO:Initializing create_model()
2024-02-28 22:32:41,302:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571F1E50>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000160670ED970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:32:41,302:INFO:Checking exceptions
2024-02-28 22:32:41,302:INFO:Importing libraries
2024-02-28 22:32:41,302:INFO:Copying training dataset
2024-02-28 22:32:41,304:INFO:Defining folds
2024-02-28 22:32:41,304:INFO:Declaring metric variables
2024-02-28 22:32:41,306:INFO:Importing untrained model
2024-02-28 22:32:41,309:INFO:Lasso Regression Imported successfully
2024-02-28 22:32:41,309:INFO:Starting cross validation
2024-02-28 22:32:41,309:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:32:41,406:INFO:Calculating mean and std
2024-02-28 22:32:41,406:INFO:Creating metrics dataframe
2024-02-28 22:32:41,408:INFO:Uploading results into container
2024-02-28 22:32:41,409:INFO:Uploading model into container now
2024-02-28 22:32:41,409:INFO:_master_model_container: 9
2024-02-28 22:32:41,409:INFO:_display_container: 10
2024-02-28 22:32:41,409:INFO:Lasso(random_state=123)
2024-02-28 22:32:41,409:INFO:create_model() successfully completed......................................
2024-02-28 22:32:41,550:INFO:SubProcess create_model() end ==================================
2024-02-28 22:32:41,550:INFO:Creating metrics dataframe
2024-02-28 22:32:41,558:INFO:Initializing Ridge Regression
2024-02-28 22:32:41,558:INFO:Total runtime is 0.0085793137550354 minutes
2024-02-28 22:32:41,560:INFO:SubProcess create_model() called ==================================
2024-02-28 22:32:41,560:INFO:Initializing create_model()
2024-02-28 22:32:41,560:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571F1E50>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000160670ED970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:32:41,560:INFO:Checking exceptions
2024-02-28 22:32:41,560:INFO:Importing libraries
2024-02-28 22:32:41,560:INFO:Copying training dataset
2024-02-28 22:32:41,563:INFO:Defining folds
2024-02-28 22:32:41,563:INFO:Declaring metric variables
2024-02-28 22:32:41,564:INFO:Importing untrained model
2024-02-28 22:32:41,567:INFO:Ridge Regression Imported successfully
2024-02-28 22:32:41,571:INFO:Starting cross validation
2024-02-28 22:32:41,571:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:32:41,656:INFO:Calculating mean and std
2024-02-28 22:32:41,656:INFO:Creating metrics dataframe
2024-02-28 22:32:41,663:INFO:Uploading results into container
2024-02-28 22:32:41,664:INFO:Uploading model into container now
2024-02-28 22:32:41,664:INFO:_master_model_container: 10
2024-02-28 22:32:41,664:INFO:_display_container: 10
2024-02-28 22:32:41,664:INFO:Ridge(random_state=123)
2024-02-28 22:32:41,664:INFO:create_model() successfully completed......................................
2024-02-28 22:32:41,802:INFO:SubProcess create_model() end ==================================
2024-02-28 22:32:41,802:INFO:Creating metrics dataframe
2024-02-28 22:32:41,810:INFO:Initializing Elastic Net
2024-02-28 22:32:41,810:INFO:Total runtime is 0.012779307365417481 minutes
2024-02-28 22:32:41,810:INFO:SubProcess create_model() called ==================================
2024-02-28 22:32:41,810:INFO:Initializing create_model()
2024-02-28 22:32:41,810:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571F1E50>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000160670ED970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:32:41,810:INFO:Checking exceptions
2024-02-28 22:32:41,810:INFO:Importing libraries
2024-02-28 22:32:41,810:INFO:Copying training dataset
2024-02-28 22:32:41,810:INFO:Defining folds
2024-02-28 22:32:41,810:INFO:Declaring metric variables
2024-02-28 22:32:41,817:INFO:Importing untrained model
2024-02-28 22:32:41,817:INFO:Elastic Net Imported successfully
2024-02-28 22:32:41,825:INFO:Starting cross validation
2024-02-28 22:32:41,825:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:32:41,918:INFO:Calculating mean and std
2024-02-28 22:32:41,918:INFO:Creating metrics dataframe
2024-02-28 22:32:41,925:INFO:Uploading results into container
2024-02-28 22:32:41,925:INFO:Uploading model into container now
2024-02-28 22:32:41,925:INFO:_master_model_container: 11
2024-02-28 22:32:41,925:INFO:_display_container: 10
2024-02-28 22:32:41,925:INFO:ElasticNet(random_state=123)
2024-02-28 22:32:41,925:INFO:create_model() successfully completed......................................
2024-02-28 22:32:42,064:INFO:SubProcess create_model() end ==================================
2024-02-28 22:32:42,064:INFO:Creating metrics dataframe
2024-02-28 22:32:42,073:INFO:Initializing Least Angle Regression
2024-02-28 22:32:42,073:INFO:Total runtime is 0.01716726620992025 minutes
2024-02-28 22:32:42,073:INFO:SubProcess create_model() called ==================================
2024-02-28 22:32:42,073:INFO:Initializing create_model()
2024-02-28 22:32:42,073:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571F1E50>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000160670ED970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:32:42,073:INFO:Checking exceptions
2024-02-28 22:32:42,073:INFO:Importing libraries
2024-02-28 22:32:42,073:INFO:Copying training dataset
2024-02-28 22:32:42,079:INFO:Defining folds
2024-02-28 22:32:42,079:INFO:Declaring metric variables
2024-02-28 22:32:42,079:INFO:Importing untrained model
2024-02-28 22:32:42,084:INFO:Least Angle Regression Imported successfully
2024-02-28 22:32:42,089:INFO:Starting cross validation
2024-02-28 22:32:42,089:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:32:42,179:INFO:Calculating mean and std
2024-02-28 22:32:42,179:INFO:Creating metrics dataframe
2024-02-28 22:32:42,179:INFO:Uploading results into container
2024-02-28 22:32:42,179:INFO:Uploading model into container now
2024-02-28 22:32:42,179:INFO:_master_model_container: 12
2024-02-28 22:32:42,179:INFO:_display_container: 10
2024-02-28 22:32:42,179:INFO:Lars(random_state=123)
2024-02-28 22:32:42,179:INFO:create_model() successfully completed......................................
2024-02-28 22:32:42,327:INFO:SubProcess create_model() end ==================================
2024-02-28 22:32:42,327:INFO:Creating metrics dataframe
2024-02-28 22:32:42,333:INFO:Initializing Lasso Least Angle Regression
2024-02-28 22:32:42,333:INFO:Total runtime is 0.021498735745747885 minutes
2024-02-28 22:32:42,336:INFO:SubProcess create_model() called ==================================
2024-02-28 22:32:42,336:INFO:Initializing create_model()
2024-02-28 22:32:42,336:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571F1E50>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000160670ED970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:32:42,337:INFO:Checking exceptions
2024-02-28 22:32:42,337:INFO:Importing libraries
2024-02-28 22:32:42,337:INFO:Copying training dataset
2024-02-28 22:32:42,339:INFO:Defining folds
2024-02-28 22:32:42,340:INFO:Declaring metric variables
2024-02-28 22:32:42,342:INFO:Importing untrained model
2024-02-28 22:32:42,345:INFO:Lasso Least Angle Regression Imported successfully
2024-02-28 22:32:42,350:INFO:Starting cross validation
2024-02-28 22:32:42,350:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:32:42,440:INFO:Calculating mean and std
2024-02-28 22:32:42,441:INFO:Creating metrics dataframe
2024-02-28 22:32:42,441:INFO:Uploading results into container
2024-02-28 22:32:42,441:INFO:Uploading model into container now
2024-02-28 22:32:42,441:INFO:_master_model_container: 13
2024-02-28 22:32:42,441:INFO:_display_container: 10
2024-02-28 22:32:42,441:INFO:LassoLars(random_state=123)
2024-02-28 22:32:42,441:INFO:create_model() successfully completed......................................
2024-02-28 22:32:42,579:INFO:SubProcess create_model() end ==================================
2024-02-28 22:32:42,579:INFO:Creating metrics dataframe
2024-02-28 22:32:42,590:INFO:Initializing Orthogonal Matching Pursuit
2024-02-28 22:32:42,590:INFO:Total runtime is 0.025781853993733724 minutes
2024-02-28 22:32:42,595:INFO:SubProcess create_model() called ==================================
2024-02-28 22:32:42,595:INFO:Initializing create_model()
2024-02-28 22:32:42,595:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571F1E50>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000160670ED970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:32:42,595:INFO:Checking exceptions
2024-02-28 22:32:42,595:INFO:Importing libraries
2024-02-28 22:32:42,595:INFO:Copying training dataset
2024-02-28 22:32:42,598:INFO:Defining folds
2024-02-28 22:32:42,598:INFO:Declaring metric variables
2024-02-28 22:32:42,600:INFO:Importing untrained model
2024-02-28 22:32:42,603:INFO:Orthogonal Matching Pursuit Imported successfully
2024-02-28 22:32:42,603:INFO:Starting cross validation
2024-02-28 22:32:42,603:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:32:42,696:INFO:Calculating mean and std
2024-02-28 22:32:42,696:INFO:Creating metrics dataframe
2024-02-28 22:32:42,696:INFO:Uploading results into container
2024-02-28 22:32:42,696:INFO:Uploading model into container now
2024-02-28 22:32:42,696:INFO:_master_model_container: 14
2024-02-28 22:32:42,696:INFO:_display_container: 10
2024-02-28 22:32:42,696:INFO:OrthogonalMatchingPursuit()
2024-02-28 22:32:42,696:INFO:create_model() successfully completed......................................
2024-02-28 22:32:42,843:INFO:SubProcess create_model() end ==================================
2024-02-28 22:32:42,843:INFO:Creating metrics dataframe
2024-02-28 22:32:42,855:INFO:Initializing Bayesian Ridge
2024-02-28 22:32:42,855:INFO:Total runtime is 0.03020212650299072 minutes
2024-02-28 22:32:42,856:INFO:SubProcess create_model() called ==================================
2024-02-28 22:32:42,856:INFO:Initializing create_model()
2024-02-28 22:32:42,856:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571F1E50>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000160670ED970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:32:42,856:INFO:Checking exceptions
2024-02-28 22:32:42,856:INFO:Importing libraries
2024-02-28 22:32:42,856:INFO:Copying training dataset
2024-02-28 22:32:42,856:INFO:Defining folds
2024-02-28 22:32:42,856:INFO:Declaring metric variables
2024-02-28 22:32:42,863:INFO:Importing untrained model
2024-02-28 22:32:42,865:INFO:Bayesian Ridge Imported successfully
2024-02-28 22:32:42,867:INFO:Starting cross validation
2024-02-28 22:32:42,871:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:32:42,964:INFO:Calculating mean and std
2024-02-28 22:32:42,964:INFO:Creating metrics dataframe
2024-02-28 22:32:42,964:INFO:Uploading results into container
2024-02-28 22:32:42,964:INFO:Uploading model into container now
2024-02-28 22:32:42,964:INFO:_master_model_container: 15
2024-02-28 22:32:42,964:INFO:_display_container: 10
2024-02-28 22:32:42,964:INFO:BayesianRidge()
2024-02-28 22:32:42,964:INFO:create_model() successfully completed......................................
2024-02-28 22:32:43,117:INFO:SubProcess create_model() end ==================================
2024-02-28 22:32:43,117:INFO:Creating metrics dataframe
2024-02-28 22:32:43,125:INFO:Initializing Passive Aggressive Regressor
2024-02-28 22:32:43,125:INFO:Total runtime is 0.0346967339515686 minutes
2024-02-28 22:32:43,127:INFO:SubProcess create_model() called ==================================
2024-02-28 22:32:43,127:INFO:Initializing create_model()
2024-02-28 22:32:43,127:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571F1E50>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000160670ED970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:32:43,127:INFO:Checking exceptions
2024-02-28 22:32:43,127:INFO:Importing libraries
2024-02-28 22:32:43,127:INFO:Copying training dataset
2024-02-28 22:32:43,130:INFO:Defining folds
2024-02-28 22:32:43,130:INFO:Declaring metric variables
2024-02-28 22:32:43,134:INFO:Importing untrained model
2024-02-28 22:32:43,136:INFO:Passive Aggressive Regressor Imported successfully
2024-02-28 22:32:43,141:INFO:Starting cross validation
2024-02-28 22:32:43,142:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:32:43,233:INFO:Calculating mean and std
2024-02-28 22:32:43,233:INFO:Creating metrics dataframe
2024-02-28 22:32:43,233:INFO:Uploading results into container
2024-02-28 22:32:43,233:INFO:Uploading model into container now
2024-02-28 22:32:43,233:INFO:_master_model_container: 16
2024-02-28 22:32:43,233:INFO:_display_container: 10
2024-02-28 22:32:43,233:INFO:PassiveAggressiveRegressor(random_state=123)
2024-02-28 22:32:43,233:INFO:create_model() successfully completed......................................
2024-02-28 22:32:43,379:INFO:SubProcess create_model() end ==================================
2024-02-28 22:32:43,379:INFO:Creating metrics dataframe
2024-02-28 22:32:43,389:INFO:Initializing Huber Regressor
2024-02-28 22:32:43,389:INFO:Total runtime is 0.039100209871927895 minutes
2024-02-28 22:32:43,394:INFO:SubProcess create_model() called ==================================
2024-02-28 22:32:43,394:INFO:Initializing create_model()
2024-02-28 22:32:43,394:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571F1E50>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000160670ED970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:32:43,394:INFO:Checking exceptions
2024-02-28 22:32:43,394:INFO:Importing libraries
2024-02-28 22:32:43,394:INFO:Copying training dataset
2024-02-28 22:32:43,397:INFO:Defining folds
2024-02-28 22:32:43,397:INFO:Declaring metric variables
2024-02-28 22:32:43,399:INFO:Importing untrained model
2024-02-28 22:32:43,402:INFO:Huber Regressor Imported successfully
2024-02-28 22:32:43,404:INFO:Starting cross validation
2024-02-28 22:32:43,404:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:32:43,428:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-02-28 22:32:43,448:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-02-28 22:32:43,487:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-02-28 22:32:43,510:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-02-28 22:32:43,533:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-02-28 22:32:43,571:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-02-28 22:32:43,594:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-02-28 22:32:43,610:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-02-28 22:32:43,617:INFO:Calculating mean and std
2024-02-28 22:32:43,617:INFO:Creating metrics dataframe
2024-02-28 22:32:43,617:INFO:Uploading results into container
2024-02-28 22:32:43,617:INFO:Uploading model into container now
2024-02-28 22:32:43,617:INFO:_master_model_container: 17
2024-02-28 22:32:43,617:INFO:_display_container: 10
2024-02-28 22:32:43,617:INFO:HuberRegressor()
2024-02-28 22:32:43,617:INFO:create_model() successfully completed......................................
2024-02-28 22:32:43,764:INFO:SubProcess create_model() end ==================================
2024-02-28 22:32:43,764:INFO:Creating metrics dataframe
2024-02-28 22:32:43,771:INFO:Initializing K Neighbors Regressor
2024-02-28 22:32:43,771:INFO:Total runtime is 0.04547004699707031 minutes
2024-02-28 22:32:43,779:INFO:SubProcess create_model() called ==================================
2024-02-28 22:32:43,779:INFO:Initializing create_model()
2024-02-28 22:32:43,779:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571F1E50>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000160670ED970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:32:43,779:INFO:Checking exceptions
2024-02-28 22:32:43,779:INFO:Importing libraries
2024-02-28 22:32:43,779:INFO:Copying training dataset
2024-02-28 22:32:43,779:INFO:Defining folds
2024-02-28 22:32:43,779:INFO:Declaring metric variables
2024-02-28 22:32:43,784:INFO:Importing untrained model
2024-02-28 22:32:43,787:INFO:K Neighbors Regressor Imported successfully
2024-02-28 22:32:43,788:INFO:Starting cross validation
2024-02-28 22:32:43,788:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:32:43,887:INFO:Calculating mean and std
2024-02-28 22:32:43,887:INFO:Creating metrics dataframe
2024-02-28 22:32:43,887:INFO:Uploading results into container
2024-02-28 22:32:43,887:INFO:Uploading model into container now
2024-02-28 22:32:43,887:INFO:_master_model_container: 18
2024-02-28 22:32:43,887:INFO:_display_container: 10
2024-02-28 22:32:43,887:INFO:KNeighborsRegressor(n_jobs=-1)
2024-02-28 22:32:43,887:INFO:create_model() successfully completed......................................
2024-02-28 22:32:44,025:INFO:SubProcess create_model() end ==================================
2024-02-28 22:32:44,033:INFO:Creating metrics dataframe
2024-02-28 22:32:44,041:INFO:Initializing Decision Tree Regressor
2024-02-28 22:32:44,041:INFO:Total runtime is 0.04996825853983561 minutes
2024-02-28 22:32:44,043:INFO:SubProcess create_model() called ==================================
2024-02-28 22:32:44,043:INFO:Initializing create_model()
2024-02-28 22:32:44,043:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571F1E50>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000160670ED970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:32:44,043:INFO:Checking exceptions
2024-02-28 22:32:44,043:INFO:Importing libraries
2024-02-28 22:32:44,043:INFO:Copying training dataset
2024-02-28 22:32:44,043:INFO:Defining folds
2024-02-28 22:32:44,043:INFO:Declaring metric variables
2024-02-28 22:32:44,050:INFO:Importing untrained model
2024-02-28 22:32:44,051:INFO:Decision Tree Regressor Imported successfully
2024-02-28 22:32:44,057:INFO:Starting cross validation
2024-02-28 22:32:44,058:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:32:44,148:INFO:Calculating mean and std
2024-02-28 22:32:44,156:INFO:Creating metrics dataframe
2024-02-28 22:32:44,158:INFO:Uploading results into container
2024-02-28 22:32:44,159:INFO:Uploading model into container now
2024-02-28 22:32:44,159:INFO:_master_model_container: 19
2024-02-28 22:32:44,159:INFO:_display_container: 10
2024-02-28 22:32:44,159:INFO:DecisionTreeRegressor(random_state=123)
2024-02-28 22:32:44,159:INFO:create_model() successfully completed......................................
2024-02-28 22:32:44,302:INFO:SubProcess create_model() end ==================================
2024-02-28 22:32:44,302:INFO:Creating metrics dataframe
2024-02-28 22:32:44,310:INFO:Initializing Random Forest Regressor
2024-02-28 22:32:44,310:INFO:Total runtime is 0.05444482564926147 minutes
2024-02-28 22:32:44,310:INFO:SubProcess create_model() called ==================================
2024-02-28 22:32:44,310:INFO:Initializing create_model()
2024-02-28 22:32:44,310:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571F1E50>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000160670ED970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:32:44,310:INFO:Checking exceptions
2024-02-28 22:32:44,310:INFO:Importing libraries
2024-02-28 22:32:44,310:INFO:Copying training dataset
2024-02-28 22:32:44,317:INFO:Defining folds
2024-02-28 22:32:44,318:INFO:Declaring metric variables
2024-02-28 22:32:44,320:INFO:Importing untrained model
2024-02-28 22:32:44,322:INFO:Random Forest Regressor Imported successfully
2024-02-28 22:32:44,327:INFO:Starting cross validation
2024-02-28 22:32:44,327:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:32:44,342:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:32:44,356:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:32:44,369:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:32:44,379:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:32:44,395:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:32:44,402:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:32:44,417:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:32:44,433:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:32:44,441:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:32:44,458:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:32:44,458:INFO:Calculating mean and std
2024-02-28 22:32:44,458:INFO:Creating metrics dataframe
2024-02-28 22:32:44,464:INFO:Uploading results into container
2024-02-28 22:32:44,464:INFO:Uploading model into container now
2024-02-28 22:32:44,464:INFO:_master_model_container: 20
2024-02-28 22:32:44,464:INFO:_display_container: 10
2024-02-28 22:32:44,464:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-02-28 22:32:44,464:INFO:create_model() successfully completed......................................
2024-02-28 22:32:44,602:INFO:SubProcess create_model() end ==================================
2024-02-28 22:32:44,602:INFO:Creating metrics dataframe
2024-02-28 22:32:44,619:INFO:Initializing Extra Trees Regressor
2024-02-28 22:32:44,619:INFO:Total runtime is 0.05959533055623372 minutes
2024-02-28 22:32:44,621:INFO:SubProcess create_model() called ==================================
2024-02-28 22:32:44,621:INFO:Initializing create_model()
2024-02-28 22:32:44,621:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571F1E50>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000160670ED970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:32:44,621:INFO:Checking exceptions
2024-02-28 22:32:44,621:INFO:Importing libraries
2024-02-28 22:32:44,621:INFO:Copying training dataset
2024-02-28 22:32:44,624:INFO:Defining folds
2024-02-28 22:32:44,624:INFO:Declaring metric variables
2024-02-28 22:32:44,625:INFO:Importing untrained model
2024-02-28 22:32:44,625:INFO:Extra Trees Regressor Imported successfully
2024-02-28 22:32:44,634:INFO:Starting cross validation
2024-02-28 22:32:44,635:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:32:44,649:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:32:44,665:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:32:44,680:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:32:44,695:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:32:44,708:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:32:44,723:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:32:44,735:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:32:44,752:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:32:44,766:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:32:44,779:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:32:44,779:INFO:Calculating mean and std
2024-02-28 22:32:44,779:INFO:Creating metrics dataframe
2024-02-28 22:32:44,779:INFO:Uploading results into container
2024-02-28 22:32:44,787:INFO:Uploading model into container now
2024-02-28 22:32:44,787:INFO:_master_model_container: 21
2024-02-28 22:32:44,787:INFO:_display_container: 10
2024-02-28 22:32:44,787:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-02-28 22:32:44,787:INFO:create_model() successfully completed......................................
2024-02-28 22:32:44,933:INFO:SubProcess create_model() end ==================================
2024-02-28 22:32:44,933:INFO:Creating metrics dataframe
2024-02-28 22:32:44,942:INFO:Initializing AdaBoost Regressor
2024-02-28 22:32:44,942:INFO:Total runtime is 0.06497820218404134 minutes
2024-02-28 22:32:44,945:INFO:SubProcess create_model() called ==================================
2024-02-28 22:32:44,945:INFO:Initializing create_model()
2024-02-28 22:32:44,945:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571F1E50>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000160670ED970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:32:44,945:INFO:Checking exceptions
2024-02-28 22:32:44,945:INFO:Importing libraries
2024-02-28 22:32:44,945:INFO:Copying training dataset
2024-02-28 22:32:44,946:INFO:Defining folds
2024-02-28 22:32:44,946:INFO:Declaring metric variables
2024-02-28 22:32:44,950:INFO:Importing untrained model
2024-02-28 22:32:44,952:INFO:AdaBoost Regressor Imported successfully
2024-02-28 22:32:44,957:INFO:Starting cross validation
2024-02-28 22:32:44,959:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:32:45,487:INFO:Calculating mean and std
2024-02-28 22:32:45,487:INFO:Creating metrics dataframe
2024-02-28 22:32:45,495:INFO:Uploading results into container
2024-02-28 22:32:45,495:INFO:Uploading model into container now
2024-02-28 22:32:45,495:INFO:_master_model_container: 22
2024-02-28 22:32:45,495:INFO:_display_container: 10
2024-02-28 22:32:45,495:INFO:AdaBoostRegressor(random_state=123)
2024-02-28 22:32:45,495:INFO:create_model() successfully completed......................................
2024-02-28 22:32:45,641:INFO:SubProcess create_model() end ==================================
2024-02-28 22:32:45,642:INFO:Creating metrics dataframe
2024-02-28 22:32:45,650:INFO:Initializing Gradient Boosting Regressor
2024-02-28 22:32:45,650:INFO:Total runtime is 0.07678354183832804 minutes
2024-02-28 22:32:45,652:INFO:SubProcess create_model() called ==================================
2024-02-28 22:32:45,653:INFO:Initializing create_model()
2024-02-28 22:32:45,653:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571F1E50>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000160670ED970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:32:45,653:INFO:Checking exceptions
2024-02-28 22:32:45,653:INFO:Importing libraries
2024-02-28 22:32:45,653:INFO:Copying training dataset
2024-02-28 22:32:45,656:INFO:Defining folds
2024-02-28 22:32:45,656:INFO:Declaring metric variables
2024-02-28 22:32:45,658:INFO:Importing untrained model
2024-02-28 22:32:45,659:INFO:Gradient Boosting Regressor Imported successfully
2024-02-28 22:32:45,665:INFO:Starting cross validation
2024-02-28 22:32:45,665:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:32:46,177:INFO:Calculating mean and std
2024-02-28 22:32:46,178:INFO:Creating metrics dataframe
2024-02-28 22:32:46,180:INFO:Uploading results into container
2024-02-28 22:32:46,180:INFO:Uploading model into container now
2024-02-28 22:32:46,181:INFO:_master_model_container: 23
2024-02-28 22:32:46,181:INFO:_display_container: 10
2024-02-28 22:32:46,181:INFO:GradientBoostingRegressor(random_state=123)
2024-02-28 22:32:46,181:INFO:create_model() successfully completed......................................
2024-02-28 22:32:46,325:INFO:SubProcess create_model() end ==================================
2024-02-28 22:32:46,325:INFO:Creating metrics dataframe
2024-02-28 22:32:46,325:INFO:Initializing Extreme Gradient Boosting
2024-02-28 22:32:46,325:INFO:Total runtime is 0.0880350947380066 minutes
2024-02-28 22:32:46,325:INFO:SubProcess create_model() called ==================================
2024-02-28 22:32:46,325:INFO:Initializing create_model()
2024-02-28 22:32:46,325:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571F1E50>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000160670ED970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:32:46,325:INFO:Checking exceptions
2024-02-28 22:32:46,325:INFO:Importing libraries
2024-02-28 22:32:46,325:INFO:Copying training dataset
2024-02-28 22:32:46,342:INFO:Defining folds
2024-02-28 22:32:46,342:INFO:Declaring metric variables
2024-02-28 22:32:46,344:INFO:Importing untrained model
2024-02-28 22:32:46,347:INFO:Extreme Gradient Boosting Imported successfully
2024-02-28 22:32:46,352:INFO:Starting cross validation
2024-02-28 22:32:46,353:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:32:48,634:INFO:Calculating mean and std
2024-02-28 22:32:48,634:INFO:Creating metrics dataframe
2024-02-28 22:32:48,643:INFO:Uploading results into container
2024-02-28 22:32:48,644:INFO:Uploading model into container now
2024-02-28 22:32:48,644:INFO:_master_model_container: 24
2024-02-28 22:32:48,644:INFO:_display_container: 10
2024-02-28 22:32:48,645:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='gpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=123, ...)
2024-02-28 22:32:48,645:INFO:create_model() successfully completed......................................
2024-02-28 22:32:48,810:INFO:SubProcess create_model() end ==================================
2024-02-28 22:32:48,810:INFO:Creating metrics dataframe
2024-02-28 22:32:48,817:INFO:Initializing Light Gradient Boosting Machine
2024-02-28 22:32:48,817:INFO:Total runtime is 0.12957155307133994 minutes
2024-02-28 22:32:48,827:INFO:SubProcess create_model() called ==================================
2024-02-28 22:32:48,827:INFO:Initializing create_model()
2024-02-28 22:32:48,827:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571F1E50>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000160670ED970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:32:48,827:INFO:Checking exceptions
2024-02-28 22:32:48,827:INFO:Importing libraries
2024-02-28 22:32:48,827:INFO:Copying training dataset
2024-02-28 22:32:48,827:INFO:Defining folds
2024-02-28 22:32:48,827:INFO:Declaring metric variables
2024-02-28 22:32:48,832:INFO:Importing untrained model
2024-02-28 22:32:48,835:INFO:Light Gradient Boosting Machine Imported successfully
2024-02-28 22:32:48,835:INFO:Starting cross validation
2024-02-28 22:32:48,840:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:32:48,844:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-02-28 22:32:48,844:INFO:[LightGBM] [Info] Total Bins 217
2024-02-28 22:32:48,844:INFO:[LightGBM] [Info] Number of data points in the train set: 246, number of used features: 5
2024-02-28 22:32:48,908:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-02-28 22:32:48,908:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-02-28 22:32:48,915:INFO:[LightGBM] [Info] GPU programs have been built
2024-02-28 22:32:48,916:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-02-28 22:32:48,917:INFO:[LightGBM] [Info] 5 dense feature groups (0.00 MB) transferred to GPU in 0.000374 secs. 0 sparse feature groups
2024-02-28 22:32:48,917:INFO:[LightGBM] [Info] Start training from score 23.452033
2024-02-28 22:32:48,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:48,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:48,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:48,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:48,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:48,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:48,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:48,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:48,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:48,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:48,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:48,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:48,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:48,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:48,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:48,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:48,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:48,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:48,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:48,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:48,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:48,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:48,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:48,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:48,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:48,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:48,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:48,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:48,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:48,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:48,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:48,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:48,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:48,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:48,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:48,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:48,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:48,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:48,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:48,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:48,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:48,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:48,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:48,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:48,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:48,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:48,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:48,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:48,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:48,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:48,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:48,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:48,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:48,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:48,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:48,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:48,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:48,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:48,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:48,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:48,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:48,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:48,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:48,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:48,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:48,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:48,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:48,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:48,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:48,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,073:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-02-28 22:32:49,073:INFO:[LightGBM] [Info] Total Bins 220
2024-02-28 22:32:49,073:INFO:[LightGBM] [Info] Number of data points in the train set: 246, number of used features: 5
2024-02-28 22:32:49,125:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-02-28 22:32:49,125:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-02-28 22:32:49,125:INFO:[LightGBM] [Info] GPU programs have been built
2024-02-28 22:32:49,125:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-02-28 22:32:49,125:INFO:[LightGBM] [Info] 5 dense feature groups (0.00 MB) transferred to GPU in 0.000326 secs. 0 sparse feature groups
2024-02-28 22:32:49,125:INFO:[LightGBM] [Info] Start training from score 23.622358
2024-02-28 22:32:49,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,295:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-02-28 22:32:49,296:INFO:[LightGBM] [Info] Total Bins 214
2024-02-28 22:32:49,296:INFO:[LightGBM] [Info] Number of data points in the train set: 246, number of used features: 5
2024-02-28 22:32:49,348:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-02-28 22:32:49,348:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-02-28 22:32:49,357:INFO:[LightGBM] [Info] GPU programs have been built
2024-02-28 22:32:49,357:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-02-28 22:32:49,357:INFO:[LightGBM] [Info] 5 dense feature groups (0.00 MB) transferred to GPU in 0.000372 secs. 0 sparse feature groups
2024-02-28 22:32:49,357:INFO:[LightGBM] [Info] Start training from score 23.693902
2024-02-28 22:32:49,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,509:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-02-28 22:32:49,509:INFO:[LightGBM] [Info] Total Bins 218
2024-02-28 22:32:49,509:INFO:[LightGBM] [Info] Number of data points in the train set: 246, number of used features: 5
2024-02-28 22:32:49,565:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-02-28 22:32:49,565:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-02-28 22:32:49,581:INFO:[LightGBM] [Info] GPU programs have been built
2024-02-28 22:32:49,581:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-02-28 22:32:49,581:INFO:[LightGBM] [Info] 5 dense feature groups (0.00 MB) transferred to GPU in 0.000348 secs. 0 sparse feature groups
2024-02-28 22:32:49,581:INFO:[LightGBM] [Info] Start training from score 23.815041
2024-02-28 22:32:49,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,734:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-02-28 22:32:49,734:INFO:[LightGBM] [Info] Total Bins 218
2024-02-28 22:32:49,734:INFO:[LightGBM] [Info] Number of data points in the train set: 247, number of used features: 5
2024-02-28 22:32:49,789:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-02-28 22:32:49,789:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-02-28 22:32:49,789:INFO:[LightGBM] [Info] GPU programs have been built
2024-02-28 22:32:49,789:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-02-28 22:32:49,789:INFO:[LightGBM] [Info] 5 dense feature groups (0.00 MB) transferred to GPU in 0.000387 secs. 0 sparse feature groups
2024-02-28 22:32:49,789:INFO:[LightGBM] [Info] Start training from score 23.681781
2024-02-28 22:32:49,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:49,953:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-02-28 22:32:49,953:INFO:[LightGBM] [Info] Total Bins 219
2024-02-28 22:32:49,953:INFO:[LightGBM] [Info] Number of data points in the train set: 247, number of used features: 5
2024-02-28 22:32:50,019:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-02-28 22:32:50,019:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-02-28 22:32:50,025:INFO:[LightGBM] [Info] GPU programs have been built
2024-02-28 22:32:50,025:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-02-28 22:32:50,025:INFO:[LightGBM] [Info] 5 dense feature groups (0.00 MB) transferred to GPU in 0.000382 secs. 0 sparse feature groups
2024-02-28 22:32:50,025:INFO:[LightGBM] [Info] Start training from score 23.918623
2024-02-28 22:32:50,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,180:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-02-28 22:32:50,180:INFO:[LightGBM] [Info] Total Bins 214
2024-02-28 22:32:50,180:INFO:[LightGBM] [Info] Number of data points in the train set: 247, number of used features: 5
2024-02-28 22:32:50,234:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-02-28 22:32:50,234:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-02-28 22:32:50,234:INFO:[LightGBM] [Info] GPU programs have been built
2024-02-28 22:32:50,234:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-02-28 22:32:50,234:INFO:[LightGBM] [Info] 5 dense feature groups (0.00 MB) transferred to GPU in 0.000364 secs. 0 sparse feature groups
2024-02-28 22:32:50,234:INFO:[LightGBM] [Info] Start training from score 23.956275
2024-02-28 22:32:50,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,404:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-02-28 22:32:50,404:INFO:[LightGBM] [Info] Total Bins 215
2024-02-28 22:32:50,404:INFO:[LightGBM] [Info] Number of data points in the train set: 247, number of used features: 5
2024-02-28 22:32:50,458:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-02-28 22:32:50,458:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-02-28 22:32:50,458:INFO:[LightGBM] [Info] GPU programs have been built
2024-02-28 22:32:50,458:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-02-28 22:32:50,458:INFO:[LightGBM] [Info] 5 dense feature groups (0.00 MB) transferred to GPU in 0.000365 secs. 0 sparse feature groups
2024-02-28 22:32:50,458:INFO:[LightGBM] [Info] Start training from score 23.765182
2024-02-28 22:32:50,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,620:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-02-28 22:32:50,620:INFO:[LightGBM] [Info] Total Bins 214
2024-02-28 22:32:50,620:INFO:[LightGBM] [Info] Number of data points in the train set: 247, number of used features: 5
2024-02-28 22:32:50,673:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-02-28 22:32:50,673:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-02-28 22:32:50,689:INFO:[LightGBM] [Info] GPU programs have been built
2024-02-28 22:32:50,689:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-02-28 22:32:50,689:INFO:[LightGBM] [Info] 5 dense feature groups (0.00 MB) transferred to GPU in 0.000758 secs. 0 sparse feature groups
2024-02-28 22:32:50,689:INFO:[LightGBM] [Info] Start training from score 23.770040
2024-02-28 22:32:50,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,850:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-02-28 22:32:50,850:INFO:[LightGBM] [Info] Total Bins 218
2024-02-28 22:32:50,850:INFO:[LightGBM] [Info] Number of data points in the train set: 247, number of used features: 5
2024-02-28 22:32:50,897:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-02-28 22:32:50,897:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-02-28 22:32:50,912:INFO:[LightGBM] [Info] GPU programs have been built
2024-02-28 22:32:50,912:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-02-28 22:32:50,912:INFO:[LightGBM] [Info] 5 dense feature groups (0.00 MB) transferred to GPU in 0.000398 secs. 0 sparse feature groups
2024-02-28 22:32:50,912:INFO:[LightGBM] [Info] Start training from score 23.837652
2024-02-28 22:32:50,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:50,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:51,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:51,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:51,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:51,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:51,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:51,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:51,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:51,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:51,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:51,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:51,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:51,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:51,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:51,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:51,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:51,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:51,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:51,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:51,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:51,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:51,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:51,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:51,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:51,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:51,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:51,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:51,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:51,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:51,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:51,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:51,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:51,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:51,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:32:51,059:INFO:Calculating mean and std
2024-02-28 22:32:51,074:INFO:Creating metrics dataframe
2024-02-28 22:32:51,077:INFO:Uploading results into container
2024-02-28 22:32:51,078:INFO:Uploading model into container now
2024-02-28 22:32:51,079:INFO:_master_model_container: 25
2024-02-28 22:32:51,079:INFO:_display_container: 10
2024-02-28 22:32:51,079:INFO:LGBMRegressor(device='gpu', n_jobs=-1, random_state=123)
2024-02-28 22:32:51,079:INFO:create_model() successfully completed......................................
2024-02-28 22:32:51,249:INFO:SubProcess create_model() end ==================================
2024-02-28 22:32:51,249:INFO:Creating metrics dataframe
2024-02-28 22:32:51,259:INFO:Initializing CatBoost Regressor
2024-02-28 22:32:51,259:INFO:Total runtime is 0.17026465336481733 minutes
2024-02-28 22:32:51,261:INFO:SubProcess create_model() called ==================================
2024-02-28 22:32:51,261:INFO:Initializing create_model()
2024-02-28 22:32:51,261:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571F1E50>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000160670ED970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:32:51,261:INFO:Checking exceptions
2024-02-28 22:32:51,261:INFO:Importing libraries
2024-02-28 22:32:51,261:INFO:Copying training dataset
2024-02-28 22:32:51,263:INFO:Defining folds
2024-02-28 22:32:51,264:INFO:Declaring metric variables
2024-02-28 22:32:51,266:INFO:Importing untrained model
2024-02-28 22:32:51,270:INFO:CatBoost Regressor Imported successfully
2024-02-28 22:32:51,274:INFO:Starting cross validation
2024-02-28 22:32:51,274:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:34:05,226:INFO:Calculating mean and std
2024-02-28 22:34:05,226:INFO:Creating metrics dataframe
2024-02-28 22:34:05,226:INFO:Uploading results into container
2024-02-28 22:34:05,234:INFO:Uploading model into container now
2024-02-28 22:34:05,234:INFO:_master_model_container: 26
2024-02-28 22:34:05,234:INFO:_display_container: 10
2024-02-28 22:34:05,234:INFO:<catboost.core.CatBoostRegressor object at 0x000001602B45DDC0>
2024-02-28 22:34:05,234:INFO:create_model() successfully completed......................................
2024-02-28 22:34:05,372:INFO:SubProcess create_model() end ==================================
2024-02-28 22:34:05,372:INFO:Creating metrics dataframe
2024-02-28 22:34:05,381:INFO:Initializing Dummy Regressor
2024-02-28 22:34:05,381:INFO:Total runtime is 1.4056228081385296 minutes
2024-02-28 22:34:05,389:INFO:SubProcess create_model() called ==================================
2024-02-28 22:34:05,390:INFO:Initializing create_model()
2024-02-28 22:34:05,390:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571F1E50>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000160670ED970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:34:05,390:INFO:Checking exceptions
2024-02-28 22:34:05,390:INFO:Importing libraries
2024-02-28 22:34:05,390:INFO:Copying training dataset
2024-02-28 22:34:05,391:INFO:Defining folds
2024-02-28 22:34:05,391:INFO:Declaring metric variables
2024-02-28 22:34:05,391:INFO:Importing untrained model
2024-02-28 22:34:05,396:INFO:Dummy Regressor Imported successfully
2024-02-28 22:34:05,401:INFO:Starting cross validation
2024-02-28 22:34:05,401:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:34:05,472:INFO:Calculating mean and std
2024-02-28 22:34:05,472:INFO:Creating metrics dataframe
2024-02-28 22:34:05,472:INFO:Uploading results into container
2024-02-28 22:34:05,472:INFO:Uploading model into container now
2024-02-28 22:34:05,472:INFO:_master_model_container: 27
2024-02-28 22:34:05,472:INFO:_display_container: 10
2024-02-28 22:34:05,472:INFO:DummyRegressor()
2024-02-28 22:34:05,472:INFO:create_model() successfully completed......................................
2024-02-28 22:34:05,619:INFO:SubProcess create_model() end ==================================
2024-02-28 22:34:05,619:INFO:Creating metrics dataframe
2024-02-28 22:34:05,635:INFO:Initializing create_model()
2024-02-28 22:34:05,635:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571F1E50>, estimator=GradientBoostingRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:34:05,635:INFO:Checking exceptions
2024-02-28 22:34:05,636:INFO:Importing libraries
2024-02-28 22:34:05,636:INFO:Copying training dataset
2024-02-28 22:34:05,636:INFO:Defining folds
2024-02-28 22:34:05,636:INFO:Declaring metric variables
2024-02-28 22:34:05,636:INFO:Importing untrained model
2024-02-28 22:34:05,636:INFO:Declaring custom model
2024-02-28 22:34:05,636:INFO:Gradient Boosting Regressor Imported successfully
2024-02-28 22:34:05,636:INFO:Cross validation set to False
2024-02-28 22:34:05,636:INFO:Fitting Model
2024-02-28 22:34:05,688:INFO:GradientBoostingRegressor(random_state=123)
2024-02-28 22:34:05,688:INFO:create_model() successfully completed......................................
2024-02-28 22:34:05,834:INFO:Initializing create_model()
2024-02-28 22:34:05,834:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571F1E50>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:34:05,834:INFO:Checking exceptions
2024-02-28 22:34:05,839:INFO:Importing libraries
2024-02-28 22:34:05,839:INFO:Copying training dataset
2024-02-28 22:34:05,841:INFO:Defining folds
2024-02-28 22:34:05,841:INFO:Declaring metric variables
2024-02-28 22:34:05,841:INFO:Importing untrained model
2024-02-28 22:34:05,842:INFO:Declaring custom model
2024-02-28 22:34:05,842:INFO:Random Forest Regressor Imported successfully
2024-02-28 22:34:05,842:INFO:Cross validation set to False
2024-02-28 22:34:05,842:INFO:Fitting Model
2024-02-28 22:34:05,850:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-02-28 22:34:05,850:INFO:create_model() successfully completed......................................
2024-02-28 22:34:05,988:INFO:Initializing create_model()
2024-02-28 22:34:05,988:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571F1E50>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:34:05,988:INFO:Checking exceptions
2024-02-28 22:34:05,988:INFO:Importing libraries
2024-02-28 22:34:05,988:INFO:Copying training dataset
2024-02-28 22:34:05,988:INFO:Defining folds
2024-02-28 22:34:05,995:INFO:Declaring metric variables
2024-02-28 22:34:05,995:INFO:Importing untrained model
2024-02-28 22:34:05,995:INFO:Declaring custom model
2024-02-28 22:34:05,996:INFO:Extra Trees Regressor Imported successfully
2024-02-28 22:34:05,996:INFO:Cross validation set to False
2024-02-28 22:34:05,996:INFO:Fitting Model
2024-02-28 22:34:06,005:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-02-28 22:34:06,005:INFO:create_model() successfully completed......................................
2024-02-28 22:34:06,172:INFO:_master_model_container: 27
2024-02-28 22:34:06,172:INFO:_display_container: 10
2024-02-28 22:34:06,172:INFO:[GradientBoostingRegressor(random_state=123), RandomForestRegressor(n_jobs=-1, random_state=123), ExtraTreesRegressor(n_jobs=-1, random_state=123)]
2024-02-28 22:34:06,172:INFO:compare_models() successfully completed......................................
2024-02-28 22:34:13,228:INFO:Initializing blend_models()
2024-02-28 22:34:13,228:INFO:blend_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571F1E50>, estimator_list=[GradientBoostingRegressor(random_state=123), RandomForestRegressor(n_jobs=-1, random_state=123), ExtraTreesRegressor(n_jobs=-1, random_state=123)], fold=None, round=4, choose_better=False, optimize=R2, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2024-02-28 22:34:13,228:INFO:Checking exceptions
2024-02-28 22:34:13,234:INFO:Importing libraries
2024-02-28 22:34:13,234:INFO:Copying training dataset
2024-02-28 22:34:13,234:INFO:Getting model names
2024-02-28 22:34:13,234:INFO:SubProcess create_model() called ==================================
2024-02-28 22:34:13,250:INFO:Initializing create_model()
2024-02-28 22:34:13,250:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571F1E50>, estimator=VotingRegressor(estimators=[('Gradient Boosting Regressor',
                             GradientBoostingRegressor(random_state=123)),
                            ('Random Forest Regressor',
                             RandomForestRegressor(n_jobs=-1,
                                                   random_state=123)),
                            ('Extra Trees Regressor',
                             ExtraTreesRegressor(n_jobs=-1, random_state=123))],
                n_jobs=1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001602AD2E100>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:34:13,250:INFO:Checking exceptions
2024-02-28 22:34:13,250:INFO:Importing libraries
2024-02-28 22:34:13,250:INFO:Copying training dataset
2024-02-28 22:34:13,252:INFO:Defining folds
2024-02-28 22:34:13,253:INFO:Declaring metric variables
2024-02-28 22:34:13,255:INFO:Importing untrained model
2024-02-28 22:34:13,255:INFO:Declaring custom model
2024-02-28 22:34:13,258:INFO:Voting Regressor Imported successfully
2024-02-28 22:34:13,263:INFO:Starting cross validation
2024-02-28 22:34:13,263:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:34:13,335:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:13,336:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:13,402:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:13,404:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:13,467:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:13,468:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:13,526:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:13,526:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:13,588:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:13,588:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:13,659:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:13,659:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:13,725:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:13,726:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:13,788:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:13,788:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:13,852:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:13,852:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:13,911:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:13,919:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:13,919:INFO:Calculating mean and std
2024-02-28 22:34:13,919:INFO:Creating metrics dataframe
2024-02-28 22:34:13,919:INFO:Finalizing model
2024-02-28 22:34:13,988:INFO:Uploading results into container
2024-02-28 22:34:13,988:INFO:Uploading model into container now
2024-02-28 22:34:13,988:INFO:_master_model_container: 28
2024-02-28 22:34:13,988:INFO:_display_container: 11
2024-02-28 22:34:13,992:INFO:VotingRegressor(estimators=[('Gradient Boosting Regressor',
                             GradientBoostingRegressor(random_state=123)),
                            ('Random Forest Regressor',
                             RandomForestRegressor(n_jobs=-1,
                                                   random_state=123)),
                            ('Extra Trees Regressor',
                             ExtraTreesRegressor(n_jobs=-1, random_state=123))],
                n_jobs=1)
2024-02-28 22:34:13,992:INFO:create_model() successfully completed......................................
2024-02-28 22:34:14,139:INFO:SubProcess create_model() end ==================================
2024-02-28 22:34:14,142:INFO:_master_model_container: 28
2024-02-28 22:34:14,142:INFO:_display_container: 11
2024-02-28 22:34:14,149:INFO:VotingRegressor(estimators=[('Gradient Boosting Regressor',
                             GradientBoostingRegressor(random_state=123)),
                            ('Random Forest Regressor',
                             RandomForestRegressor(n_jobs=-1,
                                                   random_state=123)),
                            ('Extra Trees Regressor',
                             ExtraTreesRegressor(n_jobs=-1, random_state=123))],
                n_jobs=1)
2024-02-28 22:34:14,149:INFO:blend_models() successfully completed......................................
2024-02-28 22:34:38,029:INFO:Initializing stack_models()
2024-02-28 22:34:38,029:INFO:stack_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571F1E50>, estimator_list=[GradientBoostingRegressor(random_state=123), RandomForestRegressor(n_jobs=-1, random_state=123), ExtraTreesRegressor(n_jobs=-1, random_state=123)], meta_model=None, meta_model_fold=5, fold=None, round=4, method=auto, restack=False, choose_better=False, optimize=R2, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2024-02-28 22:34:38,029:INFO:Checking exceptions
2024-02-28 22:34:38,029:INFO:Defining meta model
2024-02-28 22:34:38,045:INFO:Getting model names
2024-02-28 22:34:38,045:INFO:[('Gradient Boosting Regressor', GradientBoostingRegressor(random_state=123)), ('Random Forest Regressor', RandomForestRegressor(n_jobs=-1, random_state=123)), ('Extra Trees Regressor', ExtraTreesRegressor(n_jobs=-1, random_state=123))]
2024-02-28 22:34:38,048:INFO:SubProcess create_model() called ==================================
2024-02-28 22:34:38,050:INFO:Initializing create_model()
2024-02-28 22:34:38,050:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571F1E50>, estimator=StackingRegressor(cv=5,
                  estimators=[('Gradient Boosting Regressor',
                               GradientBoostingRegressor(random_state=123)),
                              ('Random Forest Regressor',
                               RandomForestRegressor(n_jobs=-1,
                                                     random_state=123)),
                              ('Extra Trees Regressor',
                               ExtraTreesRegressor(n_jobs=-1,
                                                   random_state=123))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001602AD2E100>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:34:38,050:INFO:Checking exceptions
2024-02-28 22:34:38,050:INFO:Importing libraries
2024-02-28 22:34:38,050:INFO:Copying training dataset
2024-02-28 22:34:38,050:INFO:Defining folds
2024-02-28 22:34:38,050:INFO:Declaring metric variables
2024-02-28 22:34:38,050:INFO:Importing untrained model
2024-02-28 22:34:38,050:INFO:Declaring custom model
2024-02-28 22:34:38,061:INFO:Stacking Regressor Imported successfully
2024-02-28 22:34:38,065:INFO:Starting cross validation
2024-02-28 22:34:38,065:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:34:38,343:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:38,352:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:38,359:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:38,364:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:38,370:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:38,373:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:38,373:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:38,373:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:38,389:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:38,396:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:38,396:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:38,404:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:38,675:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:38,685:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:38,689:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:38,696:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:38,697:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:38,704:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:38,712:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:38,720:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:38,720:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:38,727:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:38,735:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:38,735:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:39,012:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:39,012:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:39,021:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:39,028:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:39,028:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:39,040:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:39,047:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:39,054:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:39,059:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:39,065:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:39,070:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:39,071:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:39,354:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:39,359:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:39,365:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:39,370:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:39,375:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:39,383:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:39,388:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:39,394:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:39,399:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:39,406:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:39,411:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:39,412:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:39,681:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:39,692:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:39,698:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:39,703:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:39,708:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:39,715:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:39,719:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:39,728:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:39,733:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:39,740:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:39,743:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:39,743:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:40,020:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:40,027:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:40,027:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:40,037:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:40,042:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:40,050:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:40,050:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:40,062:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:40,068:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:40,073:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:40,073:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:40,073:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:40,354:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:40,359:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:40,365:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:40,371:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:40,373:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:40,382:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:40,389:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:40,395:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:40,401:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:40,405:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:40,405:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:40,412:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:40,685:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:40,692:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:40,697:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:40,697:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:40,704:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:40,712:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:40,719:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:40,719:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:40,727:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:40,735:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:40,743:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:40,743:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:41,027:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:41,027:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:41,035:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:41,042:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:41,042:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:41,050:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:41,058:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:41,066:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:41,066:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:41,073:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:41,081:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:41,081:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:41,358:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:41,366:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:41,366:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:41,373:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:41,382:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:41,389:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:41,395:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:41,397:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:41,404:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:41,412:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:41,412:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:41,412:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:41,421:INFO:Calculating mean and std
2024-02-28 22:34:41,421:INFO:Creating metrics dataframe
2024-02-28 22:34:41,421:INFO:Finalizing model
2024-02-28 22:34:41,696:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:41,704:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:41,712:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:41,720:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:41,720:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:41,727:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:41,737:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:41,743:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:41,750:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:41,750:WARNING:c:\Users\Administrator\anaconda3\envs\EXAM_ML\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-02-28 22:34:41,763:INFO:Uploading results into container
2024-02-28 22:34:41,763:INFO:Uploading model into container now
2024-02-28 22:34:41,764:INFO:_master_model_container: 29
2024-02-28 22:34:41,764:INFO:_display_container: 12
2024-02-28 22:34:41,766:INFO:StackingRegressor(cv=5,
                  estimators=[('Gradient Boosting Regressor',
                               GradientBoostingRegressor(random_state=123)),
                              ('Random Forest Regressor',
                               RandomForestRegressor(n_jobs=-1,
                                                     random_state=123)),
                              ('Extra Trees Regressor',
                               ExtraTreesRegressor(n_jobs=-1,
                                                   random_state=123))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=1)
2024-02-28 22:34:41,766:INFO:create_model() successfully completed......................................
2024-02-28 22:34:41,912:INFO:SubProcess create_model() end ==================================
2024-02-28 22:34:41,912:INFO:_master_model_container: 29
2024-02-28 22:34:41,912:INFO:_display_container: 12
2024-02-28 22:34:41,920:INFO:StackingRegressor(cv=5,
                  estimators=[('Gradient Boosting Regressor',
                               GradientBoostingRegressor(random_state=123)),
                              ('Random Forest Regressor',
                               RandomForestRegressor(n_jobs=-1,
                                                     random_state=123)),
                              ('Extra Trees Regressor',
                               ExtraTreesRegressor(n_jobs=-1,
                                                   random_state=123))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=1)
2024-02-28 22:34:41,920:INFO:stack_models() successfully completed......................................
2024-02-28 22:35:04,629:INFO:Initializing create_model()
2024-02-28 22:35:04,629:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571F1E50>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:35:04,630:INFO:Checking exceptions
2024-02-28 22:35:04,645:INFO:Importing libraries
2024-02-28 22:35:04,645:INFO:Copying training dataset
2024-02-28 22:35:04,648:INFO:Defining folds
2024-02-28 22:35:04,648:INFO:Declaring metric variables
2024-02-28 22:35:04,650:INFO:Importing untrained model
2024-02-28 22:35:04,653:INFO:Light Gradient Boosting Machine Imported successfully
2024-02-28 22:35:04,658:INFO:Starting cross validation
2024-02-28 22:35:04,658:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:35:04,668:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-02-28 22:35:04,668:INFO:[LightGBM] [Info] Total Bins 217
2024-02-28 22:35:04,668:INFO:[LightGBM] [Info] Number of data points in the train set: 246, number of used features: 5
2024-02-28 22:35:04,751:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-02-28 22:35:04,751:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-02-28 22:35:04,759:INFO:[LightGBM] [Info] GPU programs have been built
2024-02-28 22:35:04,760:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-02-28 22:35:04,761:INFO:[LightGBM] [Info] 5 dense feature groups (0.00 MB) transferred to GPU in 0.000394 secs. 0 sparse feature groups
2024-02-28 22:35:04,761:INFO:[LightGBM] [Info] Start training from score 23.452033
2024-02-28 22:35:04,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,888:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-02-28 22:35:04,888:INFO:[LightGBM] [Info] Total Bins 220
2024-02-28 22:35:04,888:INFO:[LightGBM] [Info] Number of data points in the train set: 246, number of used features: 5
2024-02-28 22:35:04,959:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-02-28 22:35:04,959:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-02-28 22:35:04,966:INFO:[LightGBM] [Info] GPU programs have been built
2024-02-28 22:35:04,968:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-02-28 22:35:04,968:INFO:[LightGBM] [Info] 5 dense feature groups (0.00 MB) transferred to GPU in 0.000387 secs. 0 sparse feature groups
2024-02-28 22:35:04,968:INFO:[LightGBM] [Info] Start training from score 23.622358
2024-02-28 22:35:04,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:04,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,105:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-02-28 22:35:05,105:INFO:[LightGBM] [Info] Total Bins 214
2024-02-28 22:35:05,105:INFO:[LightGBM] [Info] Number of data points in the train set: 246, number of used features: 5
2024-02-28 22:35:05,167:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-02-28 22:35:05,167:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-02-28 22:35:05,167:INFO:[LightGBM] [Info] GPU programs have been built
2024-02-28 22:35:05,174:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-02-28 22:35:05,174:INFO:[LightGBM] [Info] 5 dense feature groups (0.00 MB) transferred to GPU in 0.000325 secs. 0 sparse feature groups
2024-02-28 22:35:05,174:INFO:[LightGBM] [Info] Start training from score 23.693902
2024-02-28 22:35:05,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,328:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-02-28 22:35:05,328:INFO:[LightGBM] [Info] Total Bins 218
2024-02-28 22:35:05,328:INFO:[LightGBM] [Info] Number of data points in the train set: 246, number of used features: 5
2024-02-28 22:35:05,390:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-02-28 22:35:05,390:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-02-28 22:35:05,397:INFO:[LightGBM] [Info] GPU programs have been built
2024-02-28 22:35:05,397:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-02-28 22:35:05,397:INFO:[LightGBM] [Info] 5 dense feature groups (0.00 MB) transferred to GPU in 0.000382 secs. 0 sparse feature groups
2024-02-28 22:35:05,397:INFO:[LightGBM] [Info] Start training from score 23.815041
2024-02-28 22:35:05,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,551:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-02-28 22:35:05,551:INFO:[LightGBM] [Info] Total Bins 218
2024-02-28 22:35:05,551:INFO:[LightGBM] [Info] Number of data points in the train set: 247, number of used features: 5
2024-02-28 22:35:05,613:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-02-28 22:35:05,613:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-02-28 22:35:05,620:INFO:[LightGBM] [Info] GPU programs have been built
2024-02-28 22:35:05,620:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-02-28 22:35:05,620:INFO:[LightGBM] [Info] 5 dense feature groups (0.00 MB) transferred to GPU in 0.000361 secs. 0 sparse feature groups
2024-02-28 22:35:05,620:INFO:[LightGBM] [Info] Start training from score 23.681781
2024-02-28 22:35:05,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,775:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-02-28 22:35:05,775:INFO:[LightGBM] [Info] Total Bins 219
2024-02-28 22:35:05,775:INFO:[LightGBM] [Info] Number of data points in the train set: 247, number of used features: 5
2024-02-28 22:35:05,833:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-02-28 22:35:05,833:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-02-28 22:35:05,849:INFO:[LightGBM] [Info] GPU programs have been built
2024-02-28 22:35:05,849:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-02-28 22:35:05,849:INFO:[LightGBM] [Info] 5 dense feature groups (0.00 MB) transferred to GPU in 0.000396 secs. 0 sparse feature groups
2024-02-28 22:35:05,849:INFO:[LightGBM] [Info] Start training from score 23.918623
2024-02-28 22:35:05,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:05,992:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-02-28 22:35:05,992:INFO:[LightGBM] [Info] Total Bins 214
2024-02-28 22:35:05,992:INFO:[LightGBM] [Info] Number of data points in the train set: 247, number of used features: 5
2024-02-28 22:35:06,055:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-02-28 22:35:06,055:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-02-28 22:35:06,055:INFO:[LightGBM] [Info] GPU programs have been built
2024-02-28 22:35:06,069:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-02-28 22:35:06,071:INFO:[LightGBM] [Info] 5 dense feature groups (0.00 MB) transferred to GPU in 0.000385 secs. 0 sparse feature groups
2024-02-28 22:35:06,071:INFO:[LightGBM] [Info] Start training from score 23.956275
2024-02-28 22:35:06,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,227:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-02-28 22:35:06,227:INFO:[LightGBM] [Info] Total Bins 215
2024-02-28 22:35:06,227:INFO:[LightGBM] [Info] Number of data points in the train set: 247, number of used features: 5
2024-02-28 22:35:06,290:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-02-28 22:35:06,290:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-02-28 22:35:06,297:INFO:[LightGBM] [Info] GPU programs have been built
2024-02-28 22:35:06,297:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-02-28 22:35:06,297:INFO:[LightGBM] [Info] 5 dense feature groups (0.00 MB) transferred to GPU in 0.000361 secs. 0 sparse feature groups
2024-02-28 22:35:06,297:INFO:[LightGBM] [Info] Start training from score 23.765182
2024-02-28 22:35:06,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,443:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-02-28 22:35:06,443:INFO:[LightGBM] [Info] Total Bins 214
2024-02-28 22:35:06,443:INFO:[LightGBM] [Info] Number of data points in the train set: 247, number of used features: 5
2024-02-28 22:35:06,497:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-02-28 22:35:06,497:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-02-28 22:35:06,497:INFO:[LightGBM] [Info] GPU programs have been built
2024-02-28 22:35:06,511:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-02-28 22:35:06,513:INFO:[LightGBM] [Info] 5 dense feature groups (0.00 MB) transferred to GPU in 0.000454 secs. 0 sparse feature groups
2024-02-28 22:35:06,513:INFO:[LightGBM] [Info] Start training from score 23.770040
2024-02-28 22:35:06,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,666:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-02-28 22:35:06,666:INFO:[LightGBM] [Info] Total Bins 218
2024-02-28 22:35:06,666:INFO:[LightGBM] [Info] Number of data points in the train set: 247, number of used features: 5
2024-02-28 22:35:06,717:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-02-28 22:35:06,717:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-02-28 22:35:06,733:INFO:[LightGBM] [Info] GPU programs have been built
2024-02-28 22:35:06,733:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-02-28 22:35:06,733:INFO:[LightGBM] [Info] 5 dense feature groups (0.00 MB) transferred to GPU in 0.000355 secs. 0 sparse feature groups
2024-02-28 22:35:06,733:INFO:[LightGBM] [Info] Start training from score 23.837652
2024-02-28 22:35:06,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,867:INFO:Calculating mean and std
2024-02-28 22:35:06,867:INFO:Creating metrics dataframe
2024-02-28 22:35:06,882:INFO:Finalizing model
2024-02-28 22:35:06,889:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-02-28 22:35:06,889:INFO:[LightGBM] [Info] Total Bins 234
2024-02-28 22:35:06,889:INFO:[LightGBM] [Info] Number of data points in the train set: 274, number of used features: 5
2024-02-28 22:35:06,943:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-02-28 22:35:06,943:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-02-28 22:35:06,943:INFO:[LightGBM] [Info] GPU programs have been built
2024-02-28 22:35:06,943:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-02-28 22:35:06,943:INFO:[LightGBM] [Info] 5 dense feature groups (0.00 MB) transferred to GPU in 0.000432 secs. 0 sparse feature groups
2024-02-28 22:35:06,943:INFO:[LightGBM] [Info] Start training from score 23.751460
2024-02-28 22:35:06,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:06,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:07,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:07,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:07,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:07,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:07,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:07,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:07,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:07,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:07,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:07,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:07,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:07,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:07,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:07,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:07,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:07,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:07,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:07,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:07,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:07,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:07,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:07,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:07,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:07,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:07,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:07,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:07,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:07,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:07,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:07,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:07,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:07,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:07,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:07,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:07,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:07,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:07,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:07,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:07,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:07,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:07,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:07,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:07,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:07,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:07,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:07,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:07,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:07,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:07,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:07,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:07,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:07,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:07,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:07,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:07,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:07,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:07,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:07,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:07,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:07,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:07,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:07,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:07,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:07,128:INFO:Uploading results into container
2024-02-28 22:35:07,129:INFO:Uploading model into container now
2024-02-28 22:35:07,136:INFO:_master_model_container: 30
2024-02-28 22:35:07,137:INFO:_display_container: 13
2024-02-28 22:35:07,137:INFO:LGBMRegressor(device='gpu', n_jobs=-1, random_state=123)
2024-02-28 22:35:07,137:INFO:create_model() successfully completed......................................
2024-02-28 22:35:09,751:INFO:Initializing interpret_model()
2024-02-28 22:35:09,751:INFO:interpret_model(estimator=LGBMRegressor(device='gpu', n_jobs=-1, random_state=123), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=summary, save=False, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571F1E50>)
2024-02-28 22:35:09,751:INFO:Checking exceptions
2024-02-28 22:35:09,751:INFO:Soft dependency imported: shap: 0.44.1
2024-02-28 22:35:09,945:INFO:plot type: summary
2024-02-28 22:35:09,945:INFO:Creating TreeExplainer
2024-02-28 22:35:09,950:INFO:Compiling shap values
2024-02-28 22:35:10,128:INFO:Visual Rendered Successfully
2024-02-28 22:35:10,128:INFO:interpret_model() successfully completed......................................
2024-02-28 22:35:21,320:INFO:Initializing interpret_model()
2024-02-28 22:35:21,320:INFO:interpret_model(estimator=LGBMRegressor(device='gpu', n_jobs=-1, random_state=123), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=1, plot=reason, save=False, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571F1E50>)
2024-02-28 22:35:21,320:INFO:Checking exceptions
2024-02-28 22:35:21,320:INFO:Soft dependency imported: shap: 0.44.1
2024-02-28 22:35:21,332:INFO:plot type: reason
2024-02-28 22:35:21,332:INFO:model type detected: type 2
2024-02-28 22:35:21,332:INFO:Creating TreeExplainer
2024-02-28 22:35:21,350:INFO:Compiling shap values
2024-02-28 22:35:21,358:INFO:Visual Rendered Successfully
2024-02-28 22:35:21,358:INFO:interpret_model() successfully completed......................................
2024-02-28 22:35:35,385:INFO:Initializing create_model()
2024-02-28 22:35:35,385:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571F1E50>, estimator=LinearRegression(n_jobs=-1), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:35:35,385:INFO:Checking exceptions
2024-02-28 22:35:35,386:INFO:Importing libraries
2024-02-28 22:35:35,387:INFO:Copying training dataset
2024-02-28 22:35:35,388:INFO:Defining folds
2024-02-28 22:35:35,389:INFO:Declaring metric variables
2024-02-28 22:35:35,389:INFO:Importing untrained model
2024-02-28 22:35:35,389:INFO:Declaring custom model
2024-02-28 22:35:35,389:INFO:Linear Regression Imported successfully
2024-02-28 22:35:35,389:INFO:Starting cross validation
2024-02-28 22:35:35,390:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:35:35,474:INFO:Calculating mean and std
2024-02-28 22:35:35,474:INFO:Creating metrics dataframe
2024-02-28 22:35:35,474:INFO:Finalizing model
2024-02-28 22:35:35,485:INFO:Uploading results into container
2024-02-28 22:35:35,486:INFO:_master_model_container: 30
2024-02-28 22:35:35,486:INFO:_display_container: 14
2024-02-28 22:35:35,486:INFO:LinearRegression(n_jobs=-1)
2024-02-28 22:35:35,486:INFO:create_model() successfully completed......................................
2024-02-28 22:35:35,638:INFO:Initializing create_model()
2024-02-28 22:35:35,638:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571F1E50>, estimator=Lasso(random_state=123), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:35:35,638:INFO:Checking exceptions
2024-02-28 22:35:35,639:INFO:Importing libraries
2024-02-28 22:35:35,639:INFO:Copying training dataset
2024-02-28 22:35:35,641:INFO:Defining folds
2024-02-28 22:35:35,641:INFO:Declaring metric variables
2024-02-28 22:35:35,642:INFO:Importing untrained model
2024-02-28 22:35:35,642:INFO:Declaring custom model
2024-02-28 22:35:35,642:INFO:Lasso Regression Imported successfully
2024-02-28 22:35:35,642:INFO:Starting cross validation
2024-02-28 22:35:35,643:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:35:35,728:INFO:Calculating mean and std
2024-02-28 22:35:35,728:INFO:Creating metrics dataframe
2024-02-28 22:35:35,728:INFO:Finalizing model
2024-02-28 22:35:35,738:INFO:Uploading results into container
2024-02-28 22:35:35,738:INFO:_master_model_container: 30
2024-02-28 22:35:35,738:INFO:_display_container: 15
2024-02-28 22:35:35,738:INFO:Lasso(random_state=123)
2024-02-28 22:35:35,738:INFO:create_model() successfully completed......................................
2024-02-28 22:35:35,890:INFO:Initializing create_model()
2024-02-28 22:35:35,890:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571F1E50>, estimator=Ridge(random_state=123), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:35:35,890:INFO:Checking exceptions
2024-02-28 22:35:35,890:INFO:Importing libraries
2024-02-28 22:35:35,890:INFO:Copying training dataset
2024-02-28 22:35:35,890:INFO:Defining folds
2024-02-28 22:35:35,890:INFO:Declaring metric variables
2024-02-28 22:35:35,890:INFO:Importing untrained model
2024-02-28 22:35:35,890:INFO:Declaring custom model
2024-02-28 22:35:35,890:INFO:Ridge Regression Imported successfully
2024-02-28 22:35:35,890:INFO:Starting cross validation
2024-02-28 22:35:35,890:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:35:35,974:INFO:Calculating mean and std
2024-02-28 22:35:35,974:INFO:Creating metrics dataframe
2024-02-28 22:35:35,982:INFO:Finalizing model
2024-02-28 22:35:35,982:INFO:Uploading results into container
2024-02-28 22:35:35,982:INFO:_master_model_container: 30
2024-02-28 22:35:35,982:INFO:_display_container: 16
2024-02-28 22:35:35,982:INFO:Ridge(random_state=123)
2024-02-28 22:35:35,982:INFO:create_model() successfully completed......................................
2024-02-28 22:35:36,136:INFO:Initializing create_model()
2024-02-28 22:35:36,136:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571F1E50>, estimator=ElasticNet(random_state=123), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:35:36,136:INFO:Checking exceptions
2024-02-28 22:35:36,136:INFO:Importing libraries
2024-02-28 22:35:36,136:INFO:Copying training dataset
2024-02-28 22:35:36,136:INFO:Defining folds
2024-02-28 22:35:36,136:INFO:Declaring metric variables
2024-02-28 22:35:36,136:INFO:Importing untrained model
2024-02-28 22:35:36,136:INFO:Declaring custom model
2024-02-28 22:35:36,143:INFO:Elastic Net Imported successfully
2024-02-28 22:35:36,143:INFO:Starting cross validation
2024-02-28 22:35:36,144:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:35:36,228:INFO:Calculating mean and std
2024-02-28 22:35:36,228:INFO:Creating metrics dataframe
2024-02-28 22:35:36,228:INFO:Finalizing model
2024-02-28 22:35:36,236:INFO:Uploading results into container
2024-02-28 22:35:36,236:INFO:_master_model_container: 30
2024-02-28 22:35:36,236:INFO:_display_container: 17
2024-02-28 22:35:36,236:INFO:ElasticNet(random_state=123)
2024-02-28 22:35:36,236:INFO:create_model() successfully completed......................................
2024-02-28 22:35:36,390:INFO:Initializing create_model()
2024-02-28 22:35:36,390:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571F1E50>, estimator=Lars(random_state=123), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:35:36,390:INFO:Checking exceptions
2024-02-28 22:35:36,394:INFO:Importing libraries
2024-02-28 22:35:36,394:INFO:Copying training dataset
2024-02-28 22:35:36,396:INFO:Defining folds
2024-02-28 22:35:36,396:INFO:Declaring metric variables
2024-02-28 22:35:36,396:INFO:Importing untrained model
2024-02-28 22:35:36,396:INFO:Declaring custom model
2024-02-28 22:35:36,397:INFO:Least Angle Regression Imported successfully
2024-02-28 22:35:36,397:INFO:Starting cross validation
2024-02-28 22:35:36,398:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:35:36,482:INFO:Calculating mean and std
2024-02-28 22:35:36,482:INFO:Creating metrics dataframe
2024-02-28 22:35:36,482:INFO:Finalizing model
2024-02-28 22:35:36,490:INFO:Uploading results into container
2024-02-28 22:35:36,490:INFO:_master_model_container: 30
2024-02-28 22:35:36,490:INFO:_display_container: 18
2024-02-28 22:35:36,490:INFO:Lars(random_state=123)
2024-02-28 22:35:36,490:INFO:create_model() successfully completed......................................
2024-02-28 22:35:36,647:INFO:Initializing create_model()
2024-02-28 22:35:36,647:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571F1E50>, estimator=LassoLars(random_state=123), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:35:36,647:INFO:Checking exceptions
2024-02-28 22:35:36,648:INFO:Importing libraries
2024-02-28 22:35:36,649:INFO:Copying training dataset
2024-02-28 22:35:36,650:INFO:Defining folds
2024-02-28 22:35:36,650:INFO:Declaring metric variables
2024-02-28 22:35:36,651:INFO:Importing untrained model
2024-02-28 22:35:36,651:INFO:Declaring custom model
2024-02-28 22:35:36,651:INFO:Lasso Least Angle Regression Imported successfully
2024-02-28 22:35:36,651:INFO:Starting cross validation
2024-02-28 22:35:36,652:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:35:36,736:INFO:Calculating mean and std
2024-02-28 22:35:36,736:INFO:Creating metrics dataframe
2024-02-28 22:35:36,744:INFO:Finalizing model
2024-02-28 22:35:36,744:INFO:Uploading results into container
2024-02-28 22:35:36,744:INFO:_master_model_container: 30
2024-02-28 22:35:36,744:INFO:_display_container: 19
2024-02-28 22:35:36,744:INFO:LassoLars(random_state=123)
2024-02-28 22:35:36,744:INFO:create_model() successfully completed......................................
2024-02-28 22:35:36,897:INFO:Initializing create_model()
2024-02-28 22:35:36,897:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571F1E50>, estimator=OrthogonalMatchingPursuit(), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:35:36,897:INFO:Checking exceptions
2024-02-28 22:35:36,904:INFO:Importing libraries
2024-02-28 22:35:36,904:INFO:Copying training dataset
2024-02-28 22:35:36,907:INFO:Defining folds
2024-02-28 22:35:36,907:INFO:Declaring metric variables
2024-02-28 22:35:36,907:INFO:Importing untrained model
2024-02-28 22:35:36,907:INFO:Declaring custom model
2024-02-28 22:35:36,907:INFO:Orthogonal Matching Pursuit Imported successfully
2024-02-28 22:35:36,907:INFO:Starting cross validation
2024-02-28 22:35:36,908:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:35:36,997:INFO:Calculating mean and std
2024-02-28 22:35:36,997:INFO:Creating metrics dataframe
2024-02-28 22:35:36,997:INFO:Finalizing model
2024-02-28 22:35:36,997:INFO:Uploading results into container
2024-02-28 22:35:37,005:INFO:_master_model_container: 30
2024-02-28 22:35:37,005:INFO:_display_container: 20
2024-02-28 22:35:37,005:INFO:OrthogonalMatchingPursuit()
2024-02-28 22:35:37,005:INFO:create_model() successfully completed......................................
2024-02-28 22:35:37,159:INFO:Initializing create_model()
2024-02-28 22:35:37,159:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571F1E50>, estimator=BayesianRidge(), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:35:37,159:INFO:Checking exceptions
2024-02-28 22:35:37,160:INFO:Importing libraries
2024-02-28 22:35:37,160:INFO:Copying training dataset
2024-02-28 22:35:37,162:INFO:Defining folds
2024-02-28 22:35:37,162:INFO:Declaring metric variables
2024-02-28 22:35:37,162:INFO:Importing untrained model
2024-02-28 22:35:37,162:INFO:Declaring custom model
2024-02-28 22:35:37,163:INFO:Bayesian Ridge Imported successfully
2024-02-28 22:35:37,163:INFO:Starting cross validation
2024-02-28 22:35:37,163:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:35:37,251:INFO:Calculating mean and std
2024-02-28 22:35:37,251:INFO:Creating metrics dataframe
2024-02-28 22:35:37,251:INFO:Finalizing model
2024-02-28 22:35:37,259:INFO:Uploading results into container
2024-02-28 22:35:37,259:INFO:_master_model_container: 30
2024-02-28 22:35:37,259:INFO:_display_container: 21
2024-02-28 22:35:37,259:INFO:BayesianRidge()
2024-02-28 22:35:37,259:INFO:create_model() successfully completed......................................
2024-02-28 22:35:37,437:INFO:Initializing create_model()
2024-02-28 22:35:37,437:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571F1E50>, estimator=PassiveAggressiveRegressor(random_state=123), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:35:37,437:INFO:Checking exceptions
2024-02-28 22:35:37,438:INFO:Importing libraries
2024-02-28 22:35:37,438:INFO:Copying training dataset
2024-02-28 22:35:37,440:INFO:Defining folds
2024-02-28 22:35:37,440:INFO:Declaring metric variables
2024-02-28 22:35:37,440:INFO:Importing untrained model
2024-02-28 22:35:37,440:INFO:Declaring custom model
2024-02-28 22:35:37,441:INFO:Passive Aggressive Regressor Imported successfully
2024-02-28 22:35:37,441:INFO:Starting cross validation
2024-02-28 22:35:37,441:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:35:37,536:INFO:Calculating mean and std
2024-02-28 22:35:37,536:INFO:Creating metrics dataframe
2024-02-28 22:35:37,536:INFO:Finalizing model
2024-02-28 22:35:37,544:INFO:Uploading results into container
2024-02-28 22:35:37,544:INFO:_master_model_container: 30
2024-02-28 22:35:37,544:INFO:_display_container: 22
2024-02-28 22:35:37,544:INFO:PassiveAggressiveRegressor(random_state=123)
2024-02-28 22:35:37,544:INFO:create_model() successfully completed......................................
2024-02-28 22:35:37,698:INFO:Initializing create_model()
2024-02-28 22:35:37,698:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571F1E50>, estimator=HuberRegressor(), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:35:37,698:INFO:Checking exceptions
2024-02-28 22:35:37,700:INFO:Importing libraries
2024-02-28 22:35:37,700:INFO:Copying training dataset
2024-02-28 22:35:37,702:INFO:Defining folds
2024-02-28 22:35:37,702:INFO:Declaring metric variables
2024-02-28 22:35:37,703:INFO:Importing untrained model
2024-02-28 22:35:37,703:INFO:Declaring custom model
2024-02-28 22:35:37,703:INFO:Huber Regressor Imported successfully
2024-02-28 22:35:37,703:INFO:Starting cross validation
2024-02-28 22:35:37,703:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:35:37,723:WARNING:lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html

2024-02-28 22:35:37,744:WARNING:lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html

2024-02-28 22:35:37,782:WARNING:lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html

2024-02-28 22:35:37,805:WARNING:lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html

2024-02-28 22:35:37,828:WARNING:lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html

2024-02-28 22:35:37,859:WARNING:lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html

2024-02-28 22:35:37,882:WARNING:lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html

2024-02-28 22:35:37,905:WARNING:lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html

2024-02-28 22:35:37,912:INFO:Calculating mean and std
2024-02-28 22:35:37,913:INFO:Creating metrics dataframe
2024-02-28 22:35:37,913:INFO:Finalizing model
2024-02-28 22:35:37,928:WARNING:lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html

2024-02-28 22:35:37,928:INFO:Uploading results into container
2024-02-28 22:35:37,928:INFO:_master_model_container: 30
2024-02-28 22:35:37,928:INFO:_display_container: 23
2024-02-28 22:35:37,928:INFO:HuberRegressor()
2024-02-28 22:35:37,928:INFO:create_model() successfully completed......................................
2024-02-28 22:35:38,084:INFO:Initializing create_model()
2024-02-28 22:35:38,084:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571F1E50>, estimator=KNeighborsRegressor(n_jobs=-1), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:35:38,084:INFO:Checking exceptions
2024-02-28 22:35:38,088:INFO:Importing libraries
2024-02-28 22:35:38,088:INFO:Copying training dataset
2024-02-28 22:35:38,089:INFO:Defining folds
2024-02-28 22:35:38,089:INFO:Declaring metric variables
2024-02-28 22:35:38,089:INFO:Importing untrained model
2024-02-28 22:35:38,089:INFO:Declaring custom model
2024-02-28 22:35:38,090:INFO:K Neighbors Regressor Imported successfully
2024-02-28 22:35:38,090:INFO:Starting cross validation
2024-02-28 22:35:38,090:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:35:38,182:INFO:Calculating mean and std
2024-02-28 22:35:38,182:INFO:Creating metrics dataframe
2024-02-28 22:35:38,182:INFO:Finalizing model
2024-02-28 22:35:38,191:INFO:Uploading results into container
2024-02-28 22:35:38,191:INFO:_master_model_container: 30
2024-02-28 22:35:38,191:INFO:_display_container: 24
2024-02-28 22:35:38,191:INFO:KNeighborsRegressor(n_jobs=-1)
2024-02-28 22:35:38,191:INFO:create_model() successfully completed......................................
2024-02-28 22:35:38,344:INFO:Initializing create_model()
2024-02-28 22:35:38,344:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571F1E50>, estimator=DecisionTreeRegressor(random_state=123), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:35:38,344:INFO:Checking exceptions
2024-02-28 22:35:38,347:INFO:Importing libraries
2024-02-28 22:35:38,347:INFO:Copying training dataset
2024-02-28 22:35:38,349:INFO:Defining folds
2024-02-28 22:35:38,349:INFO:Declaring metric variables
2024-02-28 22:35:38,350:INFO:Importing untrained model
2024-02-28 22:35:38,350:INFO:Declaring custom model
2024-02-28 22:35:38,351:INFO:Decision Tree Regressor Imported successfully
2024-02-28 22:35:38,351:INFO:Starting cross validation
2024-02-28 22:35:38,351:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:35:38,436:INFO:Calculating mean and std
2024-02-28 22:35:38,436:INFO:Creating metrics dataframe
2024-02-28 22:35:38,444:INFO:Finalizing model
2024-02-28 22:35:38,444:INFO:Uploading results into container
2024-02-28 22:35:38,444:INFO:_master_model_container: 30
2024-02-28 22:35:38,444:INFO:_display_container: 25
2024-02-28 22:35:38,444:INFO:DecisionTreeRegressor(random_state=123)
2024-02-28 22:35:38,444:INFO:create_model() successfully completed......................................
2024-02-28 22:35:38,597:INFO:Initializing create_model()
2024-02-28 22:35:38,597:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571F1E50>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:35:38,597:INFO:Checking exceptions
2024-02-28 22:35:38,604:INFO:Importing libraries
2024-02-28 22:35:38,604:INFO:Copying training dataset
2024-02-28 22:35:38,606:INFO:Defining folds
2024-02-28 22:35:38,606:INFO:Declaring metric variables
2024-02-28 22:35:38,606:INFO:Importing untrained model
2024-02-28 22:35:38,607:INFO:Declaring custom model
2024-02-28 22:35:38,607:INFO:Random Forest Regressor Imported successfully
2024-02-28 22:35:38,608:INFO:Starting cross validation
2024-02-28 22:35:38,608:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:35:38,620:WARNING:X does not have valid feature names, but RandomForestRegressor was fitted with feature names

2024-02-28 22:35:38,631:WARNING:X does not have valid feature names, but RandomForestRegressor was fitted with feature names

2024-02-28 22:35:38,643:WARNING:X does not have valid feature names, but RandomForestRegressor was fitted with feature names

2024-02-28 22:35:38,659:WARNING:X does not have valid feature names, but RandomForestRegressor was fitted with feature names

2024-02-28 22:35:38,667:WARNING:X does not have valid feature names, but RandomForestRegressor was fitted with feature names

2024-02-28 22:35:38,683:WARNING:X does not have valid feature names, but RandomForestRegressor was fitted with feature names

2024-02-28 22:35:38,697:WARNING:X does not have valid feature names, but RandomForestRegressor was fitted with feature names

2024-02-28 22:35:38,713:WARNING:X does not have valid feature names, but RandomForestRegressor was fitted with feature names

2024-02-28 22:35:38,721:WARNING:X does not have valid feature names, but RandomForestRegressor was fitted with feature names

2024-02-28 22:35:38,736:WARNING:X does not have valid feature names, but RandomForestRegressor was fitted with feature names

2024-02-28 22:35:38,736:INFO:Calculating mean and std
2024-02-28 22:35:38,736:INFO:Creating metrics dataframe
2024-02-28 22:35:38,736:INFO:Finalizing model
2024-02-28 22:35:38,751:INFO:Uploading results into container
2024-02-28 22:35:38,751:INFO:_master_model_container: 30
2024-02-28 22:35:38,751:INFO:_display_container: 26
2024-02-28 22:35:38,751:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-02-28 22:35:38,751:INFO:create_model() successfully completed......................................
2024-02-28 22:35:38,897:INFO:Initializing create_model()
2024-02-28 22:35:38,897:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571F1E50>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:35:38,905:INFO:Checking exceptions
2024-02-28 22:35:38,905:INFO:Importing libraries
2024-02-28 22:35:38,905:INFO:Copying training dataset
2024-02-28 22:35:38,907:INFO:Defining folds
2024-02-28 22:35:38,907:INFO:Declaring metric variables
2024-02-28 22:35:38,908:INFO:Importing untrained model
2024-02-28 22:35:38,908:INFO:Declaring custom model
2024-02-28 22:35:38,908:INFO:Extra Trees Regressor Imported successfully
2024-02-28 22:35:38,908:INFO:Starting cross validation
2024-02-28 22:35:38,909:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:35:38,921:WARNING:X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names

2024-02-28 22:35:38,936:WARNING:X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names

2024-02-28 22:35:38,950:WARNING:X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names

2024-02-28 22:35:38,959:WARNING:X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names

2024-02-28 22:35:38,974:WARNING:X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names

2024-02-28 22:35:38,990:WARNING:X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names

2024-02-28 22:35:39,005:WARNING:X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names

2024-02-28 22:35:39,013:WARNING:X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names

2024-02-28 22:35:39,031:WARNING:X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names

2024-02-28 22:35:39,043:WARNING:X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names

2024-02-28 22:35:39,043:INFO:Calculating mean and std
2024-02-28 22:35:39,043:INFO:Creating metrics dataframe
2024-02-28 22:35:39,043:INFO:Finalizing model
2024-02-28 22:35:39,059:INFO:Uploading results into container
2024-02-28 22:35:39,059:INFO:_master_model_container: 30
2024-02-28 22:35:39,059:INFO:_display_container: 27
2024-02-28 22:35:39,059:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-02-28 22:35:39,059:INFO:create_model() successfully completed......................................
2024-02-28 22:35:39,205:INFO:Initializing create_model()
2024-02-28 22:35:39,205:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571F1E50>, estimator=AdaBoostRegressor(random_state=123), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:35:39,205:INFO:Checking exceptions
2024-02-28 22:35:39,211:INFO:Importing libraries
2024-02-28 22:35:39,211:INFO:Copying training dataset
2024-02-28 22:35:39,214:INFO:Defining folds
2024-02-28 22:35:39,214:INFO:Declaring metric variables
2024-02-28 22:35:39,214:INFO:Importing untrained model
2024-02-28 22:35:39,214:INFO:Declaring custom model
2024-02-28 22:35:39,214:INFO:AdaBoost Regressor Imported successfully
2024-02-28 22:35:39,215:INFO:Starting cross validation
2024-02-28 22:35:39,215:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:35:39,759:INFO:Calculating mean and std
2024-02-28 22:35:39,759:INFO:Creating metrics dataframe
2024-02-28 22:35:39,759:INFO:Finalizing model
2024-02-28 22:35:39,812:INFO:Uploading results into container
2024-02-28 22:35:39,813:INFO:_master_model_container: 30
2024-02-28 22:35:39,813:INFO:_display_container: 28
2024-02-28 22:35:39,813:INFO:AdaBoostRegressor(random_state=123)
2024-02-28 22:35:39,813:INFO:create_model() successfully completed......................................
2024-02-28 22:35:39,959:INFO:Initializing create_model()
2024-02-28 22:35:39,966:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571F1E50>, estimator=GradientBoostingRegressor(random_state=123), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:35:39,967:INFO:Checking exceptions
2024-02-28 22:35:39,968:INFO:Importing libraries
2024-02-28 22:35:39,968:INFO:Copying training dataset
2024-02-28 22:35:39,969:INFO:Defining folds
2024-02-28 22:35:39,970:INFO:Declaring metric variables
2024-02-28 22:35:39,970:INFO:Importing untrained model
2024-02-28 22:35:39,970:INFO:Declaring custom model
2024-02-28 22:35:39,970:INFO:Gradient Boosting Regressor Imported successfully
2024-02-28 22:35:39,971:INFO:Starting cross validation
2024-02-28 22:35:39,971:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:35:40,474:INFO:Calculating mean and std
2024-02-28 22:35:40,474:INFO:Creating metrics dataframe
2024-02-28 22:35:40,474:INFO:Finalizing model
2024-02-28 22:35:40,528:INFO:Uploading results into container
2024-02-28 22:35:40,528:INFO:_master_model_container: 30
2024-02-28 22:35:40,528:INFO:_display_container: 29
2024-02-28 22:35:40,528:INFO:GradientBoostingRegressor(random_state=123)
2024-02-28 22:35:40,528:INFO:create_model() successfully completed......................................
2024-02-28 22:35:40,684:INFO:Initializing create_model()
2024-02-28 22:35:40,684:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571F1E50>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='gpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=123, ...), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:35:40,684:INFO:Checking exceptions
2024-02-28 22:35:40,685:INFO:Importing libraries
2024-02-28 22:35:40,685:INFO:Copying training dataset
2024-02-28 22:35:40,687:INFO:Defining folds
2024-02-28 22:35:40,687:INFO:Declaring metric variables
2024-02-28 22:35:40,687:INFO:Importing untrained model
2024-02-28 22:35:40,687:INFO:Declaring custom model
2024-02-28 22:35:40,687:INFO:Extreme Gradient Boosting Imported successfully
2024-02-28 22:35:40,687:INFO:Starting cross validation
2024-02-28 22:35:40,687:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:35:42,966:INFO:Calculating mean and std
2024-02-28 22:35:42,966:INFO:Creating metrics dataframe
2024-02-28 22:35:42,974:INFO:Finalizing model
2024-02-28 22:35:43,167:INFO:Uploading results into container
2024-02-28 22:35:43,167:INFO:_master_model_container: 30
2024-02-28 22:35:43,167:INFO:_display_container: 30
2024-02-28 22:35:43,174:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='gpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=123, ...)
2024-02-28 22:35:43,174:INFO:create_model() successfully completed......................................
2024-02-28 22:35:43,351:INFO:Initializing create_model()
2024-02-28 22:35:43,351:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571F1E50>, estimator=LGBMRegressor(device='gpu', n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:35:43,351:INFO:Checking exceptions
2024-02-28 22:35:43,356:INFO:Importing libraries
2024-02-28 22:35:43,356:INFO:Copying training dataset
2024-02-28 22:35:43,358:INFO:Defining folds
2024-02-28 22:35:43,358:INFO:Declaring metric variables
2024-02-28 22:35:43,358:INFO:Importing untrained model
2024-02-28 22:35:43,358:INFO:Declaring custom model
2024-02-28 22:35:43,359:INFO:Light Gradient Boosting Machine Imported successfully
2024-02-28 22:35:43,359:INFO:Starting cross validation
2024-02-28 22:35:43,360:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:35:43,366:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-02-28 22:35:43,366:INFO:[LightGBM] [Info] Total Bins 217
2024-02-28 22:35:43,366:INFO:[LightGBM] [Info] Number of data points in the train set: 246, number of used features: 5
2024-02-28 22:35:43,420:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-02-28 22:35:43,420:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-02-28 22:35:43,428:INFO:[LightGBM] [Info] GPU programs have been built
2024-02-28 22:35:43,436:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-02-28 22:35:43,436:INFO:[LightGBM] [Info] 5 dense feature groups (0.00 MB) transferred to GPU in 0.000431 secs. 0 sparse feature groups
2024-02-28 22:35:43,436:INFO:[LightGBM] [Info] Start training from score 23.452033
2024-02-28 22:35:43,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,582:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-02-28 22:35:43,582:INFO:[LightGBM] [Info] Total Bins 220
2024-02-28 22:35:43,582:INFO:[LightGBM] [Info] Number of data points in the train set: 246, number of used features: 5
2024-02-28 22:35:43,636:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-02-28 22:35:43,636:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-02-28 22:35:43,643:INFO:[LightGBM] [Info] GPU programs have been built
2024-02-28 22:35:43,643:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-02-28 22:35:43,651:INFO:[LightGBM] [Info] 5 dense feature groups (0.00 MB) transferred to GPU in 0.000483 secs. 0 sparse feature groups
2024-02-28 22:35:43,651:INFO:[LightGBM] [Info] Start training from score 23.622358
2024-02-28 22:35:43,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,797:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-02-28 22:35:43,797:INFO:[LightGBM] [Info] Total Bins 214
2024-02-28 22:35:43,797:INFO:[LightGBM] [Info] Number of data points in the train set: 246, number of used features: 5
2024-02-28 22:35:43,851:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-02-28 22:35:43,851:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-02-28 22:35:43,859:INFO:[LightGBM] [Info] GPU programs have been built
2024-02-28 22:35:43,859:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-02-28 22:35:43,859:INFO:[LightGBM] [Info] 5 dense feature groups (0.00 MB) transferred to GPU in 0.000411 secs. 0 sparse feature groups
2024-02-28 22:35:43,859:INFO:[LightGBM] [Info] Start training from score 23.693902
2024-02-28 22:35:43,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:43,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,013:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-02-28 22:35:44,013:INFO:[LightGBM] [Info] Total Bins 218
2024-02-28 22:35:44,013:INFO:[LightGBM] [Info] Number of data points in the train set: 246, number of used features: 5
2024-02-28 22:35:44,075:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-02-28 22:35:44,075:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-02-28 22:35:44,083:INFO:[LightGBM] [Info] GPU programs have been built
2024-02-28 22:35:44,083:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-02-28 22:35:44,083:INFO:[LightGBM] [Info] 5 dense feature groups (0.00 MB) transferred to GPU in 0.000361 secs. 0 sparse feature groups
2024-02-28 22:35:44,083:INFO:[LightGBM] [Info] Start training from score 23.815041
2024-02-28 22:35:44,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,236:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-02-28 22:35:44,236:INFO:[LightGBM] [Info] Total Bins 218
2024-02-28 22:35:44,236:INFO:[LightGBM] [Info] Number of data points in the train set: 247, number of used features: 5
2024-02-28 22:35:44,292:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-02-28 22:35:44,292:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-02-28 22:35:44,292:INFO:[LightGBM] [Info] GPU programs have been built
2024-02-28 22:35:44,292:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-02-28 22:35:44,292:INFO:[LightGBM] [Info] 5 dense feature groups (0.00 MB) transferred to GPU in 0.000448 secs. 0 sparse feature groups
2024-02-28 22:35:44,292:INFO:[LightGBM] [Info] Start training from score 23.681781
2024-02-28 22:35:44,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,451:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-02-28 22:35:44,451:INFO:[LightGBM] [Info] Total Bins 219
2024-02-28 22:35:44,451:INFO:[LightGBM] [Info] Number of data points in the train set: 247, number of used features: 5
2024-02-28 22:35:44,522:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-02-28 22:35:44,522:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-02-28 22:35:44,522:INFO:[LightGBM] [Info] GPU programs have been built
2024-02-28 22:35:44,522:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-02-28 22:35:44,522:INFO:[LightGBM] [Info] 5 dense feature groups (0.00 MB) transferred to GPU in 0.000377 secs. 0 sparse feature groups
2024-02-28 22:35:44,522:INFO:[LightGBM] [Info] Start training from score 23.918623
2024-02-28 22:35:44,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,683:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-02-28 22:35:44,683:INFO:[LightGBM] [Info] Total Bins 214
2024-02-28 22:35:44,683:INFO:[LightGBM] [Info] Number of data points in the train set: 247, number of used features: 5
2024-02-28 22:35:44,737:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-02-28 22:35:44,737:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-02-28 22:35:44,753:INFO:[LightGBM] [Info] GPU programs have been built
2024-02-28 22:35:44,753:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-02-28 22:35:44,753:INFO:[LightGBM] [Info] 5 dense feature groups (0.00 MB) transferred to GPU in 0.000364 secs. 0 sparse feature groups
2024-02-28 22:35:44,753:INFO:[LightGBM] [Info] Start training from score 23.956275
2024-02-28 22:35:44,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,891:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-02-28 22:35:44,891:INFO:[LightGBM] [Info] Total Bins 215
2024-02-28 22:35:44,891:INFO:[LightGBM] [Info] Number of data points in the train set: 247, number of used features: 5
2024-02-28 22:35:44,961:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-02-28 22:35:44,961:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-02-28 22:35:44,961:INFO:[LightGBM] [Info] GPU programs have been built
2024-02-28 22:35:44,961:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-02-28 22:35:44,961:INFO:[LightGBM] [Info] 5 dense feature groups (0.00 MB) transferred to GPU in 0.000346 secs. 0 sparse feature groups
2024-02-28 22:35:44,961:INFO:[LightGBM] [Info] Start training from score 23.765182
2024-02-28 22:35:44,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:44,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,124:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-02-28 22:35:45,124:INFO:[LightGBM] [Info] Total Bins 214
2024-02-28 22:35:45,124:INFO:[LightGBM] [Info] Number of data points in the train set: 247, number of used features: 5
2024-02-28 22:35:45,177:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-02-28 22:35:45,177:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-02-28 22:35:45,177:INFO:[LightGBM] [Info] GPU programs have been built
2024-02-28 22:35:45,192:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-02-28 22:35:45,192:INFO:[LightGBM] [Info] 5 dense feature groups (0.00 MB) transferred to GPU in 0.000361 secs. 0 sparse feature groups
2024-02-28 22:35:45,192:INFO:[LightGBM] [Info] Start training from score 23.770040
2024-02-28 22:35:45,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,343:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-02-28 22:35:45,343:INFO:[LightGBM] [Info] Total Bins 218
2024-02-28 22:35:45,343:INFO:[LightGBM] [Info] Number of data points in the train set: 247, number of used features: 5
2024-02-28 22:35:45,397:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-02-28 22:35:45,397:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-02-28 22:35:45,410:INFO:[LightGBM] [Info] GPU programs have been built
2024-02-28 22:35:45,411:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-02-28 22:35:45,412:INFO:[LightGBM] [Info] 5 dense feature groups (0.00 MB) transferred to GPU in 0.000336 secs. 0 sparse feature groups
2024-02-28 22:35:45,412:INFO:[LightGBM] [Info] Start training from score 23.837652
2024-02-28 22:35:45,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,557:INFO:Calculating mean and std
2024-02-28 22:35:45,557:INFO:Creating metrics dataframe
2024-02-28 22:35:45,559:INFO:Finalizing model
2024-02-28 22:35:45,559:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-02-28 22:35:45,559:INFO:[LightGBM] [Info] Total Bins 234
2024-02-28 22:35:45,559:INFO:[LightGBM] [Info] Number of data points in the train set: 274, number of used features: 5
2024-02-28 22:35:45,620:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-02-28 22:35:45,620:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-02-28 22:35:45,620:INFO:[LightGBM] [Info] GPU programs have been built
2024-02-28 22:35:45,628:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-02-28 22:35:45,628:INFO:[LightGBM] [Info] 5 dense feature groups (0.00 MB) transferred to GPU in 0.000409 secs. 0 sparse feature groups
2024-02-28 22:35:45,628:INFO:[LightGBM] [Info] Start training from score 23.751460
2024-02-28 22:35:45,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-28 22:35:45,774:INFO:Uploading results into container
2024-02-28 22:35:45,782:INFO:_master_model_container: 30
2024-02-28 22:35:45,782:INFO:_display_container: 31
2024-02-28 22:35:45,782:INFO:LGBMRegressor(device='gpu', n_jobs=-1, random_state=123)
2024-02-28 22:35:45,782:INFO:create_model() successfully completed......................................
2024-02-28 22:35:45,959:INFO:Initializing create_model()
2024-02-28 22:35:45,959:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571F1E50>, estimator=<catboost.core.CatBoostRegressor object at 0x000001601C9EA580>, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:35:45,959:INFO:Checking exceptions
2024-02-28 22:35:45,965:INFO:Importing libraries
2024-02-28 22:35:45,965:INFO:Copying training dataset
2024-02-28 22:35:45,967:INFO:Defining folds
2024-02-28 22:35:45,967:INFO:Declaring metric variables
2024-02-28 22:35:45,967:INFO:Importing untrained model
2024-02-28 22:35:45,967:INFO:Declaring custom model
2024-02-28 22:35:45,968:INFO:CatBoost Regressor Imported successfully
2024-02-28 22:35:45,968:INFO:Starting cross validation
2024-02-28 22:35:45,969:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:37:01,831:INFO:Calculating mean and std
2024-02-28 22:37:01,831:INFO:Creating metrics dataframe
2024-02-28 22:37:01,833:INFO:Finalizing model
2024-02-28 22:37:08,651:INFO:Uploading results into container
2024-02-28 22:37:08,652:INFO:_master_model_container: 30
2024-02-28 22:37:08,652:INFO:_display_container: 32
2024-02-28 22:37:08,652:INFO:<catboost.core.CatBoostRegressor object at 0x000001601784A1F0>
2024-02-28 22:37:08,652:INFO:create_model() successfully completed......................................
2024-02-28 22:37:08,814:INFO:Initializing create_model()
2024-02-28 22:37:08,814:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571F1E50>, estimator=DummyRegressor(), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:37:08,814:INFO:Checking exceptions
2024-02-28 22:37:08,817:INFO:Importing libraries
2024-02-28 22:37:08,817:INFO:Copying training dataset
2024-02-28 22:37:08,819:INFO:Defining folds
2024-02-28 22:37:08,819:INFO:Declaring metric variables
2024-02-28 22:37:08,819:INFO:Importing untrained model
2024-02-28 22:37:08,819:INFO:Declaring custom model
2024-02-28 22:37:08,819:INFO:Dummy Regressor Imported successfully
2024-02-28 22:37:08,819:INFO:Starting cross validation
2024-02-28 22:37:08,820:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-28 22:37:08,899:INFO:Calculating mean and std
2024-02-28 22:37:08,899:INFO:Creating metrics dataframe
2024-02-28 22:37:08,899:INFO:Finalizing model
2024-02-28 22:37:08,899:INFO:Uploading results into container
2024-02-28 22:37:08,899:INFO:_master_model_container: 30
2024-02-28 22:37:08,899:INFO:_display_container: 33
2024-02-28 22:37:08,899:INFO:DummyRegressor()
2024-02-28 22:37:08,899:INFO:create_model() successfully completed......................................
2024-02-28 22:38:08,743:INFO:Initializing automl()
2024-02-28 22:38:08,743:INFO:automl(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571F1E50>, optimize=R2, use_holdout=False, turbo=True, return_train_score=False)
2024-02-28 22:38:08,743:INFO:Model Selection Basis : CV Results on Training set
2024-02-28 22:38:08,743:INFO:Checking model 0
2024-02-28 22:38:08,743:INFO:Checking model 2
2024-02-28 22:38:08,743:INFO:Checking model 3
2024-02-28 22:38:08,743:INFO:Checking model 4
2024-02-28 22:38:08,743:INFO:Checking model 5
2024-02-28 22:38:08,743:INFO:Checking model 6
2024-02-28 22:38:08,743:INFO:Checking model 7
2024-02-28 22:38:08,743:INFO:Checking model 8
2024-02-28 22:38:08,743:INFO:Checking model 9
2024-02-28 22:38:08,743:INFO:Checking model 10
2024-02-28 22:38:08,743:INFO:Checking model 11
2024-02-28 22:38:08,743:INFO:Checking model 12
2024-02-28 22:38:08,743:INFO:Checking model 13
2024-02-28 22:38:08,743:INFO:Checking model 14
2024-02-28 22:38:08,743:INFO:Checking model 15
2024-02-28 22:38:08,743:INFO:Checking model 16
2024-02-28 22:38:08,743:INFO:Checking model 17
2024-02-28 22:38:08,743:INFO:Checking model 18
2024-02-28 22:38:08,743:INFO:Checking model 19
2024-02-28 22:38:08,743:INFO:Checking model 20
2024-02-28 22:38:08,743:INFO:Checking model 21
2024-02-28 22:38:08,743:INFO:Checking model 22
2024-02-28 22:38:08,743:INFO:Checking model 23
2024-02-28 22:38:08,743:INFO:Checking model 24
2024-02-28 22:38:08,743:INFO:Checking model 25
2024-02-28 22:38:08,743:INFO:Checking model 26
2024-02-28 22:38:08,743:INFO:Checking model 27
2024-02-28 22:38:08,743:INFO:Checking model 28
2024-02-28 22:38:08,743:INFO:Checking model 29
2024-02-28 22:38:08,743:INFO:Initializing create_model()
2024-02-28 22:38:08,743:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000160571F1E50>, estimator=VotingRegressor(estimators=[('Gradient Boosting Regressor',
                             GradientBoostingRegressor(random_state=123)),
                            ('Random Forest Regressor',
                             RandomForestRegressor(n_jobs=-1,
                                                   random_state=123)),
                            ('Extra Trees Regressor',
                             ExtraTreesRegressor(n_jobs=-1, random_state=123))],
                n_jobs=1), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-28 22:38:08,743:INFO:Checking exceptions
2024-02-28 22:38:08,754:INFO:Importing libraries
2024-02-28 22:38:08,754:INFO:Copying training dataset
2024-02-28 22:38:08,756:INFO:Defining folds
2024-02-28 22:38:08,756:INFO:Declaring metric variables
2024-02-28 22:38:08,756:INFO:Importing untrained model
2024-02-28 22:38:08,756:INFO:Declaring custom model
2024-02-28 22:38:08,757:INFO:Voting Regressor Imported successfully
2024-02-28 22:38:08,758:INFO:Cross validation set to False
2024-02-28 22:38:08,758:INFO:Fitting Model
2024-02-28 22:38:08,830:INFO:VotingRegressor(estimators=[('Gradient Boosting Regressor',
                             GradientBoostingRegressor(random_state=123)),
                            ('Random Forest Regressor',
                             RandomForestRegressor(n_jobs=-1,
                                                   random_state=123)),
                            ('Extra Trees Regressor',
                             ExtraTreesRegressor(n_jobs=-1, random_state=123))],
                n_jobs=1)
2024-02-28 22:38:08,830:INFO:create_model() successfully completed......................................
2024-02-28 22:38:09,129:INFO:VotingRegressor(estimators=[('Gradient Boosting Regressor',
                             GradientBoostingRegressor(random_state=123)),
                            ('Random Forest Regressor',
                             RandomForestRegressor(n_jobs=-1,
                                                   random_state=123)),
                            ('Extra Trees Regressor',
                             ExtraTreesRegressor(n_jobs=-1, random_state=123))],
                n_jobs=1)
2024-02-28 22:38:09,129:INFO:automl() successfully completed......................................
